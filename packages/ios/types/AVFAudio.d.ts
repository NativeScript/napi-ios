/// <reference types="@nativescript/objc-node-api" />
/// <reference path="./Runtime.d.ts" />
/// <reference path="./AudioToolbox.d.ts" />

declare const AVAudioSessionSetActiveFlags_NotifyOthersOnDeactivation: number;

declare const AVAudioUnitTypeOfflineEffect: string;

declare const AVAudioSessionPolarPatternStereo: string;

declare const AVAudioSessionModeGameChat: string;

declare const AVSampleRateConverterAudioQualityKey: string;

declare const AVAudioSessionPortAVB: string;

declare const AVSpeechUtteranceDefaultSpeechRate: number;

declare const AVAudioApplicationMuteStateKey: string;

declare const AVSpeechSynthesisVoiceIdentifierAlex: string;

declare const AVSpeechUtteranceMaximumSpeechRate: number;

declare const AVSpeechUtteranceMinimumSpeechRate: number;

declare const AVExtendedNoteOnEventDefaultInstrument: number;

declare const AVAudioUnitTypePanner: string;

declare const AVAudioUnitTypeMixer: string;

declare const AVAudioUnitTypeEffect: string;

declare const AVAudioUnitTypeFormatConverter: string;

declare const AVAudioUnitTypeMusicEffect: string;

declare const AVAudioUnitTypeOutput: string;

declare const AVAudioSequencerInfoDictionaryKeyYear: string;

declare const AVAudioSequencerInfoDictionaryKeyTitle: string;

declare const AVAudioSequencerInfoDictionaryKeySourceBitDepth: string;

declare const AVAudioSequencerInfoDictionaryKeyRecordedDate: string;

declare const AVAudioSequencerInfoDictionaryKeyLyricist: string;

declare const AVAudioSequencerInfoDictionaryKeyKeySignature: string;

declare const AVAudioSequencerInfoDictionaryKeyGenre: string;

declare const AVAudioSequencerInfoDictionaryKeyEncodingApplication: string;

declare const AVAudioSequencerInfoDictionaryKeyChannelLayout: string;

declare const AVAudioSequencerInfoDictionaryKeyArtist: string;

declare const AVAudioSequencerInfoDictionaryKeyAlbum: string;

declare const AVAudioSessionPolarPatternCardioid: string;

declare const AVAudioSessionPolarPatternOmnidirectional: string;

declare const AVAudioSessionOrientationRight: string;

declare const AVAudioSequencerInfoDictionaryKeyComposer: string;

declare const AVAudioSessionOrientationBack: string;

declare const AVAudioSessionOrientationFront: string;

declare const AVAudioSessionOrientationTop: string;

declare const AVAudioSessionAvailableInputsChangeNotification: string;

declare const AVAudioSessionRenderingModeNewRenderingModeKey: string;

declare const AVAudioSessionRouteChangePreviousRouteKey: string;

declare const AVAudioSessionRouteChangeReasonKey: string;

declare const AVAudioSessionInterruptionOptionKey: string;

declare const AVAudioSessionUserIntentToUnmuteOutputNotification: string;

declare const AVAudioSessionMuteStateKey: string;

declare const AVAudioSessionSpatialAudioEnabledKey: string;

declare const AVAudioSessionOutputMuteStateChangeNotification: string;

declare const AVAudioSessionRenderingCapabilitiesChangeNotification: string;

declare const AVAudioSessionSilenceSecondaryAudioHintNotification: string;

declare const AVAudioSessionMediaServicesWereLostNotification: string;

declare const AVAudioSessionInterruptionNotification: string;

declare const AVAudioSessionModeShortFormVideo: string;

declare const AVAudioSessionModeVoicePrompt: string;

declare const AVAudioSessionModeVideoChat: string;

declare const AVAudioSessionModeMoviePlayback: string;

declare const AVAudioSessionModeVideoRecording: string;

declare const AVAudioSessionModeVoiceChat: string;

declare const AVAudioSessionCategoryAudioProcessing: string;

declare const AVAudioSessionCategoryPlayAndRecord: string;

declare const AVAudioSessionCategorySoloAmbient: string;

declare const AVAudioSessionCategoryAmbient: string;

declare const AVAudioSessionPortThunderbolt: string;

declare const AVAudioSessionPortDisplayPort: string;

declare const AVAudioSessionPortPCI: string;

declare const AVAudioSessionPortVirtual: string;

declare const AVAudioSessionPortBluetoothHFP: string;

declare const AVAudioSessionPortBluetoothLE: string;

declare const AVAudioSessionPortAirPlay: string;

declare const AVAudioSessionPortBuiltInSpeaker: string;

declare const AVAudioSessionPortBuiltInReceiver: string;

declare const AVAudioSessionPortBluetoothA2DP: string;

declare const AVAudioSessionPortLineOut: string;

declare const AVAudioSessionPortLineIn: string;

declare const AVAudioSessionPortContinuityMicrophone: string;

declare const AVAudioEngineConfigurationChangeNotification: string;

declare const AVSampleRateConverterAlgorithm_Mastering: string;

declare const AVAudioBitRateStrategy_VariableConstrained: string;

declare const AVAudioBitRateStrategy_LongTermAverage: string;

declare const AVAudioBitRateStrategy_Constant: string;

declare const AVChannelLayoutKey: string;

declare const AVEncoderASPFrequencyKey: string;

declare const AVEncoderContentSourceKey: string;

declare const AVEncoderDynamicRangeControlConfigurationKey: string;

declare const AVEncoderBitDepthHintKey: string;

declare const AVEncoderBitRatePerChannelKey: string;

declare const AVEncoderBitRateKey: string;

declare const AVEncoderAudioQualityForVBRKey: string;

declare const AVAudioFileTypeKey: string;

declare const AVLinearPCMIsFloatKey: string;

declare const AVNumberOfChannelsKey: string;

declare const AVAudioUnitManufacturerNameApple: string;

declare const AVAudioSessionSpatialPlaybackCapabilitiesChangedNotification: string;

declare const AVAudioUnitComponentTagsDidChangeNotification: string;

declare const AVAudioSessionPortFireWire: string;

declare const AVAudioSessionPortHeadsetMic: string;

declare const AVAudioSessionPortHeadphones: string;

declare const AVAudioSessionPortUSBAudio: string;

declare const AVAudioSequencerInfoDictionaryKeyTimeSignature: string;

declare const AVAudioSequencerInfoDictionaryKeyCopyright: string;

declare const AVSampleRateConverterAlgorithmKey: string;

declare const AVLinearPCMIsNonInterleaved: string;

declare const AVSampleRateKey: string;

declare const AVAudioSessionInterruptionTypeKey: string;

declare const AVAudioSequencerInfoDictionaryKeyTempo: string;

declare const AVAudioSessionSilenceSecondaryAudioHintTypeKey: string;

declare const AVAudioSequencerInfoDictionaryKeyApproximateDurationInSeconds: string;

declare const AVAudioSequencerInfoDictionaryKeySubTitle: string;

declare const AVSampleRateConverterAlgorithm_MinimumPhase: string;

declare const AVAudioSessionRenderingModeChangeNotification: string;

declare const AVAudioSessionModeMeasurement: string;

declare const AVFormatIDKey: string;

declare const AVAudioSessionRouteChangeNotification: string;

declare const AVAudioUnitComponentManagerRegistrationsChangedNotification: string;

declare const AVSampleRateConverterAlgorithm_Normal: string;

declare const AVAudioSessionMicrophoneInjectionIsAvailableKey: string;

declare const AVAudioSessionPortCarAudio: string;

declare const AVAudioSessionMediaServicesWereResetNotification: string;

declare const AVAudioSessionCategoryRecord: string;

declare const AVAudioSessionInterruptionWasSuspendedKey: string;

declare const AVAudioSessionLocationUpper: string;

declare const AVAudioSessionPortHDMI: string;

declare const AVAudioSequencerInfoDictionaryKeyTrackNumber: string;

declare const AVAudioSessionInterruptionFlags_ShouldResume: number;

declare const AVAudioSessionCategoryPlayback: string;

declare const AVEncoderAudioQualityKey: string;

declare const AVSpeechSynthesisIPANotationAttribute: string;

declare const AVAudioSequencerInfoDictionaryKeyComments: string;

declare const AVAudioSequencerInfoDictionaryKeyISRC: string;

declare const AVAudioSessionPortBuiltInMic: string;

declare const AVAudioSessionModeSpokenAudio: string;

declare const AVAudioSequencerInfoDictionaryKeySourceEncoder: string;

declare const AVAudioApplicationInputMuteStateChangeNotification: string;

declare const AVAudioSessionLocationLower: string;

declare const AVEncoderBitRateStrategyKey: string;

declare const AVLinearPCMIsBigEndianKey: string;

declare const AVLinearPCMBitDepthKey: string;

declare const AVAudioUnitTypeMIDIProcessor: string;

declare const AVAudioBitRateStrategy_Variable: string;

declare const AVAudioSessionPolarPatternSubcardioid: string;

declare const AVAudioSessionOrientationBottom: string;

declare const AVAudioSessionMicrophoneInjectionCapabilitiesChangeNotification: string;

declare const AVAudioSequencerInfoDictionaryKeyNominalBitRate: string;

declare const AVAudioSessionCategoryMultiRoute: string;

declare const AVAudioUnitTypeMusicDevice: string;

declare const AVAudioSessionModeDefault: string;

declare const AVAudioSessionInterruptionReasonKey: string;

declare const AVAudioUnitTypeGenerator: string;

declare const AVSpeechSynthesisAvailableVoicesDidChangeNotification: string;

declare const AVAudioSessionOrientationLeft: string;

declare const AVAudioEngineManualRenderingStatus: {
  Error: -1,
  Success: 0,
  InsufficientDataFromInputNode: 1,
  CannotDoInCurrentContext: 2,
};

declare const AVAudioPlayerNodeCompletionCallbackType: {
  Consumed: 0,
  Rendered: 1,
  PlayedBack: 2,
};

declare const AVAudioRoutingArbitrationCategory: {
  Playback: 0,
  PlayAndRecord: 1,
  PlayAndRecordVoice: 2,
};

declare const AVSpeechSynthesisMarkerMark: {
  Phoneme: 0,
  Word: 1,
  Sentence: 2,
  Paragraph: 3,
  Bookmark: 4,
};

declare const AVSpeechSynthesisVoiceGender: {
  Unspecified: 0,
  Male: 1,
  Female: 2,
};

declare const AVSpeechSynthesisVoiceQuality: {
  Default: 1,
  Enhanced: 2,
  Premium: 3,
};

declare const AVMIDIMetaEventType: {
  SequenceNumber: 0,
  Text: 1,
  Copyright: 2,
  TrackName: 3,
  Instrument: 4,
  Lyric: 5,
  Marker: 6,
  CuePoint: 7,
  MidiChannel: 32,
  MidiPort: 33,
  EndOfTrack: 47,
  Tempo: 81,
  SmpteOffset: 84,
  TimeSignature: 88,
  KeySignature: 89,
  ProprietaryEvent: 127,
};

declare const AVMIDIControlChangeMessageType: {
  BankSelect: 0,
  ModWheel: 1,
  Breath: 2,
  Foot: 4,
  PortamentoTime: 5,
  DataEntry: 6,
  Volume: 7,
  Balance: 8,
  Pan: 10,
  Expression: 11,
  Sustain: 64,
  Portamento: 65,
  Sostenuto: 66,
  Soft: 67,
  LegatoPedal: 68,
  Hold2Pedal: 69,
  FilterResonance: 71,
  ReleaseTime: 72,
  AttackTime: 73,
  Brightness: 74,
  DecayTime: 75,
  VibratoRate: 76,
  VibratoDepth: 77,
  VibratoDelay: 78,
  ReverbLevel: 91,
  ChorusLevel: 93,
  RPN_LSB: 100,
  RPN_MSB: 101,
  AllSoundOff: 120,
  ResetAllControllers: 121,
  AllNotesOff: 123,
  OmniModeOff: 124,
  OmniModeOn: 125,
  MonoModeOn: 126,
  MonoModeOff: 127,
};

declare const AVAudioUnitDistortionPreset: {
  DrumsBitBrush: 0,
  DrumsBufferBeats: 1,
  DrumsLoFi: 2,
  MultiBrokenSpeaker: 3,
  MultiCellphoneConcert: 4,
  MultiDecimated1: 5,
  MultiDecimated2: 6,
  MultiDecimated3: 7,
  MultiDecimated4: 8,
  MultiDistortedFunk: 9,
  MultiDistortedCubed: 10,
  MultiDistortedSquared: 11,
  MultiEcho1: 12,
  MultiEcho2: 13,
  MultiEchoTight1: 14,
  MultiEchoTight2: 15,
  MultiEverythingIsBroken: 16,
  SpeechAlienChatter: 17,
  SpeechCosmicInterference: 18,
  SpeechGoldenPi: 19,
  SpeechRadioTower: 20,
  SpeechWaves: 21,
};

declare const AVMusicTrackLoopCount: {
  AVMusicTrackLoopCountForever: -1,
};

declare const AVAudioPlayerNodeBufferOptions: {
  Loops: 1,
  Interrupts: 2,
  InterruptsAtLoop: 4,
};

declare const AVAudioSessionRouteSharingPolicy: {
  Default: 0,
  LongFormAudio: 1,
  LongForm: 1,
  Independent: 2,
  LongFormVideo: 3,
};

declare const AVAudioSessionSetActiveOptions: {
  AVAudioSessionSetActiveOptionNotifyOthersOnDeactivation: 1,
};

declare const AVAudioSessionInterruptionType: {
  Began: 1,
  Ended: 0,
};

declare const AVAudioSessionCategoryOptions: {
  MixWithOthers: 1,
  DuckOthers: 2,
  AllowBluetooth: 4,
  AllowBluetoothHFP: 4,
  DefaultToSpeaker: 8,
  InterruptSpokenAudioAndMixWithOthers: 17,
  AllowBluetoothA2DP: 32,
  AllowAirPlay: 64,
  OverrideMutedMicrophoneInterruption: 128,
  BluetoothHighQualityRecording: 524288,
};

declare const AVAudioSessionPortOverride: {
  None: 0,
  Speaker: 1936747378,
};

declare const AVAudioSessionActivationOptions: {
  AVAudioSessionActivationOptionNone: 0,
};

declare const AVAudioEnvironmentOutputType: {
  Auto: 0,
  Headphones: 1,
  BuiltInSpeakers: 2,
  ExternalSpeakers: 3,
};

declare const AVAudioEnvironmentDistanceAttenuationModel: {
  Exponential: 1,
  Inverse: 2,
  Linear: 3,
};

declare const AVAudioUnitReverbPreset: {
  SmallRoom: 0,
  MediumRoom: 1,
  LargeRoom: 2,
  MediumHall: 3,
  LargeHall: 4,
  Plate: 5,
  MediumChamber: 6,
  LargeChamber: 7,
  Cathedral: 8,
  LargeRoom2: 9,
  MediumHall2: 10,
  MediumHall3: 11,
  LargeHall2: 12,
};

declare const AVAudioEngineManualRenderingError: {
  InvalidMode: -80800,
  Initialized: -80801,
  NotRunning: -80802,
};

declare const AVAudio3DMixingSourceMode: {
  SpatializeIfMono: 0,
  Bypass: 1,
  PointSource: 2,
  AmbienceBed: 3,
};

declare const AVAudio3DMixingRenderingAlgorithm: {
  EqualPowerPanning: 0,
  SphericalHead: 1,
  HRTF: 2,
  SoundField: 3,
  StereoPassThrough: 5,
  HRTFHQ: 6,
  Auto: 7,
};

declare const AVAudioConverterInputStatus: {
  HaveData: 0,
  NoDataNow: 1,
  EndOfStream: 2,
};

declare const AVAudioConverterPrimeMethod: {
  Pre: 0,
  Normal: 1,
  None: 2,
};

declare const AVAudioContentSource: {
  Unspecified: -1,
  Reserved: 0,
  AppleCapture_Traditional: 1,
  AppleCapture_Spatial: 2,
  AppleCapture_Spatial_Enhanced: 3,
  AppleMusic_Traditional: 4,
  AppleMusic_Spatial: 5,
  AppleAV_Traditional_Offline: 6,
  AppleAV_Spatial_Offline: 7,
  AppleAV_Traditional_Live: 8,
  AppleAV_Spatial_Live: 9,
  ApplePassthrough: 10,
  Capture_Traditional: 33,
  Capture_Spatial: 34,
  Capture_Spatial_Enhanced: 35,
  Music_Traditional: 36,
  Music_Spatial: 37,
  AV_Traditional_Offline: 38,
  AV_Spatial_Offline: 39,
  AV_Traditional_Live: 40,
  AV_Spatial_Live: 41,
  Passthrough: 42,
};

declare const AVAudioDynamicRangeControlConfiguration: {
  None: 0,
  Music: 1,
  Speech: 2,
  Movie: 3,
  Capture: 4,
};

declare const AVSpeechSynthesisPersonalVoiceAuthorizationStatus: {
  NotDetermined: 0,
  Denied: 1,
  Unsupported: 2,
  Authorized: 3,
};

declare const AVAudioConverterOutputStatus: {
  HaveData: 0,
  InputRanDry: 1,
  EndOfStream: 2,
  Error: 3,
};

declare const AVAudioCommonFormat: {
  OtherFormat: 0,
  PCMFormatFloat32: 1,
  PCMFormatFloat64: 2,
  PCMFormatInt16: 3,
  PCMFormatInt32: 4,
};

declare const AVAudioSessionInterruptionOptions: {
  AVAudioSessionInterruptionOptionShouldResume: 1,
};

declare const AVAudioSessionIOType: {
  NotSpecified: 0,
  Aggregated: 1,
};

declare const AVAudioVoiceProcessingOtherAudioDuckingLevel: {
  Default: 0,
  Min: 10,
  Mid: 20,
  Max: 30,
};

declare const AVAudioSessionMicrophoneInjectionMode: {
  None: 0,
  SpokenAudio: 1,
};

declare const AVAudioSessionInterruptionReason: {
  Default: 0,
  AppWasSuspended: 1,
  BuiltInMicMuted: 2,
  RouteDisconnected: 4,
};

declare const AVAudioSessionRecordPermission: {
  Undetermined: 1970168948,
  Denied: 1684369017,
  Granted: 1735552628,
};

declare const AVSpeechBoundary: {
  Immediate: 0,
  Word: 1,
};

declare const AVAudioSessionRouteChangeReason: {
  Unknown: 0,
  NewDeviceAvailable: 1,
  OldDeviceUnavailable: 2,
  CategoryChange: 3,
  Override: 4,
  WakeFromSleep: 6,
  NoSuitableRouteForCategory: 7,
  RouteConfigurationChange: 8,
};

declare const AVAudioSessionRenderingMode: {
  NotApplicable: 0,
  MonoStereo: 1,
  Surround: 2,
  SpatialAudio: 3,
  DolbyAudio: 4,
  DolbyAtmos: 5,
};

declare const AVAudioSessionPromptStyle: {
  None: 1852796517,
  Short: 1936224884,
  Normal: 1852992876,
};

declare const AVAudioSessionSilenceSecondaryAudioHintType: {
  Begin: 1,
  End: 0,
};

declare const AVAudioStereoOrientation: {
  None: 0,
  Portrait: 1,
  PortraitUpsideDown: 2,
  LandscapeRight: 3,
  LandscapeLeft: 4,
};

declare const AVAudioVoiceProcessingSpeechActivityEvent: {
  Started: 0,
  Ended: 1,
};

declare const AVMusicSequenceLoadOptions: {
  Preserve: 0,
  ChannelsTo: 1,
};

declare const AVAudioUnitEQFilterType: {
  Parametric: 0,
  LowPass: 1,
  HighPass: 2,
  ResonantLowPass: 3,
  ResonantHighPass: 4,
  BandPass: 5,
  BandStop: 6,
  LowShelf: 7,
  HighShelf: 8,
  ResonantLowShelf: 9,
  ResonantHighShelf: 10,
};

declare const AVSpeechSynthesisVoiceTraits: {
  None: 0,
  IsNoveltyVoice: 1,
  IsPersonalVoice: 2,
};

declare const AVAudioQuality: {
  Min: 0,
  Low: 32,
  Medium: 64,
  High: 96,
  Max: 127,
};

declare const AVAudioApplicationMicrophoneInjectionPermission: {
  ServiceDisabled: 1936876659,
  Undetermined: 1970168948,
  Denied: 1684369017,
  Granted: 1735552628,
};

declare const AVAudio3DMixingPointSourceInHeadMode: {
  Mono: 0,
  Bypass: 1,
};

declare const AVAudioEngineManualRenderingMode: {
  Offline: 0,
  Realtime: 1,
};

declare const AVAudioApplicationRecordPermission: {
  Undetermined: 1970168948,
  Denied: 1684369017,
  Granted: 1735552628,
};

declare class AVAudioVoiceProcessingOtherAudioDuckingConfiguration {
  constructor(init?: AVAudioVoiceProcessingOtherAudioDuckingConfiguration);
  enableAdvancedDucking: boolean;
  duckingLevel: interop.Enum<typeof AVAudioVoiceProcessingOtherAudioDuckingLevel>;
}

declare class AVAudio3DVectorOrientation {
  constructor(init?: AVAudio3DVectorOrientation);
  forward: AVAudio3DPoint;
  up: AVAudio3DPoint;
}

declare class AVAudio3DPoint {
  constructor(init?: AVAudio3DPoint);
  x: number;
  y: number;
  z: number;
}

declare class _AVBeatRange {
  constructor(init?: _AVBeatRange);
  start: number;
  length: number;
}

declare class AVAudio3DAngularOrientation {
  constructor(init?: AVAudio3DAngularOrientation);
  yaw: number;
  pitch: number;
  roll: number;
}

declare class AVAudioConverterPrimeInfo {
  constructor(init?: AVAudioConverterPrimeInfo);
  leadingFrames: number;
  trailingFrames: number;
}

declare interface AVAudioSessionDelegate extends NSObjectProtocol {
  beginInterruption?(): void;

  endInterruptionWithFlags?(flags: number): void;

  endInterruption?(): void;

  inputIsAvailableChanged?(isInputAvailable: boolean): void;
}

declare class AVAudioSessionDelegate extends NativeObject implements AVAudioSessionDelegate {
}

declare interface AVAudioPlayerDelegate extends NSObjectProtocol {
  audioPlayerDidFinishPlayingSuccessfully?(player: AVAudioPlayer, flag: boolean): void;

  audioPlayerDecodeErrorDidOccurError?(player: AVAudioPlayer, error: NSError | null): void;

  audioPlayerBeginInterruption?(player: AVAudioPlayer): void;

  audioPlayerEndInterruptionWithOptions?(player: AVAudioPlayer, flags: number): void;

  audioPlayerEndInterruptionWithFlags?(player: AVAudioPlayer, flags: number): void;

  audioPlayerEndInterruption?(player: AVAudioPlayer): void;
}

declare class AVAudioPlayerDelegate extends NativeObject implements AVAudioPlayerDelegate {
}

declare interface AVAudioStereoMixing extends NSObjectProtocol {
  pan: number;

  setPan(pan: number): void;
}

declare class AVAudioStereoMixing extends NativeObject implements AVAudioStereoMixing {
}

declare interface AVAudioMixing extends AVAudioStereoMixing, AVAudio3DMixing {
  destinationForMixerBus(mixer: AVAudioNode, bus: number): AVAudioMixingDestination;

  volume: number;

  setVolume(volume: number): void;
}

declare class AVAudioMixing extends NativeObject implements AVAudioMixing {
}

declare interface AVAudioRecorderDelegate extends NSObjectProtocol {
  audioRecorderDidFinishRecordingSuccessfully?(recorder: AVAudioRecorder, flag: boolean): void;

  audioRecorderEncodeErrorDidOccurError?(recorder: AVAudioRecorder, error: NSError | null): void;

  audioRecorderBeginInterruption?(recorder: AVAudioRecorder): void;

  audioRecorderEndInterruptionWithOptions?(recorder: AVAudioRecorder, flags: number): void;

  audioRecorderEndInterruptionWithFlags?(recorder: AVAudioRecorder, flags: number): void;

  audioRecorderEndInterruption?(recorder: AVAudioRecorder): void;
}

declare class AVAudioRecorderDelegate extends NativeObject implements AVAudioRecorderDelegate {
}

declare interface AVAudio3DMixing extends NSObjectProtocol {
  renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>;

  sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>;

  pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>;

  rate: number;

  reverbBlend: number;

  obstruction: number;

  occlusion: number;

  position: AVAudio3DPoint;

  setRenderingAlgorithm(renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>): void;

  setSourceMode(sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>): void;

  setPointSourceInHeadMode(pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>): void;

  setRate(rate: number): void;

  setReverbBlend(reverbBlend: number): void;

  setObstruction(obstruction: number): void;

  setOcclusion(occlusion: number): void;

  setPosition(position: AVAudio3DPoint): void;
}

declare class AVAudio3DMixing extends NativeObject implements AVAudio3DMixing {
}

declare interface AVSpeechSynthesizerDelegate extends NSObjectProtocol {
  speechSynthesizerDidStartSpeechUtterance?(synthesizer: AVSpeechSynthesizer, utterance: AVSpeechUtterance): void;

  speechSynthesizerDidFinishSpeechUtterance?(synthesizer: AVSpeechSynthesizer, utterance: AVSpeechUtterance): void;

  speechSynthesizerDidPauseSpeechUtterance?(synthesizer: AVSpeechSynthesizer, utterance: AVSpeechUtterance): void;

  speechSynthesizerDidContinueSpeechUtterance?(synthesizer: AVSpeechSynthesizer, utterance: AVSpeechUtterance): void;

  speechSynthesizerDidCancelSpeechUtterance?(synthesizer: AVSpeechSynthesizer, utterance: AVSpeechUtterance): void;

  speechSynthesizerWillSpeakRangeOfSpeechStringUtterance?(synthesizer: AVSpeechSynthesizer, characterRange: _NSRange, utterance: AVSpeechUtterance): void;

  speechSynthesizerWillSpeakMarkerUtterance?(synthesizer: AVSpeechSynthesizer, marker: AVSpeechSynthesisMarker, utterance: AVSpeechUtterance): void;
}

declare class AVSpeechSynthesizerDelegate extends NativeObject implements AVSpeechSynthesizerDelegate {
}

declare class AVMusicUserEvent extends AVMusicEvent {
  initWithData(data: NSData): this;

  readonly sizeInBytes: number;
}

declare class AVMIDIChannelPressureEvent extends AVMIDIChannelEvent {
  initWithChannelPressure(channel: number, pressure: number): this;

  pressure: number;

  setPressure(pressure: number): void;
}

declare class AVAudioUnitEQFilterParameters extends NSObject {
  filterType: interop.Enum<typeof AVAudioUnitEQFilterType>;

  frequency: number;

  bandwidth: number;

  gain: number;

  bypass: boolean;

  setFilterType(filterType: interop.Enum<typeof AVAudioUnitEQFilterType>): void;

  setFrequency(frequency: number): void;

  setBandwidth(bandwidth: number): void;

  setGain(gain: number): void;

  setBypass(bypass: boolean): void;
}

declare class AVParameterEvent extends AVMusicEvent {
  initWithParameterIDScopeElementValue(parameterID: number, scope: number, element: number, value: number): this;

  parameterID: number;

  scope: number;

  element: number;

  value: number;

  setParameterID(parameterID: number): void;

  setScope(scope: number): void;

  setElement(element: number): void;

  setValue(value: number): void;
}

declare class AVMusicEvent extends NSObject {
}

declare class AVAudioSessionChannelDescription extends NSObject {
  readonly channelName: string;

  readonly owningPortUID: string;

  readonly channelNumber: number;

  readonly channelLabel: number;
}

declare class AVAudioApplication extends NSObject {
  static readonly sharedInstance: AVAudioApplication;

  setInputMutedError(muted: boolean, outError: interop.PointerConvertible): boolean;

  readonly inputMuted: boolean;

  readonly recordPermission: interop.Enum<typeof AVAudioApplicationRecordPermission>;

  static requestRecordPermissionWithCompletionHandler(response: (p1: boolean) => void): void;

  readonly microphoneInjectionPermission: interop.Enum<typeof AVAudioApplicationMicrophoneInjectionPermission>;

  static requestMicrophoneInjectionPermissionWithCompletionHandler(response: (p1: interop.Enum<typeof AVAudioApplicationMicrophoneInjectionPermission>) => void): void;

  isInputMuted(): boolean;
}

declare class AVSpeechUtterance extends NSObject implements NSCopying, NSSecureCoding {
  static speechUtteranceWithString<This extends abstract new (...args: any) => any>(this: This, string: string): InstanceType<This>;

  static speechUtteranceWithAttributedString<This extends abstract new (...args: any) => any>(this: This, string: NSAttributedString): InstanceType<This>;

  static speechUtteranceWithSSMLRepresentation<This extends abstract new (...args: any) => any>(this: This, string: string): InstanceType<This>;

  initWithString(string: string): this;

  initWithAttributedString(string: NSAttributedString): this;

  initWithSSMLRepresentation(string: string): this;

  voice: AVSpeechSynthesisVoice;

  readonly speechString: string;

  readonly attributedSpeechString: NSAttributedString;

  rate: number;

  pitchMultiplier: number;

  volume: number;

  prefersAssistiveTechnologySettings: boolean;

  preUtteranceDelay: number;

  postUtteranceDelay: number;

  setVoice(voice: AVSpeechSynthesisVoice | null): void;

  setRate(rate: number): void;

  setPitchMultiplier(pitchMultiplier: number): void;

  setVolume(volume: number): void;

  setPrefersAssistiveTechnologySettings(prefersAssistiveTechnologySettings: boolean): void;

  setPreUtteranceDelay(preUtteranceDelay: number): void;

  setPostUtteranceDelay(postUtteranceDelay: number): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVExtendedTempoEvent extends AVMusicEvent {
  initWithTempo(tempo: number): this;

  tempo: number;

  setTempo(tempo: number): void;
}

declare class AVAUPresetEvent extends AVMusicEvent {
  initWithScopeElementDictionary(scope: number, element: number, presetDictionary: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  scope: number;

  element: number;

  readonly presetDictionary: NSDictionary;

  setScope(scope: number): void;

  setElement(element: number): void;
}

declare class AVMIDISysexEvent extends AVMusicEvent {
  initWithData(data: NSData): this;

  readonly sizeInBytes: number;
}

declare class AVMIDIPitchBendEvent extends AVMIDIChannelEvent {
  initWithChannelValue(channel: number, value: number): this;

  value: number;

  setValue(value: number): void;
}

declare class AVMIDIProgramChangeEvent extends AVMIDIChannelEvent {
  initWithChannelProgramNumber(channel: number, programNumber: number): this;

  programNumber: number;

  setProgramNumber(programNumber: number): void;
}

declare class AVMIDIPolyPressureEvent extends AVMIDIChannelEvent {
  initWithChannelKeyPressure(channel: number, key: number, pressure: number): this;

  key: number;

  pressure: number;

  setKey(key: number): void;

  setPressure(pressure: number): void;
}

declare class AVMIDIControlChangeEvent extends AVMIDIChannelEvent {
  initWithChannelMessageTypeValue(channel: number, messageType: interop.Enum<typeof AVMIDIControlChangeMessageType>, value: number): this;

  readonly messageType: interop.Enum<typeof AVMIDIControlChangeMessageType>;

  readonly value: number;
}

declare class AVAudioBuffer extends NSObject implements NSCopying, NSMutableCopying {
  readonly format: AVAudioFormat;

  readonly audioBufferList: interop.Pointer;

  readonly mutableAudioBufferList: interop.Pointer;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMIDIChannelEvent extends AVMusicEvent {
  channel: number;

  setChannel(channel: number): void;
}

declare class AVMIDIPlayer extends NSObject {
  initWithContentsOfURLSoundBankURLError(inURL: NSURL, bankURL: NSURL | null, outError: interop.PointerConvertible): this;

  initWithDataSoundBankURLError(data: NSData, bankURL: NSURL | null, outError: interop.PointerConvertible): this;

  prepareToPlay(): void;

  play(completionHandler: () => void | null): void;

  stop(): void;

  readonly duration: number;

  readonly playing: boolean;

  rate: number;

  currentPosition: number;

  isPlaying(): boolean;

  setRate(rate: number): void;

  setCurrentPosition(currentPosition: number): void;
}

declare class AVAudioUnitTimePitch extends AVAudioUnitTimeEffect {
  rate: number;

  pitch: number;

  overlap: number;

  setRate(rate: number): void;

  setPitch(pitch: number): void;

  setOverlap(overlap: number): void;
}

declare class AVAudioUnitDelay extends AVAudioUnitEffect {
  delayTime: number;

  feedback: number;

  lowPassCutoff: number;

  wetDryMix: number;

  setDelayTime(delayTime: number): void;

  setFeedback(feedback: number): void;

  setLowPassCutoff(lowPassCutoff: number): void;

  setWetDryMix(wetDryMix: number): void;
}

declare class AVAudioUnitComponentManager extends NSObject {
  readonly tagNames: NSArray;

  readonly standardLocalizedTagNames: NSArray;

  static sharedAudioUnitComponentManager<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  componentsMatchingPredicate(predicate: NSPredicate): NSArray;

  componentsPassingTest(testHandler: (p1: AVAudioUnitComponent, p2: interop.PointerConvertible) => boolean): NSArray;

  componentsMatchingDescription(desc: AudioComponentDescription): NSArray;
}

declare class AVAudioPlayer extends NSObject {
  initWithContentsOfURLError(url: NSURL, outError: interop.PointerConvertible): this;

  initWithDataError(data: NSData, outError: interop.PointerConvertible): this;

  initWithContentsOfURLFileTypeHintError(url: NSURL, utiString: string | null, outError: interop.PointerConvertible): this;

  initWithDataFileTypeHintError(data: NSData, utiString: string | null, outError: interop.PointerConvertible): this;

  prepareToPlay(): boolean;

  play(): boolean;

  playAtTime(time: number): boolean;

  pause(): void;

  stop(): void;

  readonly playing: boolean;

  readonly numberOfChannels: number;

  readonly duration: number;

  delegate: AVAudioPlayerDelegate;

  readonly url: NSURL;

  readonly data: NSData;

  pan: number;

  volume: number;

  setVolumeFadeDuration(volume: number, duration: number): void;

  enableRate: boolean;

  rate: number;

  currentTime: number;

  readonly deviceCurrentTime: number;

  numberOfLoops: number;

  readonly settings: NSDictionary;

  readonly format: AVAudioFormat;

  meteringEnabled: boolean;

  updateMeters(): void;

  peakPowerForChannel(channelNumber: number): number;

  averagePowerForChannel(channelNumber: number): number;

  get channelAssignments(): NSArray;
  set channelAssignments(value: NSArray<interop.Object> | Array<interop.Object>);

  isPlaying(): boolean;

  setDelegate(delegate: AVAudioPlayerDelegate | null): void;

  setPan(pan: number): void;

  setVolume(volume: number): void;

  setEnableRate(enableRate: boolean): void;

  setRate(rate: number): void;

  setCurrentTime(currentTime: number): void;

  setNumberOfLoops(numberOfLoops: number): void;

  isMeteringEnabled(): boolean;

  setMeteringEnabled(meteringEnabled: boolean): void;

  setChannelAssignments(channelAssignments: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVAudioSession extends NSObject {
  static sharedInstance(): AVAudioSession;

  readonly availableCategories: NSArray;

  setCategoryError(category: string, outError: interop.PointerConvertible): boolean;

  setCategoryWithOptionsError(category: string, options: interop.Enum<typeof AVAudioSessionCategoryOptions>, outError: interop.PointerConvertible): boolean;

  setCategoryModeOptionsError(category: string, mode: string, options: interop.Enum<typeof AVAudioSessionCategoryOptions>, outError: interop.PointerConvertible): boolean;

  setCategoryModeRouteSharingPolicyOptionsError(category: string, mode: string, policy: interop.Enum<typeof AVAudioSessionRouteSharingPolicy>, options: interop.Enum<typeof AVAudioSessionCategoryOptions>, outError: interop.PointerConvertible): boolean;

  readonly category: string;

  readonly categoryOptions: interop.Enum<typeof AVAudioSessionCategoryOptions>;

  readonly routeSharingPolicy: interop.Enum<typeof AVAudioSessionRouteSharingPolicy>;

  readonly availableModes: NSArray;

  setModeError(mode: string, outError: interop.PointerConvertible): boolean;

  readonly mode: string;

  setAllowHapticsAndSystemSoundsDuringRecordingError(inValue: boolean, outError: interop.PointerConvertible): boolean;

  readonly allowHapticsAndSystemSoundsDuringRecording: boolean;

  readonly recordPermission: interop.Enum<typeof AVAudioSessionRecordPermission>;

  requestRecordPermission(response: (p1: boolean) => void): void;

  overrideOutputAudioPortError(portOverride: interop.Enum<typeof AVAudioSessionPortOverride>, outError: interop.PointerConvertible): boolean;

  setPreferredInputError(inPort: AVAudioSessionPortDescription | null, outError: interop.PointerConvertible): boolean;

  readonly preferredInput: AVAudioSessionPortDescription;

  setPrefersNoInterruptionsFromSystemAlertsError(inValue: boolean, outError: interop.PointerConvertible): boolean;

  readonly prefersNoInterruptionsFromSystemAlerts: boolean;

  readonly renderingMode: interop.Enum<typeof AVAudioSessionRenderingMode>;

  setPrefersEchoCancelledInputError(value: boolean, error: interop.PointerConvertible): boolean;

  readonly prefersEchoCancelledInput: boolean;

  readonly isEchoCancelledInputEnabled: boolean;

  readonly isEchoCancelledInputAvailable: boolean;

  setOutputMutedError(muted: boolean, outError: interop.PointerConvertible): boolean;

  readonly outputMuted: boolean;

  isOutputMuted(): boolean;

  setActiveError(active: boolean, outError: interop.PointerConvertible): boolean;

  setActiveWithOptionsError(active: boolean, options: interop.Enum<typeof AVAudioSessionSetActiveOptions>, outError: interop.PointerConvertible): boolean;

  setPreferredSampleRateError(sampleRate: number, outError: interop.PointerConvertible): boolean;

  readonly preferredSampleRate: number;

  setPreferredIOBufferDurationError(duration: number, outError: interop.PointerConvertible): boolean;

  readonly preferredIOBufferDuration: number;

  setPreferredInputNumberOfChannelsError(count: number, outError: interop.PointerConvertible): boolean;

  readonly preferredInputNumberOfChannels: number;

  setPreferredOutputNumberOfChannelsError(count: number, outError: interop.PointerConvertible): boolean;

  readonly preferredOutputNumberOfChannels: number;

  setPreferredInputOrientationError(orientation: interop.Enum<typeof AVAudioStereoOrientation>, outError: interop.PointerConvertible): boolean;

  readonly preferredInputOrientation: interop.Enum<typeof AVAudioStereoOrientation>;

  readonly inputOrientation: interop.Enum<typeof AVAudioStereoOrientation>;

  readonly maximumInputNumberOfChannels: number;

  readonly maximumOutputNumberOfChannels: number;

  setInputGainError(gain: number, outError: interop.PointerConvertible): boolean;

  readonly inputGain: number;

  readonly inputGainSettable: boolean;

  readonly inputAvailable: boolean;

  readonly inputDataSources: NSArray;

  readonly inputDataSource: AVAudioSessionDataSourceDescription;

  setInputDataSourceError(dataSource: AVAudioSessionDataSourceDescription | null, outError: interop.PointerConvertible): boolean;

  readonly outputDataSources: NSArray;

  readonly outputDataSource: AVAudioSessionDataSourceDescription;

  setOutputDataSourceError(dataSource: AVAudioSessionDataSourceDescription | null, outError: interop.PointerConvertible): boolean;

  readonly sampleRate: number;

  readonly inputNumberOfChannels: number;

  readonly outputNumberOfChannels: number;

  readonly inputLatency: number;

  readonly outputLatency: number;

  readonly IOBufferDuration: number;

  readonly supportedOutputChannelLayouts: NSArray;

  isInputGainSettable(): boolean;

  isInputAvailable(): boolean;

  readonly otherAudioPlaying: boolean;

  readonly secondaryAudioShouldBeSilencedHint: boolean;

  readonly outputVolume: number;

  readonly promptStyle: interop.Enum<typeof AVAudioSessionPromptStyle>;

  isOtherAudioPlaying(): boolean;

  readonly availableInputs: NSArray;

  readonly currentRoute: AVAudioSessionRouteDescription;

  setAggregatedIOPreferenceError(inIOType: interop.Enum<typeof AVAudioSessionIOType>, outError: interop.PointerConvertible): boolean;

  setSupportsMultichannelContentError(inValue: boolean, outError: interop.PointerConvertible): boolean;

  readonly supportsMultichannelContent: boolean;

  setPrefersInterruptionOnRouteDisconnectError(inValue: boolean, outError: interop.PointerConvertible): boolean;

  readonly prefersInterruptionOnRouteDisconnect: boolean;

  setPreferredMicrophoneInjectionModeError(inValue: interop.Enum<typeof AVAudioSessionMicrophoneInjectionMode>, outError: interop.PointerConvertible): boolean;

  readonly preferredMicrophoneInjectionMode: interop.Enum<typeof AVAudioSessionMicrophoneInjectionMode>;

  readonly isMicrophoneInjectionAvailable: boolean;

  delegate: AVAudioSessionDelegate;

  init(): this;

  setActiveWithFlagsError(active: boolean, flags: number, outError: interop.PointerConvertible): boolean;

  readonly inputIsAvailable: boolean;

  readonly currentHardwareSampleRate: number;

  readonly currentHardwareInputNumberOfChannels: number;

  readonly currentHardwareOutputNumberOfChannels: number;

  setPreferredHardwareSampleRateError(sampleRate: number, outError: interop.PointerConvertible): boolean;

  readonly preferredHardwareSampleRate: number;

  setDelegate(delegate: AVAudioSessionDelegate): void;

  prepareRouteSelectionForPlaybackWithCompletionHandler(completionHandler: (p1: boolean, p2: interop.Enum<typeof AVAudioSessionRouteSelection>) => void): void;
}

declare class AVAudioSessionDataSourceDescription extends NSObject {
  readonly dataSourceID: NSNumber;

  readonly dataSourceName: string;

  readonly location: string;

  readonly orientation: string;

  readonly supportedPolarPatterns: NSArray;

  readonly selectedPolarPattern: string;

  readonly preferredPolarPattern: string;

  setPreferredPolarPatternError(pattern: string | null, outError: interop.PointerConvertible): boolean;
}

declare class AVAudioMixerNode extends AVAudioNode implements AVAudioMixing {
  init(): this;

  outputVolume: number;

  readonly nextAvailableInputBus: number;

  setOutputVolume(outputVolume: number): void;

  destinationForMixerBus(mixer: AVAudioNode, bus: number): AVAudioMixingDestination;

  volume: number;

  setVolume(volume: number): void;

  pan: number;

  setPan(pan: number): void;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;

  renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>;

  sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>;

  pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>;

  rate: number;

  reverbBlend: number;

  obstruction: number;

  occlusion: number;

  position: AVAudio3DPoint;

  setRenderingAlgorithm(renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>): void;

  setSourceMode(sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>): void;

  setPointSourceInHeadMode(pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>): void;

  setRate(rate: number): void;

  setReverbBlend(reverbBlend: number): void;

  setObstruction(obstruction: number): void;

  setOcclusion(occlusion: number): void;

  setPosition(position: AVAudio3DPoint): void;
}

declare class AVAudioEnvironmentDistanceAttenuationParameters extends NSObject {
  distanceAttenuationModel: interop.Enum<typeof AVAudioEnvironmentDistanceAttenuationModel>;

  referenceDistance: number;

  maximumDistance: number;

  rolloffFactor: number;

  setDistanceAttenuationModel(distanceAttenuationModel: interop.Enum<typeof AVAudioEnvironmentDistanceAttenuationModel>): void;

  setReferenceDistance(referenceDistance: number): void;

  setMaximumDistance(maximumDistance: number): void;

  setRolloffFactor(rolloffFactor: number): void;
}

declare class AVAudioUnitReverb extends AVAudioUnitEffect {
  loadFactoryPreset(preset: interop.Enum<typeof AVAudioUnitReverbPreset>): void;

  wetDryMix: number;

  setWetDryMix(wetDryMix: number): void;
}

declare class AVAudioUnit extends AVAudioNode {
  static instantiateWithComponentDescriptionOptionsCompletionHandler(audioComponentDescription: AudioComponentDescription, options: interop.Enum<typeof AudioComponentInstantiationOptions>, completionHandler: (p1: AVAudioUnit, p2: NSError) => void | null): void;

  loadAudioUnitPresetAtURLError(url: NSURL, outError: interop.PointerConvertible): boolean;

  readonly audioComponentDescription: AudioComponentDescription;

  readonly audioUnit: interop.Pointer;

  readonly AUAudioUnit: AUAudioUnit;

  readonly name: string;

  readonly manufacturerName: string;

  readonly version: number;
}

declare class AVAudioOutputNode extends AVAudioIONode {
}

declare class AVAudioConverter extends NSObject {
  initFromFormatToFormat(fromFormat: AVAudioFormat, toFormat: AVAudioFormat): this;

  reset(): void;

  readonly inputFormat: AVAudioFormat;

  readonly outputFormat: AVAudioFormat;

  get channelMap(): NSArray;
  set channelMap(value: NSArray<interop.Object> | Array<interop.Object>);

  magicCookie: NSData;

  downmix: boolean;

  dither: boolean;

  sampleRateConverterQuality: number;

  sampleRateConverterAlgorithm: string;

  primeMethod: interop.Enum<typeof AVAudioConverterPrimeMethod>;

  primeInfo: AVAudioConverterPrimeInfo;

  audioSyncPacketFrequency: number;

  contentSource: interop.Enum<typeof AVAudioContentSource>;

  dynamicRangeControlConfiguration: interop.Enum<typeof AVAudioDynamicRangeControlConfiguration>;

  convertToBufferFromBufferError(outputBuffer: AVAudioPCMBuffer, inputBuffer: AVAudioPCMBuffer, outError: interop.PointerConvertible): boolean;

  convertToBufferErrorWithInputFromBlock(outputBuffer: AVAudioBuffer, outError: interop.PointerConvertible, inputBlock: (p1: number, p2: interop.PointerConvertible) => AVAudioBuffer): interop.Enum<typeof AVAudioConverterOutputStatus>;

  setChannelMap(channelMap: NSArray<interop.Object> | Array<interop.Object>): void;

  setMagicCookie(magicCookie: NSData | null): void;

  setDownmix(downmix: boolean): void;

  setDither(dither: boolean): void;

  setSampleRateConverterQuality(sampleRateConverterQuality: number): void;

  setSampleRateConverterAlgorithm(sampleRateConverterAlgorithm: string | null): void;

  setPrimeMethod(primeMethod: interop.Enum<typeof AVAudioConverterPrimeMethod>): void;

  setPrimeInfo(primeInfo: AVAudioConverterPrimeInfo): void;

  setAudioSyncPacketFrequency(audioSyncPacketFrequency: number): void;

  setContentSource(contentSource: interop.Enum<typeof AVAudioContentSource>): void;

  setDynamicRangeControlConfiguration(dynamicRangeControlConfiguration: interop.Enum<typeof AVAudioDynamicRangeControlConfiguration>): void;

  bitRate: number;

  bitRateStrategy: string;

  readonly maximumOutputPacketSize: number;

  readonly availableEncodeBitRates: NSArray;

  readonly applicableEncodeBitRates: NSArray;

  readonly availableEncodeSampleRates: NSArray;

  readonly applicableEncodeSampleRates: NSArray;

  readonly availableEncodeChannelLayoutTags: NSArray;

  setBitRate(bitRate: number): void;

  setBitRateStrategy(bitRateStrategy: string | null): void;
}

declare class AVAudioChannelLayout extends NSObject implements NSSecureCoding {
  initWithLayoutTag(layoutTag: number): this;

  initWithLayout(layout: interop.PointerConvertible): this;

  isEqual(object: interop.Object): boolean;

  static layoutWithLayoutTag<This extends abstract new (...args: any) => any>(this: This, layoutTag: number): InstanceType<This>;

  static layoutWithLayout<This extends abstract new (...args: any) => any>(this: This, layout: interop.PointerConvertible): InstanceType<This>;

  readonly layoutTag: number;

  readonly layout: interop.Pointer;

  readonly channelCount: number;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVMIDIMetaEvent extends AVMusicEvent {
  initWithTypeData(type: interop.Enum<typeof AVMIDIMetaEventType>, data: NSData): this;

  readonly type: interop.Enum<typeof AVMIDIMetaEventType>;
}

declare class AVAudioSessionPortExtensionBluetoothMicrophone extends NSObject {
  readonly highQualityRecording: AVAudioSessionCapability;

  readonly farFieldCapture: AVAudioSessionCapability;
}

declare class AVMIDINoteEvent extends AVMusicEvent {
  initWithChannelKeyVelocityDuration(channel: number, keyNum: number, velocity: number, duration: number): this;

  channel: number;

  key: number;

  velocity: number;

  duration: number;

  setChannel(channel: number): void;

  setKey(key: number): void;

  setVelocity(velocity: number): void;

  setDuration(duration: number): void;
}

declare class AVAudioNode extends NSObject {
  reset(): void;

  inputFormatForBus(bus: number): AVAudioFormat;

  outputFormatForBus(bus: number): AVAudioFormat;

  nameForInputBus(bus: number): string;

  nameForOutputBus(bus: number): string;

  installTapOnBusBufferSizeFormatBlock(bus: number, bufferSize: number, format: AVAudioFormat | null, tapBlock: (p1: AVAudioPCMBuffer, p2: AVAudioTime) => void): void;

  removeTapOnBus(bus: number): void;

  readonly engine: AVAudioEngine;

  readonly numberOfInputs: number;

  readonly numberOfOutputs: number;

  readonly lastRenderTime: AVAudioTime;

  readonly AUAudioUnit: AUAudioUnit;

  readonly latency: number;

  readonly outputPresentationLatency: number;
}

declare class AVSpeechSynthesisMarker extends NSObject implements NSSecureCoding, NSCopying {
  mark: interop.Enum<typeof AVSpeechSynthesisMarkerMark>;

  byteSampleOffset: number;

  textRange: _NSRange;

  bookmarkName: string;

  phoneme: string;

  initWithMarkerTypeForTextRangeAtByteSampleOffset(type: interop.Enum<typeof AVSpeechSynthesisMarkerMark>, range: _NSRange, byteSampleOffset: number): this;

  initWithWordRangeAtByteSampleOffset(range: _NSRange, byteSampleOffset: number): this;

  initWithSentenceRangeAtByteSampleOffset(range: _NSRange, byteSampleOffset: number): this;

  initWithParagraphRangeAtByteSampleOffset(range: _NSRange, byteSampleOffset: number): this;

  initWithPhonemeStringAtByteSampleOffset(phoneme: string, byteSampleOffset: number): this;

  initWithBookmarkNameAtByteSampleOffset(mark: string, byteSampleOffset: number): this;

  setMark(mark: interop.Enum<typeof AVSpeechSynthesisMarkerMark>): void;

  setByteSampleOffset(byteSampleOffset: number): void;

  setTextRange(textRange: _NSRange): void;

  setBookmarkName(bookmarkName: string): void;

  setPhoneme(phoneme: string): void;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAudioSequencer extends NSObject {
  init(): this;

  initWithAudioEngine(engine: AVAudioEngine): this;

  loadFromURLOptionsError(fileURL: NSURL, options: interop.Enum<typeof AVMusicSequenceLoadOptions>, outError: interop.PointerConvertible): boolean;

  loadFromDataOptionsError(data: NSData, options: interop.Enum<typeof AVMusicSequenceLoadOptions>, outError: interop.PointerConvertible): boolean;

  writeToURLSMPTEResolutionReplaceExistingError(fileURL: NSURL, resolution: number, replace: boolean, outError: interop.PointerConvertible): boolean;

  dataWithSMPTEResolutionError(SMPTEResolution: number, outError: interop.PointerConvertible): NSData;

  secondsForBeats(beats: number): number;

  beatsForSeconds(seconds: number): number;

  reverseEvents(): void;

  createAndAppendTrack(): AVMusicTrack;

  removeTrack(track: AVMusicTrack): boolean;

  setUserCallback(userCallback: (p1: AVMusicTrack, p2: NSData, p3: number) => void | null): void;

  readonly tracks: NSArray;

  readonly tempoTrack: AVMusicTrack;

  readonly userInfo: NSDictionary;

  currentPositionInSeconds: number;

  currentPositionInBeats: number;

  readonly playing: boolean;

  rate: number;

  hostTimeForBeatsError(inBeats: number, outError: interop.PointerConvertible): number;

  beatsForHostTimeError(inHostTime: number, outError: interop.PointerConvertible): number;

  prepareToPlay(): void;

  startAndReturnError(outError: interop.PointerConvertible): boolean;

  stop(): void;

  setCurrentPositionInSeconds(currentPositionInSeconds: number): void;

  setCurrentPositionInBeats(currentPositionInBeats: number): void;

  isPlaying(): boolean;

  setRate(rate: number): void;
}

declare class AVAudioIONode extends AVAudioNode {
  readonly presentationLatency: number;

  readonly audioUnit: interop.Pointer;

  readonly voiceProcessingEnabled: boolean;

  setVoiceProcessingEnabledError(enabled: boolean, outError: interop.PointerConvertible): boolean;

  isVoiceProcessingEnabled(): boolean;
}

declare class AVSpeechSynthesisVoice extends NSObject implements NSSecureCoding {
  static speechVoices(): NSArray;

  static currentLanguageCode(): string;

  static voiceWithLanguage(languageCode: string | null): AVSpeechSynthesisVoice;

  static voiceWithIdentifier(identifier: string): AVSpeechSynthesisVoice;

  readonly language: string;

  readonly identifier: string;

  readonly name: string;

  readonly quality: interop.Enum<typeof AVSpeechSynthesisVoiceQuality>;

  readonly gender: interop.Enum<typeof AVSpeechSynthesisVoiceGender>;

  readonly audioFileSettings: NSDictionary;

  readonly voiceTraits: interop.Enum<typeof AVSpeechSynthesisVoiceTraits>;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVAudioUnitSampler extends AVAudioUnitMIDIInstrument {
  loadSoundBankInstrumentAtURLProgramBankMSBBankLSBError(bankURL: NSURL, program: number, bankMSB: number, bankLSB: number, outError: interop.PointerConvertible): boolean;

  loadInstrumentAtURLError(instrumentURL: NSURL, outError: interop.PointerConvertible): boolean;

  loadAudioFilesAtURLsError(audioFiles: NSArray<interop.Object> | Array<interop.Object>, outError: interop.PointerConvertible): boolean;

  stereoPan: number;

  overallGain: number;

  masterGain: number;

  globalTuning: number;

  setStereoPan(stereoPan: number): void;

  setOverallGain(overallGain: number): void;

  setMasterGain(masterGain: number): void;

  setGlobalTuning(globalTuning: number): void;
}

declare class AVAudioEnvironmentNode extends AVAudioNode implements AVAudioMixing {
  init(): this;

  outputType: interop.Enum<typeof AVAudioEnvironmentOutputType>;

  outputVolume: number;

  readonly nextAvailableInputBus: number;

  listenerPosition: AVAudio3DPoint;

  listenerVectorOrientation: AVAudio3DVectorOrientation;

  listenerAngularOrientation: AVAudio3DAngularOrientation;

  readonly distanceAttenuationParameters: AVAudioEnvironmentDistanceAttenuationParameters;

  readonly reverbParameters: AVAudioEnvironmentReverbParameters;

  readonly applicableRenderingAlgorithms: NSArray;

  listenerHeadTrackingEnabled: boolean;

  setOutputType(outputType: interop.Enum<typeof AVAudioEnvironmentOutputType>): void;

  setOutputVolume(outputVolume: number): void;

  setListenerPosition(listenerPosition: AVAudio3DPoint): void;

  setListenerVectorOrientation(listenerVectorOrientation: AVAudio3DVectorOrientation): void;

  setListenerAngularOrientation(listenerAngularOrientation: AVAudio3DAngularOrientation): void;

  isListenerHeadTrackingEnabled(): boolean;

  setListenerHeadTrackingEnabled(listenerHeadTrackingEnabled: boolean): void;

  destinationForMixerBus(mixer: AVAudioNode, bus: number): AVAudioMixingDestination;

  volume: number;

  setVolume(volume: number): void;

  pan: number;

  setPan(pan: number): void;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;

  renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>;

  sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>;

  pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>;

  rate: number;

  reverbBlend: number;

  obstruction: number;

  occlusion: number;

  position: AVAudio3DPoint;

  setRenderingAlgorithm(renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>): void;

  setSourceMode(sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>): void;

  setPointSourceInHeadMode(pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>): void;

  setRate(rate: number): void;

  setReverbBlend(reverbBlend: number): void;

  setObstruction(obstruction: number): void;

  setOcclusion(occlusion: number): void;

  setPosition(position: AVAudio3DPoint): void;
}

declare class AVAudioSessionRouteDescription extends NSObject {
  readonly inputs: NSArray;

  readonly outputs: NSArray;
}

declare class AVSpeechSynthesisProviderVoice extends NSObject implements NSSecureCoding, NSCopying {
  readonly name: string;

  readonly identifier: string;

  readonly primaryLanguages: NSArray;

  readonly supportedLanguages: NSArray;

  voiceSize: number;

  version: string;

  gender: interop.Enum<typeof AVSpeechSynthesisVoiceGender>;

  age: number;

  initWithNameIdentifierPrimaryLanguagesSupportedLanguages(name: string, identifier: string, primaryLanguages: NSArray<interop.Object> | Array<interop.Object>, supportedLanguages: NSArray<interop.Object> | Array<interop.Object>): this;

  static updateSpeechVoices(): void;

  setVoiceSize(voiceSize: number): void;

  setVersion(version: string): void;

  setGender(gender: interop.Enum<typeof AVSpeechSynthesisVoiceGender>): void;

  setAge(age: number): void;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVSpeechSynthesisProviderRequest extends NSObject implements NSSecureCoding, NSCopying {
  readonly ssmlRepresentation: string;

  readonly voice: AVSpeechSynthesisProviderVoice;

  initWithSSMLRepresentationVoice(text: string, voice: AVSpeechSynthesisProviderVoice): this;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAudioUnitDistortion extends AVAudioUnitEffect {
  loadFactoryPreset(preset: interop.Enum<typeof AVAudioUnitDistortionPreset>): void;

  preGain: number;

  wetDryMix: number;

  setPreGain(preGain: number): void;

  setWetDryMix(wetDryMix: number): void;
}

declare class AVAudioUnitComponent extends NSObject {
  readonly name: string;

  readonly typeName: string;

  readonly localizedTypeName: string;

  readonly manufacturerName: string;

  readonly version: number;

  readonly versionString: string;

  readonly sandboxSafe: boolean;

  readonly hasMIDIInput: boolean;

  readonly hasMIDIOutput: boolean;

  readonly audioComponent: interop.Pointer;

  readonly allTagNames: NSArray;

  readonly audioComponentDescription: AudioComponentDescription;

  readonly icon: UIImage;

  readonly passesAUVal: boolean;

  readonly configurationDictionary: NSDictionary;

  isSandboxSafe(): boolean;
}

declare class AVAudioFormat extends NSObject implements NSSecureCoding {
  initWithStreamDescription(asbd: interop.PointerConvertible): this;

  initWithStreamDescriptionChannelLayout(asbd: interop.PointerConvertible, layout: AVAudioChannelLayout | null): this;

  initStandardFormatWithSampleRateChannels(sampleRate: number, channels: number): this;

  initStandardFormatWithSampleRateChannelLayout(sampleRate: number, layout: AVAudioChannelLayout): this;

  initWithCommonFormatSampleRateChannelsInterleaved(format: interop.Enum<typeof AVAudioCommonFormat>, sampleRate: number, channels: number, interleaved: boolean): this;

  initWithCommonFormatSampleRateInterleavedChannelLayout(format: interop.Enum<typeof AVAudioCommonFormat>, sampleRate: number, interleaved: boolean, layout: AVAudioChannelLayout): this;

  initWithSettings(settings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  initWithCMAudioFormatDescription(formatDescription: interop.PointerConvertible): this;

  isEqual(object: interop.Object): boolean;

  readonly standard: boolean;

  readonly commonFormat: interop.Enum<typeof AVAudioCommonFormat>;

  readonly channelCount: number;

  readonly sampleRate: number;

  readonly interleaved: boolean;

  readonly streamDescription: interop.Pointer;

  readonly channelLayout: AVAudioChannelLayout;

  magicCookie: NSData;

  readonly settings: NSDictionary;

  readonly formatDescription: interop.Pointer;

  isStandard(): boolean;

  isInterleaved(): boolean;

  setMagicCookie(magicCookie: NSData | null): void;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVAudioUnitVarispeed extends AVAudioUnitTimeEffect {
  rate: number;

  setRate(rate: number): void;
}

declare class AVMusicTrack extends NSObject {
  destinationAudioUnit: AVAudioUnit;

  destinationMIDIEndpoint: number;

  loopRange: _AVBeatRange;

  loopingEnabled: boolean;

  numberOfLoops: number;

  offsetTime: number;

  muted: boolean;

  soloed: boolean;

  lengthInBeats: number;

  lengthInSeconds: number;

  readonly timeResolution: number;

  setDestinationAudioUnit(destinationAudioUnit: AVAudioUnit | null): void;

  setDestinationMIDIEndpoint(destinationMIDIEndpoint: number): void;

  setLoopRange(loopRange: _AVBeatRange): void;

  isLoopingEnabled(): boolean;

  setLoopingEnabled(loopingEnabled: boolean): void;

  setNumberOfLoops(numberOfLoops: number): void;

  setOffsetTime(offsetTime: number): void;

  isMuted(): boolean;

  setMuted(muted: boolean): void;

  isSoloed(): boolean;

  setSoloed(soloed: boolean): void;

  setLengthInBeats(lengthInBeats: number): void;

  setLengthInSeconds(lengthInSeconds: number): void;

  usesAutomatedParameters: boolean;

  addEventAtBeat(event: AVMusicEvent, beat: number): void;

  moveEventsInRangeByAmount(range: _AVBeatRange, beatAmount: number): void;

  clearEventsInRange(range: _AVBeatRange): void;

  cutEventsInRange(range: _AVBeatRange): void;

  copyEventsInRangeFromTrackInsertAtBeat(range: _AVBeatRange, sourceTrack: AVMusicTrack, insertStartBeat: number): void;

  copyAndMergeEventsInRangeFromTrackMergeAtBeat(range: _AVBeatRange, sourceTrack: AVMusicTrack, mergeStartBeat: number): void;

  enumerateEventsInRangeUsingBlock(range: _AVBeatRange, block: (p1: AVMusicEvent, p2: interop.PointerConvertible, p3: interop.PointerConvertible) => void): void;

  setUsesAutomatedParameters(usesAutomatedParameters: boolean): void;
}

declare class AVAudioSinkNode extends AVAudioNode {
  initWithReceiverBlock(block: (p1: interop.PointerConvertible, p2: number, p3: interop.PointerConvertible) => number): this;
}

declare class AVAudioUnitTimeEffect extends AVAudioUnit {
  initWithAudioComponentDescription(audioComponentDescription: AudioComponentDescription): this;

  bypass: boolean;

  setBypass(bypass: boolean): void;
}

declare class AVSpeechSynthesizer extends NSObject {
  delegate: AVSpeechSynthesizerDelegate;

  readonly speaking: boolean;

  readonly paused: boolean;

  speakUtterance(utterance: AVSpeechUtterance): void;

  writeUtteranceToBufferCallback(utterance: AVSpeechUtterance, bufferCallback: (p1: AVAudioBuffer) => void): void;

  writeUtteranceToBufferCallbackToMarkerCallback(utterance: AVSpeechUtterance, bufferCallback: (p1: AVAudioBuffer) => void, markerCallback: (p1: NSArray<interop.Object> | Array<interop.Object>) => void): void;

  stopSpeakingAtBoundary(boundary: interop.Enum<typeof AVSpeechBoundary>): boolean;

  pauseSpeakingAtBoundary(boundary: interop.Enum<typeof AVSpeechBoundary>): boolean;

  continueSpeaking(): boolean;

  get outputChannels(): NSArray;
  set outputChannels(value: NSArray<interop.Object> | Array<interop.Object>);

  usesApplicationAudioSession: boolean;

  mixToTelephonyUplink: boolean;

  static requestPersonalVoiceAuthorizationWithCompletionHandler(handler: (p1: interop.Enum<typeof AVSpeechSynthesisPersonalVoiceAuthorizationStatus>) => void): void;

  static readonly personalVoiceAuthorizationStatus: interop.Enum<typeof AVSpeechSynthesisPersonalVoiceAuthorizationStatus>;

  setDelegate(delegate: AVSpeechSynthesizerDelegate | null): void;

  isSpeaking(): boolean;

  isPaused(): boolean;

  setOutputChannels(outputChannels: NSArray<interop.Object> | Array<interop.Object>): void;

  setUsesApplicationAudioSession(usesApplicationAudioSession: boolean): void;

  setMixToTelephonyUplink(mixToTelephonyUplink: boolean): void;
}

declare class AVAudioUnitEQ extends AVAudioUnitEffect {
  initWithNumberOfBands(numberOfBands: number): this;

  readonly bands: NSArray;

  globalGain: number;

  setGlobalGain(globalGain: number): void;
}

declare class AVAudioInputNode extends AVAudioIONode implements AVAudioMixing {
  setManualRenderingInputPCMFormatInputBlock(format: AVAudioFormat, block: (p1: number) => interop.Pointer): boolean;

  voiceProcessingBypassed: boolean;

  voiceProcessingAGCEnabled: boolean;

  voiceProcessingInputMuted: boolean;

  setMutedSpeechActivityEventListener(listenerBlock: (p1: interop.Enum<typeof AVAudioVoiceProcessingSpeechActivityEvent>) => void | null): boolean;

  voiceProcessingOtherAudioDuckingConfiguration: AVAudioVoiceProcessingOtherAudioDuckingConfiguration;

  isVoiceProcessingBypassed(): boolean;

  setVoiceProcessingBypassed(voiceProcessingBypassed: boolean): void;

  isVoiceProcessingAGCEnabled(): boolean;

  setVoiceProcessingAGCEnabled(voiceProcessingAGCEnabled: boolean): void;

  isVoiceProcessingInputMuted(): boolean;

  setVoiceProcessingInputMuted(voiceProcessingInputMuted: boolean): void;

  setVoiceProcessingOtherAudioDuckingConfiguration(voiceProcessingOtherAudioDuckingConfiguration: AVAudioVoiceProcessingOtherAudioDuckingConfiguration): void;

  destinationForMixerBus(mixer: AVAudioNode, bus: number): AVAudioMixingDestination;

  volume: number;

  setVolume(volume: number): void;

  pan: number;

  setPan(pan: number): void;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;

  renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>;

  sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>;

  pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>;

  rate: number;

  reverbBlend: number;

  obstruction: number;

  occlusion: number;

  position: AVAudio3DPoint;

  setRenderingAlgorithm(renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>): void;

  setSourceMode(sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>): void;

  setPointSourceInHeadMode(pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>): void;

  setRate(rate: number): void;

  setReverbBlend(reverbBlend: number): void;

  setObstruction(obstruction: number): void;

  setOcclusion(occlusion: number): void;

  setPosition(position: AVAudio3DPoint): void;
}

declare class AVAudioFile extends NSObject {
  init(): this;

  initForReadingError(fileURL: NSURL, outError: interop.PointerConvertible): this;

  initForReadingCommonFormatInterleavedError(fileURL: NSURL, format: interop.Enum<typeof AVAudioCommonFormat>, interleaved: boolean, outError: interop.PointerConvertible): this;

  initForWritingSettingsError(fileURL: NSURL, settings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, outError: interop.PointerConvertible): this;

  initForWritingSettingsCommonFormatInterleavedError(fileURL: NSURL, settings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, format: interop.Enum<typeof AVAudioCommonFormat>, interleaved: boolean, outError: interop.PointerConvertible): this;

  close(): void;

  readIntoBufferError(buffer: AVAudioPCMBuffer, outError: interop.PointerConvertible): boolean;

  readIntoBufferFrameCountError(buffer: AVAudioPCMBuffer, frames: number, outError: interop.PointerConvertible): boolean;

  writeFromBufferError(buffer: AVAudioPCMBuffer, outError: interop.PointerConvertible): boolean;

  readonly isOpen: boolean;

  readonly url: NSURL;

  readonly fileFormat: AVAudioFormat;

  readonly processingFormat: AVAudioFormat;

  readonly length: number;

  framePosition: number;

  setFramePosition(framePosition: number): void;
}

declare class AVAudioCompressedBuffer extends AVAudioBuffer {
  initWithFormatPacketCapacityMaximumPacketSize(format: AVAudioFormat, packetCapacity: number, maximumPacketSize: number): this;

  initWithFormatPacketCapacity(format: AVAudioFormat, packetCapacity: number): this;

  readonly packetCapacity: number;

  packetCount: number;

  readonly maximumPacketSize: number;

  readonly data: interop.Pointer;

  readonly byteCapacity: number;

  byteLength: number;

  readonly packetDescriptions: interop.Pointer;

  readonly packetDependencies: interop.Pointer;

  setPacketCount(packetCount: number): void;

  setByteLength(byteLength: number): void;
}

declare class AVSpeechSynthesisProviderAudioUnit extends AUAudioUnit {
  get speechVoices(): NSArray;
  set speechVoices(value: NSArray<interop.Object> | Array<interop.Object>);

  speechSynthesisOutputMetadataBlock: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: AVSpeechSynthesisProviderRequest) => void;

  synthesizeSpeechRequest(speechRequest: AVSpeechSynthesisProviderRequest): void;

  cancelSpeechRequest(): void;

  setSpeechVoices(speechVoices: NSArray<interop.Object> | Array<interop.Object>): void;

  setSpeechSynthesisOutputMetadataBlock(speechSynthesisOutputMetadataBlock: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: AVSpeechSynthesisProviderRequest) => void | null): void;
}

declare class AVExtendedNoteOnEvent extends AVMusicEvent {
  initWithMIDINoteVelocityGroupIDDuration(midiNote: number, velocity: number, groupID: number, duration: number): this;

  initWithMIDINoteVelocityInstrumentIDGroupIDDuration(midiNote: number, velocity: number, instrumentID: number, groupID: number, duration: number): this;

  midiNote: number;

  velocity: number;

  instrumentID: number;

  groupID: number;

  duration: number;

  setMidiNote(midiNote: number): void;

  setVelocity(velocity: number): void;

  setInstrumentID(instrumentID: number): void;

  setGroupID(groupID: number): void;

  setDuration(duration: number): void;
}

declare class AVAudioPCMBuffer extends AVAudioBuffer {
  initWithPCMFormatFrameCapacity(format: AVAudioFormat, frameCapacity: number): this;

  initWithPCMFormatBufferListNoCopyDeallocator(format: AVAudioFormat, bufferList: interop.PointerConvertible, deallocator: (p1: interop.PointerConvertible) => void | null): this;

  readonly frameCapacity: number;

  frameLength: number;

  readonly stride: number;

  readonly floatChannelData: interop.Pointer;

  readonly int16ChannelData: interop.Pointer;

  readonly int32ChannelData: interop.Pointer;

  setFrameLength(frameLength: number): void;
}

declare class AVAudioTime extends NSObject {
  initWithAudioTimeStampSampleRate(ts: interop.PointerConvertible, sampleRate: number): this;

  initWithHostTime(hostTime: number): this;

  initWithSampleTimeAtRate(sampleTime: number, sampleRate: number): this;

  initWithHostTimeSampleTimeAtRate(hostTime: number, sampleTime: number, sampleRate: number): this;

  static timeWithAudioTimeStampSampleRate<This extends abstract new (...args: any) => any>(this: This, ts: interop.PointerConvertible, sampleRate: number): InstanceType<This>;

  static timeWithHostTime<This extends abstract new (...args: any) => any>(this: This, hostTime: number): InstanceType<This>;

  static timeWithSampleTimeAtRate<This extends abstract new (...args: any) => any>(this: This, sampleTime: number, sampleRate: number): InstanceType<This>;

  static timeWithHostTimeSampleTimeAtRate<This extends abstract new (...args: any) => any>(this: This, hostTime: number, sampleTime: number, sampleRate: number): InstanceType<This>;

  static hostTimeForSeconds(seconds: number): number;

  static secondsForHostTime(hostTime: number): number;

  extrapolateTimeFromAnchor(anchorTime: AVAudioTime): AVAudioTime;

  readonly hostTimeValid: boolean;

  readonly hostTime: number;

  readonly sampleTimeValid: boolean;

  readonly sampleTime: number;

  readonly sampleRate: number;

  readonly audioTimeStamp: AudioTimeStamp;

  isHostTimeValid(): boolean;

  isSampleTimeValid(): boolean;
}

declare class AVAudioPlayerNode extends AVAudioNode implements AVAudioMixing {
  init(): this;

  scheduleBufferCompletionHandler(buffer: AVAudioPCMBuffer, completionHandler: () => void | null): void;

  scheduleBufferCompletionCallbackTypeCompletionHandler(buffer: AVAudioPCMBuffer, callbackType: interop.Enum<typeof AVAudioPlayerNodeCompletionCallbackType>, completionHandler: (p1: interop.Enum<typeof AVAudioPlayerNodeCompletionCallbackType>) => void | null): void;

  scheduleBufferAtTimeOptionsCompletionHandler(buffer: AVAudioPCMBuffer, when: AVAudioTime | null, options: interop.Enum<typeof AVAudioPlayerNodeBufferOptions>, completionHandler: () => void | null): void;

  scheduleBufferAtTimeOptionsCompletionCallbackTypeCompletionHandler(buffer: AVAudioPCMBuffer, when: AVAudioTime | null, options: interop.Enum<typeof AVAudioPlayerNodeBufferOptions>, callbackType: interop.Enum<typeof AVAudioPlayerNodeCompletionCallbackType>, completionHandler: (p1: interop.Enum<typeof AVAudioPlayerNodeCompletionCallbackType>) => void | null): void;

  scheduleFileAtTimeCompletionHandler(file: AVAudioFile, when: AVAudioTime | null, completionHandler: () => void | null): void;

  scheduleFileAtTimeCompletionCallbackTypeCompletionHandler(file: AVAudioFile, when: AVAudioTime | null, callbackType: interop.Enum<typeof AVAudioPlayerNodeCompletionCallbackType>, completionHandler: (p1: interop.Enum<typeof AVAudioPlayerNodeCompletionCallbackType>) => void | null): void;

  scheduleSegmentStartingFrameFrameCountAtTimeCompletionHandler(file: AVAudioFile, startFrame: number, numberFrames: number, when: AVAudioTime | null, completionHandler: () => void | null): void;

  scheduleSegmentStartingFrameFrameCountAtTimeCompletionCallbackTypeCompletionHandler(file: AVAudioFile, startFrame: number, numberFrames: number, when: AVAudioTime | null, callbackType: interop.Enum<typeof AVAudioPlayerNodeCompletionCallbackType>, completionHandler: (p1: interop.Enum<typeof AVAudioPlayerNodeCompletionCallbackType>) => void | null): void;

  stop(): void;

  prepareWithFrameCount(frameCount: number): void;

  play(): void;

  playAtTime(when: AVAudioTime | null): void;

  pause(): void;

  nodeTimeForPlayerTime(playerTime: AVAudioTime): AVAudioTime | null;

  playerTimeForNodeTime(nodeTime: AVAudioTime): AVAudioTime | null;

  readonly playing: boolean;

  isPlaying(): boolean;

  destinationForMixerBus(mixer: AVAudioNode, bus: number): AVAudioMixingDestination;

  volume: number;

  setVolume(volume: number): void;

  pan: number;

  setPan(pan: number): void;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;

  renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>;

  sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>;

  pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>;

  rate: number;

  reverbBlend: number;

  obstruction: number;

  occlusion: number;

  position: AVAudio3DPoint;

  setRenderingAlgorithm(renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>): void;

  setSourceMode(sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>): void;

  setPointSourceInHeadMode(pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>): void;

  setRate(rate: number): void;

  setReverbBlend(reverbBlend: number): void;

  setObstruction(obstruction: number): void;

  setOcclusion(occlusion: number): void;

  setPosition(position: AVAudio3DPoint): void;
}

declare class AVAudioMixingDestination extends NSObject implements AVAudioMixing {
  readonly connectionPoint: AVAudioConnectionPoint;

  destinationForMixerBus(mixer: AVAudioNode, bus: number): AVAudioMixingDestination;

  volume: number;

  setVolume(volume: number): void;

  pan: number;

  setPan(pan: number): void;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;

  renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>;

  sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>;

  pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>;

  rate: number;

  reverbBlend: number;

  obstruction: number;

  occlusion: number;

  position: AVAudio3DPoint;

  setRenderingAlgorithm(renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>): void;

  setSourceMode(sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>): void;

  setPointSourceInHeadMode(pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>): void;

  setRate(rate: number): void;

  setReverbBlend(reverbBlend: number): void;

  setObstruction(obstruction: number): void;

  setOcclusion(occlusion: number): void;

  setPosition(position: AVAudio3DPoint): void;
}

declare class AVAudioUnitGenerator extends AVAudioUnit implements AVAudioMixing {
  initWithAudioComponentDescription(audioComponentDescription: AudioComponentDescription): this;

  bypass: boolean;

  setBypass(bypass: boolean): void;

  destinationForMixerBus(mixer: AVAudioNode, bus: number): AVAudioMixingDestination;

  volume: number;

  setVolume(volume: number): void;

  pan: number;

  setPan(pan: number): void;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;

  renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>;

  sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>;

  pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>;

  rate: number;

  reverbBlend: number;

  obstruction: number;

  occlusion: number;

  position: AVAudio3DPoint;

  setRenderingAlgorithm(renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>): void;

  setSourceMode(sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>): void;

  setPointSourceInHeadMode(pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>): void;

  setRate(rate: number): void;

  setReverbBlend(reverbBlend: number): void;

  setObstruction(obstruction: number): void;

  setOcclusion(occlusion: number): void;

  setPosition(position: AVAudio3DPoint): void;
}

declare class AVAudioRecorder extends NSObject {
  initWithURLSettingsError(url: NSURL, settings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, outError: interop.PointerConvertible): this;

  initWithURLFormatError(url: NSURL, format: AVAudioFormat, outError: interop.PointerConvertible): this;

  prepareToRecord(): boolean;

  record(): boolean;

  recordAtTime(time: number): boolean;

  recordForDuration(duration: number): boolean;

  recordAtTimeForDuration(time: number, duration: number): boolean;

  pause(): void;

  stop(): void;

  deleteRecording(): boolean;

  readonly recording: boolean;

  readonly url: NSURL;

  readonly settings: NSDictionary;

  readonly format: AVAudioFormat;

  delegate: AVAudioRecorderDelegate;

  readonly currentTime: number;

  readonly deviceCurrentTime: number;

  meteringEnabled: boolean;

  updateMeters(): void;

  peakPowerForChannel(channelNumber: number): number;

  averagePowerForChannel(channelNumber: number): number;

  get channelAssignments(): NSArray;
  set channelAssignments(value: NSArray<interop.Object> | Array<interop.Object>);

  isRecording(): boolean;

  setDelegate(delegate: AVAudioRecorderDelegate | null): void;

  isMeteringEnabled(): boolean;

  setMeteringEnabled(meteringEnabled: boolean): void;

  setChannelAssignments(channelAssignments: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVAudioConnectionPoint extends NSObject {
  initWithNodeBus(node: AVAudioNode, bus: number): this;

  readonly node: AVAudioNode | null;

  readonly bus: number;
}

declare class AVAudioSessionCapability extends NSObject {
  readonly supported: boolean;

  readonly enabled: boolean;

  isSupported(): boolean;

  isEnabled(): boolean;
}

declare class AVAudioUnitEffect extends AVAudioUnit {
  initWithAudioComponentDescription(audioComponentDescription: AudioComponentDescription): this;

  bypass: boolean;

  setBypass(bypass: boolean): void;
}

declare class AVAudioEngine extends NSObject {
  init(): this;

  attachNode(node: AVAudioNode): void;

  detachNode(node: AVAudioNode): void;

  connectToFromBusToBusFormat(node1: AVAudioNode, node2: AVAudioNode, bus1: number, bus2: number, format: AVAudioFormat | null): void;

  connectToFormat(node1: AVAudioNode, node2: AVAudioNode, format: AVAudioFormat | null): void;

  connectToConnectionPointsFromBusFormat(sourceNode: AVAudioNode, destNodes: NSArray<interop.Object> | Array<interop.Object>, sourceBus: number, format: AVAudioFormat | null): void;

  disconnectNodeInputBus(node: AVAudioNode, bus: number): void;

  disconnectNodeInput(node: AVAudioNode): void;

  disconnectNodeOutputBus(node: AVAudioNode, bus: number): void;

  disconnectNodeOutput(node: AVAudioNode): void;

  prepare(): void;

  startAndReturnError(outError: interop.PointerConvertible): boolean;

  pause(): void;

  reset(): void;

  stop(): void;

  inputConnectionPointForNodeInputBus(node: AVAudioNode, bus: number): AVAudioConnectionPoint | null;

  outputConnectionPointsForNodeOutputBus(node: AVAudioNode, bus: number): NSArray;

  get musicSequence(): interop.Pointer;
  set musicSequence(value: interop.PointerConvertible);

  readonly outputNode: AVAudioOutputNode;

  readonly inputNode: AVAudioInputNode;

  readonly mainMixerNode: AVAudioMixerNode;

  readonly running: boolean;

  autoShutdownEnabled: boolean;

  readonly attachedNodes: NSSet;

  enableManualRenderingModeFormatMaximumFrameCountError(mode: interop.Enum<typeof AVAudioEngineManualRenderingMode>, pcmFormat: AVAudioFormat, maximumFrameCount: number, outError: interop.PointerConvertible): boolean;

  disableManualRenderingMode(): void;

  renderOfflineToBufferError(numberOfFrames: number, buffer: AVAudioPCMBuffer, outError: interop.PointerConvertible): interop.Enum<typeof AVAudioEngineManualRenderingStatus>;

  readonly manualRenderingBlock: (p1: number, p2: interop.PointerConvertible, p3: interop.PointerConvertible) => interop.Enum<typeof AVAudioEngineManualRenderingStatus>;

  readonly isInManualRenderingMode: boolean;

  readonly manualRenderingMode: interop.Enum<typeof AVAudioEngineManualRenderingMode>;

  readonly manualRenderingFormat: AVAudioFormat;

  readonly manualRenderingMaximumFrameCount: number;

  readonly manualRenderingSampleTime: number;

  connectMIDIToFormatBlock(sourceNode: AVAudioNode, destinationNode: AVAudioNode, format: AVAudioFormat | null, tapBlock: (p1: number, p2: number, p3: number, p4: interop.PointerConvertible) => number | null): void;

  connectMIDIToFormatEventListBlock(sourceNode: AVAudioNode, destinationNode: AVAudioNode, format: AVAudioFormat | null, tapBlock: (p1: number, p2: number, p3: interop.PointerConvertible) => number | null): void;

  connectMIDIToNodesFormatBlock(sourceNode: AVAudioNode, destinationNodes: NSArray<interop.Object> | Array<interop.Object>, format: AVAudioFormat | null, tapBlock: (p1: number, p2: number, p3: number, p4: interop.PointerConvertible) => number | null): void;

  connectMIDIToNodesFormatEventListBlock(sourceNode: AVAudioNode, destinationNodes: NSArray<interop.Object> | Array<interop.Object>, format: AVAudioFormat | null, tapBlock: (p1: number, p2: number, p3: interop.PointerConvertible) => number | null): void;

  disconnectMIDIFrom(sourceNode: AVAudioNode, destinationNode: AVAudioNode): void;

  disconnectMIDIFromNodes(sourceNode: AVAudioNode, destinationNodes: NSArray<interop.Object> | Array<interop.Object>): void;

  disconnectMIDIInput(node: AVAudioNode): void;

  disconnectMIDIOutput(node: AVAudioNode): void;

  setMusicSequence(musicSequence: interop.PointerConvertible): void;

  isRunning(): boolean;

  isAutoShutdownEnabled(): boolean;

  setAutoShutdownEnabled(autoShutdownEnabled: boolean): void;
}

declare class AVAudioSessionPortDescription extends NSObject {
  readonly portType: string;

  readonly portName: string;

  readonly UID: string;

  readonly hasHardwareVoiceCallProcessing: boolean;

  readonly spatialAudioEnabled: boolean;

  readonly channels: NSArray;

  readonly dataSources: NSArray;

  readonly selectedDataSource: AVAudioSessionDataSourceDescription;

  readonly preferredDataSource: AVAudioSessionDataSourceDescription;

  setPreferredDataSourceError(dataSource: AVAudioSessionDataSourceDescription | null, outError: interop.PointerConvertible): boolean;

  isSpatialAudioEnabled(): boolean;

  readonly bluetoothMicrophoneExtension: AVAudioSessionPortExtensionBluetoothMicrophone;
}

declare class AVAudioEnvironmentReverbParameters extends NSObject {
  enable: boolean;

  level: number;

  readonly filterParameters: AVAudioUnitEQFilterParameters;

  loadFactoryReverbPreset(preset: interop.Enum<typeof AVAudioUnitReverbPreset>): void;

  setEnable(enable: boolean): void;

  setLevel(level: number): void;
}

declare class AVAudioSourceNode extends AVAudioNode implements AVAudioMixing {
  initWithRenderBlock(block: (p1: interop.PointerConvertible, p2: interop.PointerConvertible, p3: number, p4: interop.PointerConvertible) => number): this;

  initWithFormatRenderBlock(format: AVAudioFormat, block: (p1: interop.PointerConvertible, p2: interop.PointerConvertible, p3: number, p4: interop.PointerConvertible) => number): this;

  destinationForMixerBus(mixer: AVAudioNode, bus: number): AVAudioMixingDestination;

  volume: number;

  setVolume(volume: number): void;

  pan: number;

  setPan(pan: number): void;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;

  renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>;

  sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>;

  pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>;

  rate: number;

  reverbBlend: number;

  obstruction: number;

  occlusion: number;

  position: AVAudio3DPoint;

  setRenderingAlgorithm(renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>): void;

  setSourceMode(sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>): void;

  setPointSourceInHeadMode(pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>): void;

  setRate(rate: number): void;

  setReverbBlend(reverbBlend: number): void;

  setObstruction(obstruction: number): void;

  setOcclusion(occlusion: number): void;

  setPosition(position: AVAudio3DPoint): void;
}

declare class AVAudioUnitMIDIInstrument extends AVAudioUnit implements AVAudioMixing {
  initWithAudioComponentDescription(description: AudioComponentDescription): this;

  startNoteWithVelocityOnChannel(note: number, velocity: number, channel: number): void;

  stopNoteOnChannel(note: number, channel: number): void;

  sendControllerWithValueOnChannel(controller: number, value: number, channel: number): void;

  sendPitchBendOnChannel(pitchbend: number, channel: number): void;

  sendPressureOnChannel(pressure: number, channel: number): void;

  sendPressureForKeyWithValueOnChannel(key: number, value: number, channel: number): void;

  sendProgramChangeOnChannel(program: number, channel: number): void;

  sendProgramChangeBankMSBBankLSBOnChannel(program: number, bankMSB: number, bankLSB: number, channel: number): void;

  sendMIDIEventData1Data2(midiStatus: number, data1: number, data2: number): void;

  sendMIDIEventData1(midiStatus: number, data1: number): void;

  sendMIDISysExEvent(midiData: NSData): void;

  sendMIDIEventList(eventList: interop.PointerConvertible): void;

  destinationForMixerBus(mixer: AVAudioNode, bus: number): AVAudioMixingDestination;

  volume: number;

  setVolume(volume: number): void;

  pan: number;

  setPan(pan: number): void;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;

  renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>;

  sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>;

  pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>;

  rate: number;

  reverbBlend: number;

  obstruction: number;

  occlusion: number;

  position: AVAudio3DPoint;

  setRenderingAlgorithm(renderingAlgorithm: interop.Enum<typeof AVAudio3DMixingRenderingAlgorithm>): void;

  setSourceMode(sourceMode: interop.Enum<typeof AVAudio3DMixingSourceMode>): void;

  setPointSourceInHeadMode(pointSourceInHeadMode: interop.Enum<typeof AVAudio3DMixingPointSourceInHeadMode>): void;

  setRate(rate: number): void;

  setReverbBlend(reverbBlend: number): void;

  setObstruction(obstruction: number): void;

  setOcclusion(occlusion: number): void;

  setPosition(position: AVAudio3DPoint): void;
}

