/// <reference types="@nativescript/objc-node-api" />
/// <reference path="./Runtime.d.ts" />
/// <reference path="./Foundation.d.ts" />
/// <reference path="./QuartzCore.d.ts" />

declare const AVMetadataIdentifierID3MetadataBand: string;

declare const AVMetadataIdentifierQuickTimeMetadataCollectionUser: string;

declare const AVCaptureSessionPresetPhoto: string;

declare const AVMetadataID3MetadataKeyInvolvedPeopleList_v23: string;

declare const AVMediaCharacteristicUsesWideGamutColorSpace: string;

declare const AVVideoCodecKey: string;

declare const AVPlayerRateDidChangeNotification: string;

declare const AVMetadataiTunesMetadataKeyArtistID: string;

declare const AVPlayerItemTimeJumpedOriginatingParticipantKey: string;

declare const AVMetadataiTunesMetadataKeyArranger: string;

declare const AVMetadataQuickTimeMetadataKeyLocationName: string;

declare const AVMetadataIdentifierID3MetadataGeneralEncapsulatedObject: string;

declare const AVMetadataID3MetadataKeyAlbumTitle: string;

declare const AVMetadataID3MetadataKeyRecommendedBufferSize: string;

declare const AVTrackAssociationTypeSelectionFollower: string;

declare const AVPlayerInterstitialEventJoinCue: string;

declare const AVPlayerInterstitialEventMonitorInterstitialEventDidFinishPlayoutTimeKey: string;

declare const AVMetadataIdentifierQuickTimeMetadataModel: string;

declare const AVMetadataIdentifierQuickTimeMetadataProducer: string;

declare const AVMetadataObjectTypeSalientObject: string;

declare const AVVideoCodecH264: string;

declare const AVVideoYCbCrMatrix_ITU_R_2020: string;

declare const AVMetadataiTunesMetadataKeyDescription: string;

declare const AVMetadataIdentifierID3MetadataCommerical: string;

declare const AVMetadataID3MetadataKeyPositionSynchronization: string;

declare const AVMetadataIdentifierID3MetadataSignature: string;

declare const AVMetadataKeySpaceiTunes: string;

declare const AVMetadataQuickTimeMetadataKeyCameraFrameReadoutTime: string;

declare const AVCaptureSessionInterruptionEndedNotification: string;

declare const AVAssetDownloadTaskMediaSelectionPrefersMultichannelKey: string;

declare const AVMetadataIdentifierID3MetadataInternetRadioStationOwner: string;

declare const AVMetadataIdentifierID3MetadataEqualization2: string;

declare const AVMetadataIdentifierQuickTimeUserDataPhonogramRights: string;

declare const AVMetadataQuickTimeMetadataKeyArtwork: string;

declare const AVMetadataIdentifierID3MetadataCommercial: string;

declare const AVMetadataIdentifieriTunesMetadataEQ: string;

declare const AVMetadataCommonIdentifierSoftware: string;

declare const AVMetadataID3MetadataKeyPartOfASet: string;

declare const AVVideoProfileLevelKey: string;

declare const AVMetadataCommonKeyCreationDate: string;

declare const AVSampleBufferDisplayLayerOutputObscuredDueToInsufficientExternalProtectionDidChangeNotification: string;

declare const AVMetadataID3MetadataKeyRelativeVolumeAdjustment2: string;

declare const AVMetadataObjectTypeCode39Code: string;

declare const AVMetadataiTunesMetadataKeyEncodingTool: string;

declare const AVMetadataIdentifieriTunesMetadataCredits: string;

declare const AVMetadataCommonKeyFormat: string;

declare const AVCaptureSessionInterruptionReasonKey: string;

declare const AVMetadataIdentifierQuickTimeUserDataCreationDate: string;

declare const AVMetadataIdentifierQuickTimeMetadataDisplayName: string;

declare const AVMetadataQuickTimeUserDataKeyOriginalSource: string;

declare const AVMetadataID3MetadataKeyAudioSeekPointIndex: string;

declare const AVOutputSettingsPreset3840x2160: string;

declare const AVMetadataQuickTimeUserDataKeySoftware: string;

declare const AVMetadataIdentifierID3MetadataEncryption: string;

declare const AVMetadataQuickTimeMetadataKeyDirectionMotion: string;

declare const AVVideoCodecTypeJPEG: string;

declare const AVMetadataIdentifierQuickTimeUserDataProducer: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedHumanBody: string;

declare const AVMediaTypeHaptic: string;

declare const AVCaptureSystemPressureLevelShutdown: string;

declare const AVCaptureSystemPressureLevelSerious: string;

declare const AVSemanticSegmentationMatteTypeSkin: string;

declare const AVMetadataObjectTypeGS1DataBarExpandedCode: string;

declare const AVMetadataObjectTypeGS1DataBarCode: string;

declare const AVMetadataObjectTypeDataMatrixCode: string;

declare const AVMetadataObjectTypeQRCode: string;

declare const AVMetadataObjectTypeCode128Code: string;

declare const AVMetadataObjectTypeCode39Mod43Code: string;

declare const AVMetadataObjectTypeDogBody: string;

declare const AVMetadataObjectTypeCatBody: string;

declare const AVMetadataObjectTypeCatHead: string;

declare const AVMetadataObjectTypeHumanFullBody: string;

declare const AVCaptureSessionDidStartRunningNotification: string;

declare const AVCaptureSessionErrorKey: string;

declare const AVCaptureAspectRatio3x4: string;

declare const AVCaptureAspectRatio4x3: string;

declare const AVCaptureAspectRatio9x16: string;

declare const AVCaptureAspectRatio16x9: string;

declare const AVCaptureAspectRatio1x1: string;

declare const AVSpatialCaptureDiscomfortReasonNotEnoughLight: string;

declare const AVCaptureWhiteBalanceGainsCurrent: AVCaptureWhiteBalanceGains;

declare const AVCaptureWhiteBalanceTemperatureAndTintValuesCloudy: AVCaptureWhiteBalanceTemperatureAndTintValues;

declare const AVCaptureWhiteBalanceTemperatureAndTintValuesDaylight: AVCaptureWhiteBalanceTemperatureAndTintValues;

declare const AVCaptureWhiteBalanceTemperatureAndTintValuesTungsten: AVCaptureWhiteBalanceTemperatureAndTintValues;

declare const AVCaptureISOCurrent: number;

declare const AVCaptureExposureDurationCurrent: CMTime;

declare const AVAssetExportPreset1920x1080: string;

declare const AVCaptureMaxAvailableTorchLevel: number;

declare const AVCaptureDeviceTypeBuiltInMicrophone: string;

declare const AVCaptureDeviceTypeBuiltInTrueDepthCamera: string;

declare const AVCaptureDeviceTypeBuiltInDualWideCamera: string;

declare const AVCaptureDeviceTypeBuiltInDualCamera: string;

declare const AVCaptureDeviceTypeBuiltInUltraWideCamera: string;

declare const AVCaptureDeviceTypeMicrophone: string;

declare const AVCaptureDeviceTypeExternal: string;

declare const AVCaptureDeviceSubjectAreaDidChangeNotification: string;

declare const AVCaptureReactionTypeConfetti: string;

declare const AVCaptureReactionTypeRain: string;

declare const AVCaptureReactionTypeHeart: string;

declare const AVCaptureReactionTypeThumbsUp: string;

declare const AVMediaCharacteristicTactileMinimal: string;

declare const AVCaptureDeviceTypeBuiltInDuoCamera: string;

declare const AVCaptureSessionPresetiFrame1280x720: string;

declare const AVCaptureSessionPreset640x480: string;

declare const AVCaptureSessionPresetMedium: string;

declare const AVCaptureSessionPresetHigh: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedSalientObject: string;

declare const AVVideoPixelAspectRatioVerticalSpacingKey: string;

declare const AVErrorFileSizeKey: string;

declare const AVMetadataIdentifieriTunesMetadataAccountKind: string;

declare const AVSampleBufferVideoRendererDidFailToDecodeNotificationErrorKey: string;

declare const AVSampleBufferRenderSynchronizerRateDidChangeNotification: string;

declare const AVSampleBufferVideoRendererDidFailToDecodeNotification: string;

declare const AVSampleBufferDisplayLayerRequiresFlushToResumeDecodingDidChangeNotification: string;

declare const AVSampleBufferDisplayLayerFailedToDecodeNotification: string;

declare const AVSampleBufferAudioRendererFlushTimeKey: string;

declare const AVSampleBufferAudioRendererOutputConfigurationDidChangeNotification: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncReasonLoadedTimeRangesChanged: string;

declare const AVMetadataObjectTypeAztecCode: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncReasonCurrentSegmentChanged: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncNotification: string;

declare const AVPlayerWaitingDuringInterstitialEventReason: string;

declare const AVPlayerInterstitialEventMonitorInterstitialEventDidFinishDidPlayEntireEventKey: string;

declare const AVPlayerInterstitialEventMonitorInterstitialEventDidFinishNotification: string;

declare const AVPlayerInterstitialEventMonitorCurrentEventSkippedEventKey: string;

declare const AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeSkipControlLabelKey: string;

declare const AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeStateKey: string;

declare const AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeNotification: string;

declare const AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChangeStatusKey: string;

declare const AVPlayerInterstitialEventLeaveCue: string;

declare const AVPlayerItemLegibleOutputTextStylingResolutionSourceAndRulesOnly: string;

declare const AVPlayerItemLegibleOutputTextStylingResolutionDefault: string;

declare const AVPlayerItemFailedToPlayToEndTimeErrorKey: string;

declare const AVPlayerItemRecommendedTimeOffsetFromLiveDidChangeNotification: string;

declare const AVPlayerItemNewErrorLogEntryNotification: string;

declare const AVPlayerItemNewAccessLogEntryNotification: string;

declare const AVPlayerItemPlaybackStalledNotification: string;

declare const AVPlayerItemTimeJumpedNotification: string;

declare const AVPlaybackCoordinatorOtherParticipantsDidChangeNotification: string;

declare const AVCoordinatedPlaybackSuspensionReasonUserActionRequired: string;

declare const AVCoordinatedPlaybackSuspensionReasonPlayingInterstitial: string;

declare const AVPlayerEligibleForHDRPlaybackDidChangeNotification: string;

declare const AVPlayerWaitingForCoordinatedPlaybackReason: string;

declare const AVMetadataQuickTimeUserDataKeyLocationISO6709: string;

declare const AVPlayerWaitingWithNoItemToPlayReason: string;

declare const AVPlayerWaitingWhileEvaluatingBufferingRateReason: string;

declare const AVPlayerWaitingToMinimizeStallsReason: string;

declare const AVPlayerRateDidChangeReasonAudioSessionInterrupted: string;

declare const AVPlayerRateDidChangeReasonSetRateFailed: string;

declare const AVPlayerRateDidChangeReasonSetRateCalled: string;

declare const AVPlayerRateDidChangeOriginatingParticipantKey: string;

declare const AVFileTypeTIFF: string;

declare const AVOutputSettingsPresetMVHEVC4320x4320: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncReasonKey: string;

declare const AVOutputSettingsPresetMVHEVC1440x1440: string;

declare const AVOutputSettingsPresetMVHEVC960x960: string;

declare const AVOutputSettingsPresetHEVC3840x2160: string;

declare const AVOutputSettingsPresetHEVC1920x1080: string;

declare const AVOutputSettingsPreset1280x720: string;

declare const AVOutputSettingsPreset640x480: string;

declare const AVFragmentedMovieWasDefragmentedNotification: string;

declare const AVFragmentedMovieDurationDidChangeNotification: string;

declare const AVMovieReferenceRestrictionsKey: string;

declare const AVFragmentedMovieTrackTimeRangeDidChangeNotification: string;

declare const AVMetadataIdentifierIcyMetadataStreamTitle: string;

declare const AVMetadataIdentifierID3MetadataUserURL: string;

declare const AVMetadataIdentifierID3MetadataOfficialInternetRadioStationHomepage: string;

declare const AVMetadataIdentifierID3MetadataOfficialAudioSourceWebpage: string;

declare const AVMetadataIdentifierID3MetadataCommercialInformation: string;

declare const AVMetadataIdentifierID3MetadataUnsynchronizedLyric: string;

declare const AVMetadataObjectTypePDF417Code: string;

declare const AVMetadataIdentifierID3MetadataInternationalStandardRecordingCode: string;

declare const AVMetadataIdentifierID3MetadataInternetRadioStationName: string;

declare const AVMetadataIdentifierID3MetadataRecordingDates: string;

declare const AVMetadataIdentifierID3MetadataProducedNotice: string;

declare const AVMetadataIdentifierID3MetadataPartOfASet: string;

declare const AVMetadataIdentifierID3MetadataConductor: string;

declare const AVMetadataIdentifierID3MetadataOriginalReleaseYear: string;

declare const AVMetadataIdentifierID3MetadataMediaType: string;

declare const AVMetadataIdentifierID3MetadataLanguage: string;

declare const AVMetadataIdentifierID3MetadataInitialKey: string;

declare const AVMetadataIdentifierID3MetadataTitleDescription: string;

declare const AVMetadataIdentifierID3MetadataTime: string;

declare const AVMetadataIdentifierID3MetadataFileType: string;

declare const AVMetadataIdentifierID3MetadataLyricist: string;

declare const AVMetadataIdentifierID3MetadataTaggingTime: string;

declare const AVMetadataIdentifierID3MetadataReleaseTime: string;

declare const AVMetadataIdentifierID3MetadataEncodingTime: string;

declare const AVMetadataIdentifierID3MetadataCopyright: string;

declare const AVMetadataIdentifierID3MetadataComposer: string;

declare const AVMetadataIdentifierID3MetadataAlbumTitle: string;

declare const AVMetadataIdentifierID3MetadataSynchronizedLyric: string;

declare const AVMetadataIdentifierID3MetadataSeek: string;

declare const AVMetadataIdentifierID3MetadataRelativeVolumeAdjustment2: string;

declare const AVMetadataIdentifierID3MetadataRecommendedBufferSize: string;

declare const AVMetadataIdentifierID3MetadataPositionSynchronization: string;

declare const AVMetadataIdentifierID3MetadataPlayCounter: string;

declare const AVMetadataIdentifierID3MetadataOwnership: string;

declare const AVMetadataIdentifierID3MetadataEventTimingCodes: string;

declare const AVMetadataIdentifierID3MetadataAudioSeekPointIndex: string;

declare const AVMetadataIdentifierID3MetadataAttachedPicture: string;

declare const AVMetadataIdentifierID3MetadataAudioEncryption: string;

declare const AVMetadataIdentifieriTunesMetadataThanks: string;

declare const AVMetadataIdentifieriTunesMetadataPublisher: string;

declare const AVMetadataIdentifieriTunesMetadataPerformer: string;

declare const AVMetadataIdentifieriTunesMetadataRecordCompany: string;

declare const AVMetadataIdentifieriTunesMetadataDirector: string;

declare const AVMetadataIdentifieriTunesMetadataTrackNumber: string;

declare const AVMetadataIdentifieriTunesMetadataBeatsPerMin: string;

declare const AVMetadataIdentifieriTunesMetadataPlaylistID: string;

declare const AVMetadataIdentifieriTunesMetadataGenreID: string;

declare const AVMetadataIdentifieriTunesMetadataDiscNumber: string;

declare const AVMetadataIdentifieriTunesMetadataDiscCompilation: string;

declare const AVMetadataIdentifieriTunesMetadataSongID: string;

declare const AVMetadataIdentifieriTunesMetadataComposer: string;

declare const AVMetadataIdentifieriTunesMetadataTrackSubTitle: string;

declare const AVMetadataIdentifieriTunesMetadataUserGenre: string;

declare const AVMetadataIdentifieriTunesMetadataEncodedBy: string;

declare const AVMetadataIdentifieriTunesMetadataCopyright: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationHorizontalAccuracyInMeters: string;

declare const AVMetadataIdentifierQuickTimeMetadataLivePhotoVitalityScoringVersion: string;

declare const AVURLAssetURLRequestAttributionKey: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraShutterSpeedTime: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraShutterSpeedAngle: string;

declare const AVMetadataIdentifierQuickTimeMetadataWhiteBalanceByCCTColorMatrices: string;

declare const AVMetadataIdentifieriTunesMetadataAcknowledgement: string;

declare const AVMetadataIdentifierID3MetadataPayment: string;

declare const AVMetadataIdentifierQuickTimeMetadataWhiteBalanceByCCTWhiteBalanceFactors: string;

declare const AVMetadataIdentifierQuickTimeMetadataAccessibilityDescription: string;

declare const AVMetadataIdentifierQuickTimeMetadataContentIdentifier: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedDogBody: string;

declare const AVMetadataIdentifierQuickTimeMetadataPreferredAffineTransform: string;

declare const AVMetadataIdentifierQuickTimeMetadataDirectionFacing: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationBody: string;

declare const AVMetadataIdentifierQuickTimeMetadataRatingUser: string;

declare const AVMetadataIdentifierQuickTimeMetadataTitle: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraIdentifier: string;

declare const AVMetadataIdentifierQuickTimeMetadataPhonogramRights: string;

declare const AVMetadataIdentifierQuickTimeMetadataCredits: string;

declare const AVMetadataIdentifierQuickTimeMetadataPerformer: string;

declare const AVMetadataIdentifierQuickTimeMetadataEncodedBy: string;

declare const AVMetadataIdentifierQuickTimeMetadataArranger: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationISO6709: string;

declare const AVMetadataIdentifierQuickTimeMetadataSoftware: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationNote: string;

declare const AVMetadataIdentifierQuickTimeMetadataArtwork: string;

declare const AVMetadataCommonIdentifierRelation: string;

declare const AVMetadataIdentifierQuickTimeMetadataArtist: string;

declare const AVMetadataIdentifierISOUserDataTaggedCharacteristic: string;

declare const AVMetadataIdentifierQuickTimeMetadataInformation: string;

declare const AVMetadataIdentifierQuickTimeMetadataDirector: string;

declare const AVMetadataIdentifierQuickTimeMetadataCopyright: string;

declare const AVMetadataIdentifier3GPUserDataUserRating: string;

declare const AVMetadataIdentifier3GPUserDataCollection: string;

declare const AVMetadataIdentifier3GPUserDataDescription: string;

declare const AVMetadataIdentifier3GPUserDataRecordingYear: string;

declare const AVMetadataIdentifier3GPUserDataCopyright: string;

declare const AVMetadataIdentifierISOUserDataAccessibilityDescription: string;

declare const AVMetadataIdentifierISOUserDataCopyright: string;

declare const AVMetadataIdentifierQuickTimeUserDataAccessibilityDescription: string;

declare const AVMetadataIdentifierQuickTimeUserDataPublisher: string;

declare const AVMetadataIdentifierQuickTimeUserDataOriginalArtist: string;

declare const AVMetadataIdentifierQuickTimeUserDataModel: string;

declare const AVMetadataIdentifierQuickTimeUserDataKeywords: string;

declare const AVMetadataIdentifierQuickTimeUserDataInformation: string;

declare const AVMetadataIdentifierQuickTimeUserDataHostComputer: string;

declare const AVMetadataIdentifierQuickTimeUserDataGenre: string;

declare const AVMetadataIdentifierQuickTimeUserDataEncodedBy: string;

declare const AVMetadataIdentifierQuickTimeUserDataCopyright: string;

declare const AVMetadataIdentifierQuickTimeUserDataComposer: string;

declare const AVMetadataIdentifierQuickTimeUserDataComment: string;

declare const AVMetadataIdentifierQuickTimeUserDataSoftware: string;

declare const AVMetadataIdentifierQuickTimeUserDataAuthor: string;

declare const AVMetadataIdentifierQuickTimeUserDataArtist: string;

declare const AVMetadataIdentifierID3MetadataRelativeVolumeAdjustment: string;

declare const AVMetadataIdentifierQuickTimeUserDataArranger: string;

declare const AVMetadataCommonIdentifierModel: string;

declare const AVMetadataCommonIdentifierAuthor: string;

declare const AVMetadataCommonIdentifierLocation: string;

declare const AVMetadataCommonIdentifierType: string;

declare const AVMetadataCommonIdentifierLastModifiedDate: string;

declare const AVMetadataCommonIdentifierCreationDate: string;

declare const AVMetadataCommonIdentifierDescription: string;

declare const AVErrorFileTypeKey: string;

declare const AVErrorPersistentTrackIDKey: string;

declare const AVErrorPresentationTimeStampKey: string;

declare const AVErrorMediaSubTypeKey: string;

declare const AVErrorRecordingSuccessfullyFinishedKey: string;

declare const AVErrorPIDKey: string;

declare const AVOutputSettingsPresetHEVC3840x2160WithAlpha: string;

declare const AVErrorDeviceKey: string;

declare const AVCaptionUseDropFrameTimeCodeKey: string;

declare const AVAssetDownloadedAssetEvictionPriorityDefault: string;

declare const AVAssetDownloadTaskPrefersHDRKey: string;

declare const AVAssetDownloadTaskPrefersLosslessAudioKey: string;

declare const AVAssetDownloadTaskMinimumRequiredPresentationSizeKey: string;

declare const AVAssetDownloadTaskMinimumRequiredMediaBitrateKey: string;

declare const AVRouteDetectorMultipleRoutesDetectedDidChangeNotification: string;

declare const AVMetadataIdentifierQuickTimeUserDataAlbum: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationDate: string;

declare const AVMetadataIdentifierID3MetadataRecordingTime: string;

declare const AVMetadataQuickTimeUserDataKeyDirector: string;

declare const AVMetadataQuickTimeMetadataKeyCreationDate: string;

declare const AVMetadataIdentifierID3MetadataSynchronizedTempoCodes: string;

declare const AVMetadataIdentifierID3MetadataMusicianCreditsList: string;

declare const AVMetadataIdentifierID3MetadataComments: string;

declare const AVMetadataIdentifier3GPUserDataThumbnail: string;

declare const AVMetadataIdentifierID3MetadataSetSubtitle: string;

declare const AVMetadataQuickTimeUserDataKeyModel: string;

declare const AVMetadataIdentifieriTunesMetadataAlbum: string;

declare const AVCaptureWhiteBalanceTemperatureAndTintValuesFluorescent: AVCaptureWhiteBalanceTemperatureAndTintValues;

declare const AVMetadataIdentifieriTunesMetadataEncodingTool: string;

declare const AVMetadataIdentifieriTunesMetadataConductor: string;

declare const AVMetadataIdentifierID3MetadataPlaylistDelay: string;

declare const AVContentKeySystemClearKey: string;

declare const AVPlayerInterstitialEventMonitorInterstitialEventWasUnscheduledErrorKey: string;

declare const AVMetadataIdentifierID3MetadataTrackNumber: string;

declare const AVMetadataIdentifierID3MetadataFileOwner: string;

declare const AVMetadataIdentifierID3MetadataPrivate: string;

declare const AVSampleBufferVideoRendererRequiresFlushToResumeDecodingDidChangeNotification: string;

declare const AVMetadataCommonIdentifierTitle: string;

declare const AVMetadataIdentifieriTunesMetadataReleaseDate: string;

declare const AVPlayerInterstitialEventMonitorCurrentEventDidChangeNotification: string;

declare const AVFileTypeAMR: string;

declare const AVVideoScalingModeKey: string;

declare const AVMetadataIdentifierQuickTimeMetadataSpatialOverCaptureQualityScoringVersion: string;

declare const AVMetadataIdentifierQuickTimeUserDataDescription: string;

declare const AVURLAssetPrimarySessionIdentifierKey: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraFrameReadoutTime: string;

declare const AVMetadataQuickTimeMetadataKeyLocationISO6709: string;

declare const AVMetadataISOUserDataKeyAccessibilityDescription: string;

declare const AVMetadataID3MetadataKeyTrackNumber: string;

declare const AVURLAssetPreferPreciseDurationAndTimingKey: string;

declare const AVMetadataCommonKeyDescription: string;

declare const AVMetadataObjectTypeGS1DataBarLimitedCode: string;

declare const AVMetadataIdentifierQuickTimeUserDataProduct: string;

declare const AVFoundationErrorDomain: string;

declare const AVMetadataIdentifierID3MetadataOfficialAudioFileWebpage: string;

declare const AVFileTypeMPEGLayer3: string;

declare const AVMetadataiTunesMetadataKeyDiscCompilation: string;

declare const AVMetadataCommonIdentifierContributor: string;

declare const AVAssetPlaybackConfigurationOptionNonRectilinearProjection: string;

declare const AVAssetPlaybackConfigurationOptionSpatialVideo: string;

declare const AVAssetPlaybackConfigurationOptionStereoVideo: string;

declare const AVAssetWriterInputMediaDataLocationSparselyInterleavedWithMainMediaData: string;

declare const AVAssetWriterInputMediaDataLocationBeforeMainMediaDataNotInterleaved: string;

declare const AVAssetTrackTrackAssociationsDidChangeNotification: string;

declare const AVAssetTrackSegmentsDidChangeNotification: string;

declare const AVAssetTrackTimeRangeDidChangeNotification: string;

declare const AVTrackAssociationTypeMetadataReferent: string;

declare const AVTrackAssociationTypeTimecode: string;

declare const AVTrackAssociationTypeForcedSubtitlesOnly: string;

declare const AVTrackAssociationTypeChapterList: string;

declare const AVTrackAssociationTypeAudioFallback: string;

declare const AVVideoCompositionPerFrameHDRDisplayMetadataPolicyPropagate: string;

declare const AVAssetImageGeneratorApertureModeEncodedPixels: string;

declare const AVAssetImageGeneratorApertureModeProductionAperture: string;

declare const AVAssetImageGeneratorApertureModeCleanAperture: string;

declare const AVAssetExportPresetAppleProRes4444LPCM: string;

declare const AVAssetExportPresetPassthrough: string;

declare const AVAssetExportPresetAppleM4A: string;

declare const AVAssetExportPresetMVHEVC1440x1440: string;

declare const AVAssetExportPresetMVHEVC960x960: string;

declare const AVAssetExportPresetHEVC7680x4320: string;

declare const AVAssetExportPresetHEVC4320x2160: string;

declare const AVAssetExportPresetHEVC3840x2160WithAlpha: string;

declare const AVAssetExportPresetHEVC3840x2160: string;

declare const AVAssetExportPresetHEVC1920x1080: string;

declare const AVAssetExportPreset3840x2160: string;

declare const AVAssetExportPreset1280x720: string;

declare const AVAssetExportPreset960x540: string;

declare const AVAssetExportPreset640x480: string;

declare const AVAssetExportPresetHEVCHighestQuality: string;

declare const AVAssetExportPresetHighestQuality: string;

declare const AVAssetExportPresetMediumQuality: string;

declare const AVAudioTimePitchAlgorithmTimeDomain: string;

declare const AVAssetMediaSelectionGroupsDidChangeNotification: string;

declare const AVAssetDurationDidChangeNotification: string;

declare const AVURLAssetShouldParseExternalSphericalTagsKey: string;

declare const AVURLAssetHTTPUserAgentKey: string;

declare const AVURLAssetAllowsExpensiveNetworkAccessKey: string;

declare const AVURLAssetHTTPCookiesKey: string;

declare const AVURLAssetReferenceRestrictionsKey: string;

declare const AVURLAssetOverrideMIMETypeKey: string;

declare const AVMetadataIdentifierQuickTimeUserDataWarning: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraLensModel: string;

declare const AVVideoCodecHEVC: string;

declare const AVVideoYCbCrMatrix_ITU_R_709_2: string;

declare const AVMetadataCommonIdentifierSource: string;

declare const AVCaptionMediaTypeKey: string;

declare const AVMetadataCommonKeyAuthor: string;

declare const AVVideoApertureModeEncodedPixels: string;

declare const AVVideoApertureModeProductionAperture: string;

declare const AVVideoDecompressionPropertiesKey: string;

declare const AVVideoAverageNonDroppableFrameRateKey: string;

declare const AVVideoH264EntropyModeKey: string;

declare const AVVideoProfileLevelH264HighAutoLevel: string;

declare const AVVideoProfileLevelH264High40: string;

declare const AVVideoProfileLevelH264MainAutoLevel: string;

declare const AVVideoProfileLevelH264Main41: string;

declare const AVVideoProfileLevelH264Main32: string;

declare const AVMetadataIdentifieriTunesMetadataSoundEngineer: string;

declare const AVVideoProfileLevelH264Main31: string;

declare const AVVideoProfileLevelH264Main30: string;

declare const AVVideoProfileLevelH264BaselineAutoLevel: string;

declare const AVVideoProfileLevelH264Baseline41: string;

declare const AVVideoProfileLevelH264Baseline30: string;

declare const AVVideoAllowFrameReorderingKey: string;

declare const AVVideoAppleProRAWBitDepthKey: string;

declare const AVMetadataQuickTimeUserDataKeyPerformers: string;

declare const AVVideoMaxKeyFrameIntervalDurationKey: string;

declare const AVVideoAverageBitRateKey: string;

declare const AVVideoAllowWideColorKey: string;

declare const AVVideoYCbCrMatrix_ITU_R_601_4: string;

declare const AVMetadataID3MetadataKeyCommerical: string;

declare const AVVideoYCbCrMatrixKey: string;

declare const AVVideoTransferFunction_IEC_sRGB: string;

declare const AVVideoTransferFunction_SMPTE_ST_2084_PQ: string;

declare const AVVideoColorPrimaries_ITU_R_2020: string;

declare const AVVideoColorPrimaries_P3_D65: string;

declare const AVVideoColorPrimaries_ITU_R_709_2: string;

declare const AVVideoColorPrimariesKey: string;

declare const AVVideoColorPropertiesKey: string;

declare const AVVideoScalingModeResizeAspect: string;

declare const AVVideoScalingModeResize: string;

declare const AVVideoScalingModeFit: string;

declare const AVVideoPixelAspectRatioHorizontalSpacingKey: string;

declare const AVMetadataQuickTimeMetadataKeyAccessibilityDescription: string;

declare const AVVideoWidthKey: string;

declare const AVVideoCodecTypeAppleProResRAW: string;

declare const AVVideoCodecTypeAppleProRes422LT: string;

declare const AVVideoCodecTypeAppleProRes422: string;

declare const AVVideoCodecTypeJPEGXL: string;

declare const AVMetadataExtraAttributeBaseURIKey: string;

declare const AVMetadataExtraAttributeValueURIKey: string;

declare const AVMetadataQuickTimeMetadataKeyAlbum: string;

declare const AVMetadataFormatUnknown: string;

declare const AVMetadataKeySpaceHLSDateRange: string;

declare const AVMetadataIcyMetadataKeyStreamTitle: string;

declare const AVMetadataID3MetadataKeyUserURL: string;

declare const AVMetadataID3MetadataKeyOfficialPublisherWebpage: string;

declare const AVMetadataID3MetadataKeyPayment: string;

declare const AVMetadataID3MetadataKeyOfficialAudioSourceWebpage: string;

declare const AVMetadataID3MetadataKeyOfficialArtistWebpage: string;

declare const AVMetadataID3MetadataKeyOfficialAudioFileWebpage: string;

declare const AVMetadataID3MetadataKeyCopyrightInformation: string;

declare const AVMetadataID3MetadataKeyCommercialInformation: string;

declare const AVMetadataID3MetadataKeyUnsynchronizedLyric: string;

declare const AVMetadataID3MetadataKeyUniqueFileIdentifier: string;

declare const AVMetadataID3MetadataKeyUserText: string;

declare const AVMetadataID3MetadataKeySetSubtitle: string;

declare const AVMetadataID3MetadataKeyEncodedWith: string;

declare const AVMetadataID3MetadataKeyPerformerSortOrder: string;

declare const AVMetadataID3MetadataKeyAlbumSortOrder: string;

declare const AVMetadataID3MetadataKeyInternetRadioStationOwner: string;

declare const AVMetadataID3MetadataKeyInternetRadioStationName: string;

declare const AVMetadataID3MetadataKeyPublisher: string;

declare const AVMetadataID3MetadataKeyModifiedBy: string;

declare const AVMetadataID3MetadataKeyBand: string;

declare const AVMetadataID3MetadataKeyFileOwner: string;

declare const AVMetadataID3MetadataKeyOriginalLyricist: string;

declare const AVMetadataID3MetadataKeyMediaType: string;

declare const AVMetadataID3MetadataKeyLength: string;

declare const AVMetadataID3MetadataKeyLanguage: string;

declare const AVMetadataID3MetadataKeyTitleDescription: string;

declare const AVMetadataID3MetadataKeyTime: string;

declare const AVMetadataID3MetadataKeyLyricist: string;

declare const AVMetadataID3MetadataKeyRecordingTime: string;

declare const AVMetadataID3MetadataKeyOriginalReleaseTime: string;

declare const AVMetadataID3MetadataKeyPlaylistDelay: string;

declare const AVMetadataID3MetadataKeyEncodingTime: string;

declare const AVMetadataID3MetadataKeyDate: string;

declare const AVMetadataID3MetadataKeyCopyright: string;

declare const AVMetadataID3MetadataKeyContentType: string;

declare const AVMetadataID3MetadataKeyComposer: string;

declare const AVMetadataID3MetadataKeySynchronizedLyric: string;

declare const AVMetadataID3MetadataKeySignature: string;

declare const AVMetadataID3MetadataKeyRelativeVolumeAdjustment: string;

declare const AVMetadataID3MetadataKeyOwnership: string;

declare const AVMetadataID3MetadataKeyMusicCDIdentifier: string;

declare const AVMetadataID3MetadataKeyEncryption: string;

declare const AVMetadataID3MetadataKeyAudioEncryption: string;

declare const AVMetadataiTunesMetadataKeyExecProducer: string;

declare const AVMetadataiTunesMetadataKeyThanks: string;

declare const AVMetadataiTunesMetadataKeySoloist: string;

declare const AVMetadataiTunesMetadataKeySoundEngineer: string;

declare const AVMetadataiTunesMetadataKeyPublisher: string;

declare const AVMetadataiTunesMetadataKeyPerformer: string;

declare const AVAssetWriterInputMediaDataLocationInterleavedWithMainMediaData: string;

declare const AVMetadataiTunesMetadataKeyProducer: string;

declare const AVMetadataiTunesMetadataKeyRecordCompany: string;

declare const AVMetadataiTunesMetadataKeyLinerNotes: string;

declare const AVMetadataiTunesMetadataKeyDirector: string;

declare const AVMetadataiTunesMetadataKeyAcknowledgement: string;

declare const AVMetadataiTunesMetadataKeyLyrics: string;

declare const AVMetadataIdentifier3GPUserDataGenre: string;

declare const AVMetadataiTunesMetadataKeyTrackNumber: string;

declare const AVMetadataiTunesMetadataKeyContentRating: string;

declare const AVMetadataiTunesMetadataKeyGrouping: string;

declare const AVMetadataiTunesMetadataKeyDiscNumber: string;

declare const AVMetadataiTunesMetadataKeyAppleID: string;

declare const AVMetadataiTunesMetadataKeyAlbumArtist: string;

declare const AVMetadataiTunesMetadataKeyComposer: string;

declare const AVMetadataiTunesMetadataKeyTrackSubTitle: string;

declare const AVMetadataiTunesMetadataKeySongName: string;

declare const AVMetadataiTunesMetadataKeyPredefinedGenre: string;

declare const AVMetadataiTunesMetadataKeyReleaseDate: string;

declare const AVMetadataiTunesMetadataKeyCopyright: string;

declare const AVMetadataiTunesMetadataKeyArtist: string;

declare const AVMetadataiTunesMetadataKeyAlbum: string;

declare const AVMetadataQuickTimeMetadataKeyCameraFocalLength35mmEquivalent: string;

declare const AVMetadataQuickTimeMetadataKeyCameraLensIrisFNumber: string;

declare const AVCaptureSystemPressureLevelFair: string;

declare const AVMetadataQuickTimeMetadataKeyCameraShutterSpeedTime: string;

declare const AVMetadataQuickTimeMetadataKeyCameraShutterSpeedAngle: string;

declare const AVMetadataQuickTimeMetadataKeyWhiteBalanceByCCTColorMatrices: string;

declare const AVMetadataQuickTimeMetadataKeyCameraWhiteBalance: string;

declare const AVMetadataQuickTimeMetadataKeyCinematicVideoIntent: string;

declare const AVMetadataQuickTimeMetadataKeyFullFrameRatePlaybackIntent: string;

declare const AVMetadataQuickTimeMetadataKeyIsMontage: string;

declare const AVMetadataQuickTimeMetadataKeyContentIdentifier: string;

declare const AVMetadataQuickTimeMetadataKeyDirectionFacing: string;

declare const AVMetadataQuickTimeMetadataKeyLocationRole: string;

declare const AVMetadataQuickTimeMetadataKeyCollectionUser: string;

declare const AVMetadataQuickTimeMetadataKeyTitle: string;

declare const AVMetadataQuickTimeMetadataKeyCameraIdentifier: string;

declare const AVMetadataQuickTimeMetadataKeyPhonogramRights: string;

declare const AVMetadataQuickTimeMetadataKeyOriginalArtist: string;

declare const AVMetadataQuickTimeMetadataKeyModel: string;

declare const AVMetadataQuickTimeMetadataKeyGenre: string;

declare const AVMetadataQuickTimeMetadataKeyDescription: string;

declare const AVMetadataQuickTimeMetadataKeyArtist: string;

declare const AVMetadataQuickTimeMetadataKeyPublisher: string;

declare const AVMetadataQuickTimeMetadataKeyDirector: string;

declare const AVMetadataQuickTimeMetadataKeyCopyright: string;

declare const AVMetadataQuickTimeMetadataKeyAuthor: string;

declare const AVMetadataKeySpaceQuickTimeMetadata: string;

declare const AVMetadata3GPUserDataKeyAlbumAndTrack: string;

declare const AVMetadataCommonIdentifierMake: string;

declare const AVMetadata3GPUserDataKeyThumbnail: string;

declare const AVMetadata3GPUserDataKeyCollection: string;

declare const AVMetadata3GPUserDataKeyTitle: string;

declare const AVMetadata3GPUserDataKeyLocation: string;

declare const AVMetadataIdentifieriTunesMetadataUserComment: string;

declare const AVMetadata3GPUserDataKeyAuthor: string;

declare const AVMetadata3GPUserDataKeyCopyright: string;

declare const AVMetadataISOUserDataKeyDate: string;

declare const AVMetadataKeySpaceISOUserData: string;

declare const AVVideoCodecTypeAppleProResRAWHQ: string;

declare const AVMetadataQuickTimeUserDataKeyTaggedCharacteristic: string;

declare const AVMetadataQuickTimeUserDataKeyPhonogramRights: string;

declare const AVMetadataID3MetadataKeyLeadPerformer: string;

declare const AVMetadataQuickTimeUserDataKeyURLLink: string;

declare const AVMetadataQuickTimeUserDataKeySpecialPlaybackRequirements: string;

declare const AVMetadataQuickTimeUserDataKeyProduct: string;

declare const AVMetadataQuickTimeUserDataKeyPublisher: string;

declare const AVMetadataQuickTimeUserDataKeyOriginalFormat: string;

declare const AVMetadataQuickTimeUserDataKeyMake: string;

declare const AVMetadataQuickTimeUserDataKeyHostComputer: string;

declare const AVMetadataQuickTimeUserDataKeyFullName: string;

declare const AVMetadataQuickTimeUserDataKeyEncodedBy: string;

declare const AVMetadataQuickTimeUserDataKeyDescription: string;

declare const AVMetadataQuickTimeUserDataKeyChapter: string;

declare const AVMetadataQuickTimeUserDataKeyArtist: string;

declare const AVMetadataQuickTimeUserDataKeyAlbum: string;

declare const AVMetadataCommonKeySoftware: string;

declare const AVMetadataCommonKeyModel: string;

declare const AVMetadataCommonKeyArtwork: string;

declare const AVMetadataCommonKeyArtist: string;

declare const AVMetadataCommonKeyAlbumName: string;

declare const AVMetadataCommonKeyLanguage: string;

declare const AVMetadataCommonKeyIdentifier: string;

declare const AVMetadataCommonKeyType: string;

declare const AVMetadataCommonKeyLastModifiedDate: string;

declare const AVMetadataCommonKeyContributor: string;

declare const AVMetadataCommonKeySubject: string;

declare const AVStreamingKeyDeliveryContentKeyType: string;

declare const AVFileTypeDICOM: string;

declare const AVFileTypeAHAP: string;

declare const AVFileTypeSCC: string;

declare const AVFileTypeHEIC: string;

declare const AVFileTypeJPEG: string;

declare const AVFileTypeAC3: string;

declare const AVFileTypeSunAU: string;

declare const AVFileTypeAIFC: string;

declare const AVFileTypeCoreAudioFormat: string;

declare const AVFileType3GPP: string;

declare const AVFileTypeAppleM4V: string;

declare const AVFileTypeMPEG4: string;

declare const AVMediaCharacteristicIndicatesNonRectilinearProjection: string;

declare const AVMediaCharacteristicIndicatesHorizontalFieldOfView: string;

declare const AVMediaCharacteristicContainsStereoMultiviewVideo: string;

declare const AVMediaCharacteristicVoiceOverTranslation: string;

declare const AVMediaCharacteristicDescribesVideoForAccessibility: string;

declare const AVMediaCharacteristicEasyToRead: string;

declare const AVMediaCharacteristicDescribesMusicAndSoundForAccessibility: string;

declare const AVMediaCharacteristicTranscribesSpokenDialogForAccessibility: string;

declare const AVMetadataQuickTimeMetadataKeyInformation: string;

declare const AVMediaCharacteristicContainsOnlyForcedSubtitles: string;

declare const AVMediaCharacteristicIsAuxiliaryContent: string;

declare const AVMediaCharacteristicIsMainProgramContent: string;

declare const AVMediaCharacteristicContainsAlphaChannel: string;

declare const AVMediaCharacteristicContainsHDRVideo: string;

declare const AVMetadataIdentifierQuickTimeMetadataMake: string;

declare const AVMediaCharacteristicAudible: string;

declare const AVMediaTypeDepthData: string;

declare const AVMediaTypeMetadataObject: string;

declare const AVVideoRangePQ: string;

declare const AVMediaTypeMuxed: string;

declare const AVMediaTypeMetadata: string;

declare const AVMediaTypeTimecode: string;

declare const AVMediaTypeSubtitle: string;

declare const AVMediaTypeClosedCaption: string;

declare const AVMediaTypeText: string;

declare const AVMediaTypeVideo: string;

declare const AVAssetImageGeneratorDynamicRangePolicyForceSDR: string;

declare const AVMetadataQuickTimeMetadataKeyPerformer: string;

declare const AVContentKeyRequestShouldRandomizeDeviceIdentifierKey: string;

declare const AVContentKeyRequestRequiresValidationDataInSecureTokenKey: string;

declare const AVContentKeyRequestRetryReasonReceivedObsoleteContentKey: string;

declare const AVContentKeyRequestRetryReasonTimedOut: string;

declare const AVContentKeySessionServerPlaybackContextOptionServerChallenge: string;

declare const AVContentKeySessionServerPlaybackContextOptionProtocolVersions: string;

declare const AVContentKeySystemAuthorizationToken: string;

declare const AVContentKeySystemFairPlayStreaming: string;

declare const AVMetadataFormatHLSMetadata: string;

declare const AVCaptureReactionTypeLasers: string;

declare const AVMetadataFormatiTunesMetadata: string;

declare const AVMetadataObjectTypeHumanBody: string;

declare const AVVideoCodecTypeAppleProRes422Proxy: string;

declare const AVVideoCleanApertureHorizontalOffsetKey: string;

declare const AVMetadataID3MetadataKeyOriginalArtist: string;

declare const AVPlayerInterstitialEventMonitorCurrentEventSkippedNotification: string;

declare const AVPlayerAvailableHDRModesDidChangeNotification: string;

declare const AVAssetExportPresetLowQuality: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedCatBody: string;

declare const AVMetadataQuickTimeUserDataKeyOriginalArtist: string;

declare const AVMetadataIdentifierID3MetadataDate: string;

declare const AVMetadataIdentifierID3MetadataLeadPerformer: string;

declare const AVVideoApertureModeCleanAperture: string;

declare const AVMetadataIcyMetadataKeyStreamURL: string;

declare const AVTrackAssociationTypeRenderMetadataSource: string;

declare const AVVideoProfileLevelH264Baseline31: string;

declare const AVVideoCompressionPropertiesKey: string;

declare const AVMetadataiTunesMetadataKeySongID: string;

declare const AVMetadataIdentifierID3MetadataSize: string;

declare const AVMetadataObjectTypeUPCECode: string;

declare const AVMetadata3GPUserDataKeyUserRating: string;

declare const AVFileTypeAppleM4A: string;

declare const AVMetadataQuickTimeUserDataKeyArranger: string;

declare const AVMetadataCommonKeyLocation: string;

declare const AVMetadataIdentifierID3MetadataMusicCDIdentifier: string;

declare const AVMetadataIdentifierID3MetadataUniqueFileIdentifier: string;

declare const AVMetadataiTunesMetadataKeyAccountKind: string;

declare const AVMetadataIdentifierQuickTimeUserDataWriter: string;

declare const AVMetadataIdentifierID3MetadataOriginalArtist: string;

declare const AVAssetPlaybackConfigurationOptionStereoMultiviewVideo: string;

declare const AVMetadataCommonIdentifierPublisher: string;

declare const AVMetadataIdentifieriTunesMetadataLinerNotes: string;

declare const AVPlayerInterstitialEventMonitorInterstitialEventWasUnscheduledEventKey: string;

declare const AVMetadataIdentifierQuickTimeMetadataComposer: string;

declare const AVMetadataIdentifierID3MetadataPopularimeter: string;

declare const AVMetadataIdentifieriTunesMetadataContentRating: string;

declare const AVMetadataQuickTimeMetadataKeyLocationBody: string;

declare const AVMetadataIdentifieriTunesMetadataCoverArt: string;

declare const AVMetadataID3MetadataKeyInternationalStandardRecordingCode: string;

declare const AVMetadataIdentifierQuickTimeMetadataVideoOrientation: string;

declare const AVMetadataQuickTimeUserDataKeyGenre: string;

declare const AVMetadataIdentifierID3MetadataCopyrightInformation: string;

declare const AVMetadataIdentifieriTunesMetadataArranger: string;

declare const AVMetadataIdentifier3GPUserDataMediaRating: string;

declare const AVMetadataFormatQuickTimeMetadata: string;

declare const AVMetadataIdentifierQuickTimeMetadataComment: string;

declare const AVVideoColorPrimaries_SMPTE_C: string;

declare const AVLayerVideoGravityResize: string;

declare const AVCaptureSessionInterruptionSystemPressureStateKey: string;

declare const AVMetadataiTunesMetadataKeyEQ: string;

declare const AVMetadataIdentifierQuickTimeMetadataYear: string;

declare const AVMetadataIdentifieriTunesMetadataArtDirector: string;

declare const AVMetadataFormatISOUserData: string;

declare const AVMetadataID3MetadataKeyConductor: string;

declare const AVMetadataQuickTimeUserDataKeyWarning: string;

declare const AVAudioTimePitchAlgorithmLowQualityZeroLatency: string;

declare const AVMetadataIdentifierID3MetadataInvolvedPeopleList_v24: string;

declare const AVVideoTransferFunctionKey: string;

declare const AVFileTypeAppleiTT: string;

declare const AVMetadataIdentifierID3MetadataMood: string;

declare const AVCoordinatedPlaybackSuspensionReasonAudioSessionInterrupted: string;

declare const AVMetadataIdentifieriTunesMetadataOriginalArtist: string;

declare const AVMetadataIdentifierQuickTimeMetadataPublisher: string;

declare const AVMediaTypeAuxiliaryPicture: string;

declare const AVMetadataQuickTimeUserDataKeyCreationDate: string;

declare const AVURLAssetAllowsConstrainedNetworkAccessKey: string;

declare const AVMediaCharacteristicDubbedTranslation: string;

declare const AVVideoTransferFunction_ITU_R_2100_HLG: string;

declare const AVMetadataQuickTimeUserDataKeyTrack: string;

declare const AVMetadataID3MetadataKeyMPEGLocationLookupTable: string;

declare const AVSemanticSegmentationMatteTypeHair: string;

declare const AVMetadataQuickTimeMetadataKeyKeywords: string;

declare const AVCaptureSessionPreset1920x1080: string;

declare const AVMetadataiTunesMetadataKeyPhonogramRights: string;

declare const AVMetadataIdentifierQuickTimeMetadataAlbum: string;

declare const AVMetadataID3MetadataKeyLink: string;

declare const AVContentKeyRequestRandomDeviceIdentifierSeedKey: string;

declare const AVMetadataObjectTypeInterleaved2of5Code: string;

declare const AVMetadataIdentifierQuickTimeMetadataDescription: string;

declare const AVCaptureReactionTypeFireworks: string;

declare const AVAssetDownloadTaskMediaSelectionKey: string;

declare const AVCaptureWhiteBalanceTemperatureAndTintValuesShadow: AVCaptureWhiteBalanceTemperatureAndTintValues;

declare const AVMetadataIdentifierID3MetadataOriginalReleaseTime: string;

declare const AVCaptureSessionPreset1280x720: string;

declare const AVMetadataObjectTypeCodabarCode: string;

declare const AVMediaTypeAudio: string;

declare const AVMetadataQuickTimeUserDataKeyAuthor: string;

declare const AVMetadataIdentifierQuickTimeUserDataDisclaimer: string;

declare const AVVideoExpectedSourceFrameRateKey: string;

declare const AVAudioTimePitchAlgorithmVarispeed: string;

declare const AVMetadataExtraAttributeInfoKey: string;

declare const AVMetadataIdentifierQuickTimeMetadataGenre: string;

declare const AVMetadataIdentifieriTunesMetadataArtist: string;

declare const AVCaptureInputPortFormatDescriptionDidChangeNotification: string;

declare const AVMetadataIdentifier3GPUserDataTitle: string;

declare const AVSpatialCaptureDiscomfortReasonSubjectTooClose: string;

declare const AVMetadataIdentifieriTunesMetadataPhonogramRights: string;

declare const AVMetadata3GPUserDataKeyDescription: string;

declare const AVMetadataQuickTimeMetadataKeyProducer: string;

declare const AVMetadataObjectTypeDogHead: string;

declare const AVMetadataID3MetadataKeySubTitle: string;

declare const AVAssetExportPresetHEVC1920x1080WithAlpha: string;

declare const AVFileTypeProfileMPEG4AppleHLS: string;

declare const AVMetadataQuickTimeUserDataKeyTrackName: string;

declare const AVMetadataID3MetadataKeyProducedNotice: string;

declare const AVMetadataIdentifierQuickTimeMetadataOriginalArtist: string;

declare const AVMetadataiTunesMetadataKeyBeatsPerMin: string;

declare const AVMetadataID3MetadataKeySynchronizedTempoCodes: string;

declare const AVPlaybackCoordinatorSuspensionReasonsDidChangeNotification: string;

declare const AVContentKeyRequestRetryReasonReceivedResponseWithExpiredLease: string;

declare const AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChangeNotification: string;

declare const AVFileTypeQuickTimeMovie: string;

declare const AVContentKeyRequestProtocolVersionsKey: string;

declare const AVCaptureSessionWasInterruptedNotification: string;

declare const AVMetadataIdentifieriTunesMetadataSoloist: string;

declare const AVMetadataQuickTimeMetadataKeyComposer: string;

declare const AVMetadataiTunesMetadataKeyConductor: string;

declare const AVMetadataCommonKeyRelation: string;

declare const AVMetadataID3MetadataKeyEqualization: string;

declare const AVMetadataIdentifierID3MetadataEqualization: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraLensIrisFNumber: string;

declare const AVMediaCharacteristicEnhancesSpeechIntelligibility: string;

declare const AVMetadata3GPUserDataKeyPerformer: string;

declare const AVMetadataIdentifieriTunesMetadataSongName: string;

declare const AVMetadataQuickTimeUserDataKeyCopyright: string;

declare const AVMetadataIdentifierQuickTimeMetadataCreationDate: string;

declare const AVVideoCodecTypeAppleProRes4444XQ: string;

declare const AVMetadataIdentifierID3MetadataGroupIdentifier: string;

declare const AVCoordinatedPlaybackSuspensionReasonCoordinatedPlaybackNotPossible: string;

declare const AVMetadataID3MetadataKeyContentGroupDescription: string;

declare const AVMetadataIdentifierID3MetadataBeatsPerMinute: string;

declare const AVMetadata3GPUserDataKeyMediaRating: string;

declare const AVMetadataObjectTypeEAN8Code: string;

declare const AVCaptureDeviceTypeBuiltInWideAngleCamera: string;

declare const AVMetadataID3MetadataKeyOriginalFilename: string;

declare const AVPlayerItemDidPlayToEndTimeNotification: string;

declare const AVMetadataIdentifierQuickTimeUserDataTrack: string;

declare const AVCaptureSceneMonitoringStatusNotEnoughLight: string;

declare const AVMetadataFormatQuickTimeUserData: string;

declare const AVMetadataIdentifieriTunesMetadataProducer: string;

declare const AVAssetImageGeneratorDynamicRangePolicyMatchSource: string;

declare const AVMetadataIdentifier3GPUserDataMediaClassification: string;

declare const AVAssetExportPresetMVHEVC7680x7680: string;

declare const AVSemanticSegmentationMatteTypeTeeth: string;

declare const AVVideoMaxKeyFrameIntervalKey: string;

declare const AVMetadataiTunesMetadataKeyUserGenre: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraISOSensitivity: string;

declare const AVMetadataIdentifierID3MetadataOriginalAlbumTitle: string;

declare const AVMetadataIdentifieriTunesMetadataPredefinedGenre: string;

declare const AVMetadataIdentifierQuickTimeUserDataPerformers: string;

declare const AVMetadataIdentifierQuickTimeMetadataCinematicVideoIntent: string;

declare const AVMetadataID3MetadataKeyYear: string;

declare const AVMetadataIdentifierQuickTimeMetadataFullFrameRatePlaybackIntent: string;

declare const AVMetadataIdentifier3GPUserDataLocation: string;

declare const AVAudioTimePitchAlgorithmSpectral: string;

declare const AVMetadataQuickTimeMetadataKeyLocationNote: string;

declare const AVMovieShouldSupportAliasDataReferencesKey: string;

declare const AVMetadataQuickTimeUserDataKeyInformation: string;

declare const AVMetadataQuickTimeMetadataKeyCameraISOSensitivity: string;

declare const AVMetadataIdentifierID3MetadataTermsOfUse: string;

declare const AVMetadataIdentifier3GPUserDataKeywordList: string;

declare const AVMetadataIdentifierQuickTimeUserDataFullName: string;

declare const AVFileTypeHEIF: string;

declare const AVMetadataQuickTimeMetadataKeyWhiteBalanceByCCTWhiteBalanceFactors: string;

declare const AVCaptureDeviceTypeContinuityCamera: string;

declare const AVMediaCharacteristicLanguageTranslation: string;

declare const AVCaptureSessionRuntimeErrorNotification: string;

declare const AVMetadataCommonIdentifierAlbumName: string;

declare const AVMetadataIdentifierQuickTimeMetadataAuthor: string;

declare const AVMetadataQuickTimeMetadataKeyiXML: string;

declare const AVCaptureDeviceTypeBuiltInTelephotoCamera: string;

declare const AVPlayerInterstitialEventMonitorInterstitialEventWasUnscheduledNotification: string;

declare const AVMetadataiTunesMetadataKeyOnlineExtras: string;

declare const AVVideoRangeHLG: string;

declare const AVMetadataQuickTimeUserDataKeyKeywords: string;

declare const AVFileTypeAVCI: string;

declare const AVCaptureDeviceWasConnectedNotification: string;

declare const AVCaptureDeviceTypeBuiltInTripleCamera: string;

declare const AVMediaCharacteristicCarriesVideoStereoMetadata: string;

declare const AVMetadataCommonKeyPublisher: string;

declare const AVMetadataID3MetadataKeyGroupIdentifier: string;

declare const AVVideoH264EntropyModeCABAC: string;

declare const AVMetadataIdentifierQuickTimeMetadataSpatialOverCaptureQualityScore: string;

declare const AVMetadataIdentifierQuickTimeUserDataCredits: string;

declare const AVMetadataIdentifierQuickTimeMetadataAutoLivePhoto: string;

declare const AVMetadataCommonIdentifierCopyrights: string;

declare const AVAssetExportPresetAppleProRes422LPCM: string;

declare const AVPlayerInterstitialEventNoCue: string;

declare const AVMetadataID3MetadataKeyCommercial: string;

declare const AVMetadataObjectTypeMicroQRCode: string;

declare const AVAssetExportPresetMVHEVC4320x4320: string;

declare const AVMetadataQuickTimeMetadataKeyRatingUser: string;

declare const AVMetadataIdentifierID3MetadataEncodedWith: string;

declare const AVMetadataIdentifierID3MetadataInvolvedPeopleList_v23: string;

declare const AVMetadataCommonKeySource: string;

declare const AVMetadataID3MetadataKeyTaggingTime: string;

declare const AVMetadataISOUserDataKeyTaggedCharacteristic: string;

declare const AVMetadataIdentifierQuickTimeUserDataSpecialPlaybackRequirements: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationRole: string;

declare const AVMetadata3GPUserDataKeyRecordingYear: string;

declare const AVMetadataCommonIdentifierAccessibilityDescription: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraWhiteBalance: string;

declare const AVPlayerRateDidChangeReasonAppBackgrounded: string;

declare const AVPlayerItemFailedToPlayToEndTimeNotification: string;

declare const AVMetadataID3MetadataKeyPrivate: string;

declare const AVMetadataQuickTimeMetadataKeyArranger: string;

declare const AVMetadataKeySpaceCommon: string;

declare const AVMetadataIdentifierID3MetadataModifiedBy: string;

declare const AVMetadataID3MetadataKeyOfficialInternetRadioStationHomepage: string;

declare const AVMetadataID3MetadataKeyInitialKey: string;

declare const AVAssetResourceLoadingRequestStreamingContentKeyRequestRequiresPersistentKey: string;

declare const AVMetadataQuickTimeUserDataKeyCredits: string;

declare const AVCaptureSessionPresetLow: string;

declare const AVMetadataIdentifierQuickTimeUserDataLocationISO6709: string;

declare const AVCaptureDeviceTypeBuiltInLiDARDepthCamera: string;

declare const AVOutputSettingsPreset960x540: string;

declare const AVMetadataIdentifierQuickTimeMetadataKeywords: string;

declare const AVPlayerInterstitialEventMonitorEventsDidChangeNotification: string;

declare const AVCaptureSessionPreset3840x2160: string;

declare const AVMetadataCommonIdentifierFormat: string;

declare const AVMetadataIdentifieriTunesMetadataAuthor: string;

declare const AVVideoRangeSDR: string;

declare const AVLayerVideoGravityResizeAspect: string;

declare const AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChangeErrorKey: string;

declare const AVMetadataID3MetadataKeyComments: string;

declare const AVMetadataID3MetadataKeyEqualization2: string;

declare const AVCaptureReactionTypeBalloons: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedFace: string;

declare const AVFragmentedMovieContainsMovieFragmentsDidChangeNotification: string;

declare const AVMetadataObjectTypeITF14Code: string;

declare const AVMetadataQuickTimeMetadataKeyMake: string;

declare const AVMediaCharacteristicMachineGenerated: string;

declare const AVVideoHeightKey: string;

declare const AVMetadataIdentifierID3MetadataOfficialArtistWebpage: string;

declare const AVMetadata3GPUserDataKeyMediaClassification: string;

declare const AVMetadataID3MetadataKeyMusicianCreditsList: string;

declare const AVMetadataIdentifierISOUserDataDate: string;

declare const AVCaptionConversionAdjustmentTypeTimeRange: string;

declare const AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeEventKey: string;

declare const AVMetadataKeySpaceID3: string;

declare const AVMetadataID3MetadataKeySize: string;

declare const AVMetadataIdentifierQuickTimeMetadataDirectionMotion: string;

declare const AVMetadataIdentifierQuickTimeMetadataiXML: string;

declare const AVMetadataIdentifierQuickTimeUserDataChapter: string;

declare const AVMetadataIdentifier3GPUserDataAuthor: string;

declare const AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChangeEventKey: string;

declare const AVMetadataIdentifieriTunesMetadataLyrics: string;

declare const AVVideoH264EntropyModeCAVLC: string;

declare const AVMetadataQuickTimeMetadataKeyEncodedBy: string;

declare const AVMetadataQuickTimeUserDataKeyDisclaimer: string;

declare const AVMetadataCommonIdentifierCreator: string;

declare const AVMetadataQuickTimeUserDataKeyProducer: string;

declare const AVMetadataID3MetadataKeyReverb: string;

declare const AVVideoProfileLevelH264High41: string;

declare const AVMetadataID3MetadataKeyPopularimeter: string;

declare const AVMetadataCommonIdentifierArtist: string;

declare const AVMetadataKeySpaceAudioFile: string;

declare const AVMetadataiTunesMetadataKeyCredits: string;

declare const AVFileTypeProfileMPEG4CMAFCompliant: string;

declare const AVMediaCharacteristicFrameBased: string;

declare const AVMetadataObjectTypeMicroPDF417Code: string;

declare const AVMetadataObjectTypeFace: string;

declare const AVAssetExportPresetHEVCHighestQualityWithAlpha: string;

declare const AVMetadataIdentifierID3MetadataOriginalFilename: string;

declare const AVMetadataQuickTimeMetadataKeySoftware: string;

declare const AVCoreAnimationBeginTimeAtZero: number;

declare const AVMetadataQuickTimeMetadataKeyYear: string;

declare const AVCaptureDeviceWasDisconnectedNotification: string;

declare const AVMetadataIdentifieriTunesMetadataArtistID: string;

declare const AVCaptureReactionTypeThumbsDown: string;

declare const AVPlayerItemMediaSelectionDidChangeNotification: string;

declare const AVMetadataIdentifierID3MetadataSubTitle: string;

declare const AVVideoCleanApertureVerticalOffsetKey: string;

declare const AVAssetChapterMetadataGroupsDidChangeNotification: string;

declare const AVCaptionTimeCodeFrameDurationKey: string;

declare const AVMetadataID3MetadataKeyTitleSortOrder: string;

declare const AVCaptionMediaSubTypeKey: string;

declare const AVPlayerRateDidChangeReasonKey: string;

declare const AVVideoQualityKey: string;

declare const AVMetadataQuickTimeMetadataKeyComment: string;

declare const AVMetadataIdentifierQuickTimeUserDataMake: string;

declare const AVMetadataFormatID3Metadata: string;

declare const AVCaptureSessionPresetInputPriority: string;

declare const AVVideoCodecJPEG: string;

declare const AVMediaCharacteristicLegible: string;

declare const AVMetadataIdentifierID3MetadataOriginalLyricist: string;

declare const AVErrorTimeKey: string;

declare const AVVideoCodecTypeH264: string;

declare const AVMetadataID3MetadataKeyPlayCounter: string;

declare const AVMetadataIdentifieriTunesMetadataGrouping: string;

declare const AVMetadataIdentifieriTunesMetadataAppleID: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationName: string;

declare const AVMetadataQuickTimeUserDataKeyWriter: string;

declare const AVMetadataIdentifierID3MetadataLink: string;

declare const AVMetadataCommonKeyCreator: string;

declare const AVVideoCodecTypeAppleProRes422HQ: string;

declare const AVVideoScalingModeResizeAspectFill: string;

declare const AVMetadataiTunesMetadataKeyPlaylistID: string;

declare const AVOutputSettingsPresetMVHEVC7680x7680: string;

declare const AVMetadataCommonIdentifierLanguage: string;

declare const AVMetadataiTunesMetadataKeyOriginalArtist: string;

declare const AVMetadataID3MetadataKeyRecordingDates: string;

declare const AVStreamingKeyDeliveryPersistentContentKeyType: string;

declare const AVMetadataObjectTypeCode93Code: string;

declare const AVMetadataiTunesMetadataKeyCoverArt: string;

declare const AVSampleBufferDisplayLayerFailedToDecodeNotificationErrorKey: string;

declare const AVCaptureSessionPreset352x288: string;

declare const AVMetadataIdentifierID3MetadataUserText: string;

declare const AVMetadataIdentifieriTunesMetadataOnlineExtras: string;

declare const AVURLAssetAllowsCellularAccessKey: string;

declare const AVMetadataIdentifierID3MetadataTitleSortOrder: string;

declare const AVMetadataIdentifierID3MetadataLength: string;

declare const AVMetadataIdentifierQuickTimeUserDataTaggedCharacteristic: string;

declare const AVMetadataID3MetadataKeyTermsOfUse: string;

declare const AVAssetWasDefragmentedNotification: string;

declare const AVPlayerInterstitialEventMonitorInterstitialEventDidFinishEventKey: string;

declare const AVVideoTransferFunction_Linear: string;

declare const AVMetadataID3MetadataKeyOriginalReleaseYear: string;

declare const AVMetadataIdentifierQuickTimeMetadataLivePhotoVitalityScore: string;

declare const AVAssetDownloadedAssetEvictionPriorityImportant: string;

declare const AVMetadataIdentifierID3MetadataMPEGLocationLookupTable: string;

declare const AVVideoCleanApertureWidthKey: string;

declare const AVMetadataQuickTimeUserDataKeyComment: string;

declare const AVMetadataIdentifieriTunesMetadataDescription: string;

declare const AVMetadataCommonIdentifierArtwork: string;

declare const AVMetadataCommonKeyCopyrights: string;

declare const AVOutputSettingsPresetHEVC7680x4320: string;

declare const AVMetadataCommonIdentifierAssetIdentifier: string;

declare const AVCaptureLensPositionCurrent: number;

declare const AVFileType3GPP2: string;

declare const AVMetadataCommonKeyTitle: string;

declare const AVMetadataObjectTypeEAN13Code: string;

declare const AVMetadataID3MetadataKeyEncodedBy: string;

declare const AVCaptureSessionDidStopRunningNotification: string;

declare const AVMetadataID3MetadataKeyBeatsPerMinute: string;

declare const AVSampleBufferDisplayLayerReadyForDisplayDidChangeNotification: string;

declare const AVMetadataiTunesMetadataKeyAuthor: string;

declare const AVCaptureSessionPresetiFrame960x540: string;

declare const AVMetadataQuickTimeMetadataKeyCredits: string;

declare const AVVideoTransferFunction_ITU_R_709_2: string;

declare const AVMetadataID3MetadataKeyInvolvedPeopleList_v24: string;

declare const AVMetadataID3MetadataKeyAttachedPicture: string;

declare const AVMetadataCommonIdentifierSubject: string;

declare const AVMetadataIdentifierQuickTimeUserDataOriginalFormat: string;

declare const AVMetadataIdentifierID3MetadataYear: string;

declare const AVVideoCodecTypeAppleProRes4444: string;

declare const AVCaptureSystemPressureLevelNominal: string;

declare const AVLayerVideoGravityResizeAspectFill: string;

declare const AVSemanticSegmentationMatteTypeGlasses: string;

declare const AVMetadataIdentifierQuickTimeUserDataOriginalSource: string;

declare const AVMetadataIdentifierQuickTimeUserDataDirector: string;

declare const AVMetadataQuickTimeUserDataKeyAccessibilityDescription: string;

declare const AVVideoCleanApertureHeightKey: string;

declare const AVMetadataCommonKeyMake: string;

declare const AVVideoCodecTypeHEVC: string;

declare const AVCoordinatedPlaybackSuspensionReasonUserIsChangingCurrentTime: string;

declare const AVMetadataID3MetadataKeyMood: string;

declare const AVMetadataIdentifier3GPUserDataPerformer: string;

declare const AVMetadataQuickTimeMetadataKeyCameraLensModel: string;

declare const AVMetadataIdentifierID3MetadataContentType: string;

declare const AVMetadataIdentifierIcyMetadataStreamURL: string;

declare const AVMetadataQuickTimeMetadataKeyDisplayName: string;

declare const AVMediaCharacteristicIsOriginalContent: string;

declare const AVMetadataID3MetadataKeyOriginalAlbumTitle: string;

declare const AVMetadataKeySpaceQuickTimeUserData: string;

declare const AVMetadataKeySpaceIcy: string;

declare const AVMetadataID3MetadataKeyReleaseTime: string;

declare const AVMetadataIdentifieriTunesMetadataExecProducer: string;

declare const AVMetadataIdentifierID3MetadataContentGroupDescription: string;

declare const AVVideoCleanApertureKey: string;

declare const AVMetadataID3MetadataKeyGeneralEncapsulatedObject: string;

declare const AVMetadata3GPUserDataKeyGenre: string;

declare const AVMetadataIdentifieriTunesMetadataAlbumArtist: string;

declare const AVMetadataIdentifierQuickTimeUserDataURLLink: string;

declare const AVMetadataQuickTimeMetadataKeyLocationDate: string;

declare const AVOutputSettingsPresetHEVC4320x2160: string;

declare const AVMetadataQuickTimeUserDataKeyComposer: string;

declare const AVFileTypeEnhancedAC3: string;

declare const AVOutputSettingsPreset1920x1080: string;

declare const AVFileTypeAIFF: string;

declare const AVMetadataID3MetadataKeySeek: string;

declare const AVVideoPixelAspectRatioKey: string;

declare const AVMetadataIdentifierID3MetadataPublisher: string;

declare const AVMetadataIdentifierID3MetadataOfficialPublisherWebpage: string;

declare const AVMetadataISOUserDataKeyCopyright: string;

declare const AVMetadataiTunesMetadataKeyEncodedBy: string;

declare const AVOutputSettingsPresetHEVC1920x1080WithAlpha: string;

declare const AVMetadataIdentifierID3MetadataPerformerSortOrder: string;

declare const AVMetadata3GPUserDataKeyKeywordList: string;

declare const AVAssetContainsFragmentsDidChangeNotification: string;

declare const AVMetadataIdentifierQuickTimeUserDataTrackName: string;

declare const AVCaptureSystemPressureLevelCritical: string;

declare const AVMetadataCommonKeyAccessibilityDescription: string;

declare const AVMediaCharacteristicVisual: string;

declare const AVFileTypeWAVE: string;

declare const AVMetadataIdentifierID3MetadataEncodedBy: string;

declare const AVMetadataID3MetadataKeyFileType: string;

declare const AVMetadataiTunesMetadataKeyGenreID: string;

declare const AVMetadataID3MetadataKeyEventTimingCodes: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraFocalLength35mmEquivalent: string;

declare const AVCoordinatedPlaybackSuspensionReasonStallRecovery: string;

declare const AVCaptureExposureTargetBiasCurrent: number;

declare const AVMetadataIdentifierQuickTimeMetadataIsMontage: string;

declare const AVVideoCompositionPerFrameHDRDisplayMetadataPolicyGenerate: string;

declare const AVFileTypeDNG: string;

declare const AVMetadataiTunesMetadataKeyArtDirector: string;

declare const AVMetadataIdentifier3GPUserDataAlbumAndTrack: string;

declare const AVSampleBufferAudioRendererWasFlushedAutomaticallyNotification: string;

declare const AVFragmentedMovieTrackSegmentsDidChangeNotification: string;

declare const AVErrorMediaTypeKey: string;

declare const AVCaptionConversionWarningTypeExcessMediaData: string;

declare const AVMetadataIdentifierID3MetadataAlbumSortOrder: string;

declare const AVVideoCodecTypeHEVCWithAlpha: string;

declare const AVMetadataIdentifierID3MetadataReverb: string;

declare const AVMetadataiTunesMetadataKeyUserComment: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncReasonSegmentsChanged: string;

declare const AVCapturePhotoQualityPrioritization: {
  Speed: 1,
  Balanced: 2,
  Quality: 3,
};

declare const AVDepthDataAccuracy: {
  Relative: 0,
  Absolute: 1,
};

declare const AVDepthDataQuality: {
  Low: 0,
  High: 1,
};

declare const AVCaptureTimecodeGeneratorSynchronizationStatus: {
  Unknown: 0,
  SourceSelected: 1,
  Synchronizing: 2,
  Synchronized: 3,
  TimedOut: 4,
  SourceUnavailable: 5,
  SourceUnsupported: 6,
  NotRequired: 7,
};

declare const AVCaptureTimecodeSourceType: {
  FrameCount: 0,
  RealTimeClock: 1,
  External: 2,
};

declare const AVCaptureMultichannelAudioMode: {
  None: 0,
  Stereo: 1,
  FirstOrderAmbisonics: 2,
};

declare const AVExternalSyncDeviceStatus: {
  Unavailable: 0,
  Ready: 1,
  Calibrating: 2,
  ActiveSync: 3,
  FreeRunSync: 4,
};

declare const AVCaptureLensStabilizationStatus: {
  Unsupported: 0,
  Off: 1,
  Active: 2,
  OutOfRange: 3,
  Unavailable: 4,
};

declare const AVCapturePhotoOutputCaptureReadiness: {
  SessionNotRunning: 0,
  Ready: 1,
  NotReadyMomentarily: 2,
  NotReadyWaitingForCapture: 3,
  NotReadyWaitingForProcessing: 4,
};

declare const AVCaptureOutputDataDroppedReason: {
  None: 0,
  LateData: 1,
  OutOfBuffers: 2,
  Discontinuity: 3,
};

declare const AVCaptureSessionInterruptionReason: {
  VideoDeviceNotAvailableInBackground: 1,
  AudioDeviceInUseByAnotherClient: 2,
  VideoDeviceInUseByAnotherClient: 3,
  VideoDeviceNotAvailableWithMultipleForegroundApps: 4,
  VideoDeviceNotAvailableDueToSystemPressure: 5,
  SensitiveContentMitigationActivated: 6,
};

declare const AVCaptureCameraLensSmudgeDetectionStatus: {
  Disabled: 0,
  SmudgeNotDetected: 1,
  Smudged: 2,
  Unknown: 3,
};

declare const AVCaptureAutoFocusSystem: {
  None: 0,
  ContrastDetection: 1,
  PhaseDetection: 2,
};

declare const AVCaptureVideoStabilizationMode: {
  Off: 0,
  Standard: 1,
  Cinematic: 2,
  CinematicExtended: 3,
  PreviewOptimized: 4,
  CinematicExtendedEnhanced: 5,
  LowLatency: 6,
  Auto: -1,
};

declare const AVCaptureDevicePosition: {
  Unspecified: 0,
  Back: 1,
  Front: 2,
};

declare const AVCaptureSystemUserInterface: {
  VideoEffects: 1,
  MicrophoneModes: 2,
};

declare const AVCaptureMicrophoneMode: {
  Standard: 0,
  WideSpectrum: 1,
  VoiceIsolation: 2,
};

declare const AVAuthorizationStatus: {
  NotDetermined: 0,
  Restricted: 1,
  Denied: 2,
  Authorized: 3,
};

declare const AVCaptureWhiteBalanceMode: {
  Locked: 0,
  AutoWhiteBalance: 1,
  ContinuousAutoWhiteBalance: 2,
};

declare const AVCaptureExposureMode: {
  Locked: 0,
  AutoExpose: 1,
  ContinuousAutoExposure: 2,
  Custom: 3,
};

declare const AVCaptureFocusMode: {
  Locked: 0,
  AutoFocus: 1,
  ContinuousAutoFocus: 2,
};

declare const AVCaptureTorchMode: {
  Off: 0,
  On: 1,
  Auto: 2,
};

declare const AVCaptureFlashMode: {
  Off: 0,
  On: 1,
  Auto: 2,
};

declare const AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions: {
  None: 0,
  VideoZoomChanged: 1,
  FocusModeChanged: 2,
  ExposureModeChanged: 4,
};

declare const AVSampleBufferRequestDirection: {
  Forward: 1,
  None: 0,
  Reverse: -1,
};

declare const AVQueuedSampleBufferRenderingStatus: {
  Unknown: 0,
  Rendering: 1,
  Failed: 2,
};

declare const AVCaptureAutoFocusRangeRestriction: {
  None: 0,
  Near: 1,
  Far: 2,
};

declare const AVPlayerInterstitialEventTimelineOccupancy: {
  SinglePoint: 0,
  Fill: 1,
};

declare const AVPlayerInterstitialEventRestrictions: {
  None: 0,
  ConstrainsSeekingForwardInPrimaryContent: 1,
  RequiresPlaybackAtPreferredRateForAdvancement: 4,
  DefaultPolicy: 0,
};

declare const AVPlayerLooperItemOrdering: {
  Precede: 0,
  Follow: 1,
};

declare const AVPlayerLooperStatus: {
  Unknown: 0,
  Ready: 1,
  Failed: 2,
  Cancelled: 3,
};

declare const AVVariantPreferences: {
  None: 0,
  ScalabilityToLosslessAudio: 1,
};

declare const AVPlayerItemStatus: {
  Unknown: 0,
  ReadyToPlay: 1,
  Failed: 2,
};

declare const AVDelegatingPlaybackCoordinatorSeekOptions: {
  AVDelegatingPlaybackCoordinatorSeekOptionResumeImmediately: 1,
};

declare const AVPlayerHDRMode: {
  HLG: 1,
  HDR10: 2,
  DolbyVision: 4,
};

declare const AVPlayerTimeControlStatus: {
  Paused: 0,
  WaitingToPlayAtSpecifiedRate: 1,
  Playing: 2,
};

declare const AVPlayerStatus: {
  Unknown: 0,
  ReadyToPlay: 1,
  Failed: 2,
};

declare const AVError: {
  Unknown: -11800,
  OutOfMemory: -11801,
  SessionNotRunning: -11803,
  DeviceAlreadyUsedByAnotherSession: -11804,
  NoDataCaptured: -11805,
  SessionConfigurationChanged: -11806,
  DiskFull: -11807,
  DeviceWasDisconnected: -11808,
  MediaChanged: -11809,
  MaximumDurationReached: -11810,
  MaximumFileSizeReached: -11811,
  MediaDiscontinuity: -11812,
  MaximumNumberOfSamplesForFileFormatReached: -11813,
  DeviceNotConnected: -11814,
  DeviceInUseByAnotherApplication: -11815,
  DeviceLockedForConfigurationByAnotherProcess: -11817,
  SessionWasInterrupted: -11818,
  MediaServicesWereReset: -11819,
  ExportFailed: -11820,
  DecodeFailed: -11821,
  InvalidSourceMedia: -11822,
  FileAlreadyExists: -11823,
  CompositionTrackSegmentsNotContiguous: -11824,
  InvalidCompositionTrackSegmentDuration: -11825,
  InvalidCompositionTrackSegmentSourceStartTime: -11826,
  InvalidCompositionTrackSegmentSourceDuration: -11827,
  FileFormatNotRecognized: -11828,
  FileFailedToParse: -11829,
  MaximumStillImageCaptureRequestsExceeded: -11830,
  ContentIsProtected: -11831,
  NoImageAtTime: -11832,
  DecoderNotFound: -11833,
  EncoderNotFound: -11834,
  ContentIsNotAuthorized: -11835,
  ApplicationIsNotAuthorized: -11836,
  DeviceIsNotAvailableInBackground: -11837,
  OperationNotSupportedForAsset: -11838,
  DecoderTemporarilyUnavailable: -11839,
  EncoderTemporarilyUnavailable: -11840,
  InvalidVideoComposition: -11841,
  ReferenceForbiddenByReferencePolicy: -11842,
  InvalidOutputURLPathExtension: -11843,
  ScreenCaptureFailed: -11844,
  DisplayWasDisabled: -11845,
  TorchLevelUnavailable: -11846,
  OperationInterrupted: -11847,
  IncompatibleAsset: -11848,
  FailedToLoadMediaData: -11849,
  ServerIncorrectlyConfigured: -11850,
  ApplicationIsNotAuthorizedToUseDevice: -11852,
  FailedToParse: -11853,
  FileTypeDoesNotSupportSampleReferences: -11854,
  UndecodableMediaData: -11855,
  AirPlayControllerRequiresInternet: -11856,
  AirPlayReceiverRequiresInternet: -11857,
  VideoCompositorFailed: -11858,
  RecordingAlreadyInProgress: -11859,
  UnsupportedOutputSettings: -11861,
  OperationNotAllowed: -11862,
  ContentIsUnavailable: -11863,
  FormatUnsupported: -11864,
  MalformedDepth: -11865,
  ContentNotUpdated: -11866,
  NoLongerPlayable: -11867,
  NoCompatibleAlternatesForExternalDisplay: -11868,
  NoSourceTrack: -11869,
  ExternalPlaybackNotSupportedForAsset: -11870,
  OperationNotSupportedForPreset: -11871,
  SessionHardwareCostOverage: -11872,
  UnsupportedDeviceActiveFormat: -11873,
  IncorrectlyConfigured: -11875,
  SegmentStartedWithNonSyncSample: -11876,
  RosettaNotInstalled: -11877,
  OperationCancelled: -11878,
  ContentKeyRequestCancelled: -11879,
  InvalidSampleCursor: -11880,
  FailedToLoadSampleData: -11881,
  AirPlayReceiverTemporarilyUnavailable: -11882,
  EncodeFailed: -11883,
  SandboxExtensionDenied: -11884,
  ToneMappingFailed: -11885,
  NoSmartFramingsEnabled: -11890,
  AutoWhiteBalanceNotLocked: -11891,
  FollowExternalSyncDeviceTimedOut: -11892,
};

declare const AVCaptionConversionValidatorStatus: {
  Unknown: 0,
  Validating: 1,
  Completed: 2,
  Stopped: 3,
};

declare const AVCaptionRubyAlignment: {
  Start: 0,
  Center: 1,
  DistributeSpaceBetween: 2,
  DistributeSpaceAround: 3,
};

declare const AVCaptionDecoration: {
  None: 0,
  Underline: 1,
  LineThrough: 2,
  Overline: 4,
};

declare const AVCaptionAnimation: {
  None: 0,
  CharacterReveal: 1,
};

declare const AVCaptionRegionScroll: {
  None: 0,
  RollUp: 1,
};

declare const AVCaptionRegionWritingMode: {
  LeftToRightAndTopToBottom: 0,
  TopToBottomAndRightToLeft: 2,
};

declare const AVCaptionUnitsType: {
  Unspecified: 0,
  Cells: 1,
  Percent: 2,
};

declare const AVAssetSegmentType: {
  Initialization: 1,
  Separable: 2,
};

declare const AVAssetReferenceRestrictions: {
  ForbidNone: 0,
  ForbidRemoteReferenceToLocal: 1,
  ForbidLocalReferenceToRemote: 2,
  ForbidCrossSiteReference: 4,
  ForbidLocalReferenceToLocal: 8,
  ForbidAll: 65535,
  DefaultPolicy: 2,
};

declare const AVExternalContentProtectionStatus: {
  Pending: 0,
  Sufficient: 1,
  Insufficient: 2,
};

declare const AVKeyValueStatus: {
  Unknown: 0,
  Loading: 1,
  Loaded: 2,
  Failed: 3,
  Cancelled: 4,
};

declare const AVPlayerItemSegmentType: {
  Primary: 0,
  Interstitial: 1,
};

declare const AVAssetExportSessionStatus: {
  Unknown: 0,
  Waiting: 1,
  Exporting: 2,
  Completed: 3,
  Failed: 4,
  Cancelled: 5,
};

declare const AVCaptionTextCombine: {
  All: -1,
  None: 0,
  OneDigit: 1,
  TwoDigits: 2,
  ThreeDigits: 3,
  FourDigits: 4,
};

declare const AVPlayerInterstitialEventAssetListResponseStatus: {
  Available: 0,
  Cleared: 1,
  Unavailable: 2,
};

declare const AVContentKeyRequestStatus: {
  RequestingResponse: 0,
  ReceivedResponse: 1,
  Renewed: 2,
  Retried: 3,
  Cancelled: 4,
  Failed: 5,
};

declare const AVCaptionRegionDisplayAlignment: {
  Before: 0,
  Center: 1,
  After: 2,
};

declare const AVAudioSpatializationFormats: {
  None: 0,
  MonoAndStereo: 3,
  Multichannel: 4,
  MonoStereoAndMultichannel: 7,
};

declare const AVSampleBufferRequestMode: {
  Immediate: 0,
  Scheduled: 1,
  Opportunistic: 2,
};

declare const AVPlayerInterstitialEventSkippableEventState: {
  NotSkippable: 0,
  NotYetEligible: 1,
  Eligible: 2,
  NoLongerEligible: 3,
};

declare const AVCaptionFontWeight: {
  Unknown: 0,
  Normal: 1,
  Bold: 2,
};

declare const AVPlayerAudiovisualBackgroundPlaybackPolicy: {
  Automatic: 1,
  Pauses: 2,
  ContinuesIfPossible: 3,
};

declare const AVAssetImageGeneratorResult: {
  Succeeded: 0,
  Failed: 1,
  Cancelled: 2,
};

declare const AVCaptionRubyPosition: {
  Before: 0,
  After: 1,
};

declare const AVAssetTrackGroupOutputHandling: {
  None: 0,
  PreserveAlternateTracks: 1,
  DefaultPolicy: 0,
};

declare const AVCaptionTextAlignment: {
  Start: 0,
  End: 1,
  Center: 2,
  Left: 3,
  Right: 4,
};

declare const AVCapturePrimaryConstituentDeviceSwitchingBehavior: {
  Unsupported: 0,
  Auto: 1,
  Restricted: 2,
  Locked: 3,
};

declare const AVPlayerNetworkResourcePriority: {
  Default: 0,
  Low: 1,
  High: 2,
};

declare const AVCaptureCinematicVideoFocusMode: {
  None: 0,
  Strong: 1,
  Weak: 2,
};

declare const AVAssetReaderStatus: {
  Unknown: 0,
  Reading: 1,
  Completed: 2,
  Failed: 3,
  Cancelled: 4,
};

declare const AVAssetWriterStatus: {
  Unknown: 0,
  Writing: 1,
  Completed: 2,
  Failed: 3,
  Cancelled: 4,
};

declare const AVPlayerActionAtItemEnd: {
  Advance: 0,
  Pause: 1,
  None: 2,
};

declare const AVCaptureColorSpace: {
  Space_sRGB: 0,
  Space_P3_D65: 1,
  Space_HLG_BT2020: 2,
  Space_AppleLog: 3,
  Space_AppleLog2: 4,
};

declare const AVCaptureVideoOrientation: {
  Portrait: 1,
  PortraitUpsideDown: 2,
  LandscapeRight: 3,
  LandscapeLeft: 4,
};

declare const AVDelegatingPlaybackCoordinatorRateChangeOptions: {
  AVDelegatingPlaybackCoordinatorRateChangeOptionPlayImmediately: 1,
};

declare const AVCaptureCenterStageControlMode: {
  User: 0,
  App: 1,
  Cooperative: 2,
};

declare const AVCaptionFontStyle: {
  Unknown: 0,
  Normal: 1,
  Italic: 2,
};

declare const CMTagCollectionVideoOutputPreset: {
  Monoscopic: 0,
  Stereoscopic: 1,
};

declare const AVCaptureSystemPressureFactors: {
  None: 0,
  SystemTemperature: 1,
  PeakPower: 2,
  DepthModuleTemperature: 4,
  CameraTemperature: 8,
};

declare const AVMovieWritingOptions: {
  AddMovieHeaderToDestination: 0,
  TruncateDestinationToMovieHeaderOnly: 1,
};

declare class AVCaptureTimecode {
  constructor(init?: AVCaptureTimecode);
  hours: number;
  minutes: number;
  seconds: number;
  frames: number;
  userBits: number;
  frameDuration: CMTime;
  sourceType: interop.Enum<typeof AVCaptureTimecodeSourceType>;
}

declare class AVCaptureWhiteBalanceTemperatureAndTintValues {
  constructor(init?: AVCaptureWhiteBalanceTemperatureAndTintValues);
  temperature: number;
  tint: number;
}

declare class AVCaptureWhiteBalanceChromaticityValues {
  constructor(init?: AVCaptureWhiteBalanceChromaticityValues);
  x: number;
  y: number;
}

declare class AVCaptureWhiteBalanceGains {
  constructor(init?: AVCaptureWhiteBalanceGains);
  redGain: number;
  greenGain: number;
  blueGain: number;
}

declare class AVSampleCursorChunkInfo {
  constructor(init?: AVSampleCursorChunkInfo);
  chunkSampleCount: number;
  chunkHasUniformSampleSizes: boolean;
  chunkHasUniformSampleDurations: boolean;
  chunkHasUniformFormatDescriptions: boolean;
}

declare class AVSampleCursorStorageRange {
  constructor(init?: AVSampleCursorStorageRange);
  offset: number;
  length: number;
}

declare class AVSampleCursorAudioDependencyInfo {
  constructor(init?: AVSampleCursorAudioDependencyInfo);
  audioSampleIsIndependentlyDecodable: boolean;
  audioSamplePacketRefreshCount: number;
}

declare class AVSampleCursorDependencyInfo {
  constructor(init?: AVSampleCursorDependencyInfo);
  sampleIndicatesWhetherItHasDependentSamples: boolean;
  sampleHasDependentSamples: boolean;
  sampleIndicatesWhetherItDependsOnOthers: boolean;
  sampleDependsOnOthers: boolean;
  sampleIndicatesWhetherItHasRedundantCoding: boolean;
  sampleHasRedundantCoding: boolean;
}

declare class AVCaptionSize {
  constructor(init?: AVCaptionSize);
  width: AVCaptionDimension;
  height: AVCaptionDimension;
}

declare class AVCaptionPoint {
  constructor(init?: AVCaptionPoint);
  x: AVCaptionDimension;
  y: AVCaptionDimension;
}

declare class AVEdgeWidths {
  constructor(init?: AVEdgeWidths);
  left: number;
  top: number;
  right: number;
  bottom: number;
}

declare class AVPixelAspectRatio {
  constructor(init?: AVPixelAspectRatio);
  horizontalSpacing: number;
  verticalSpacing: number;
}

declare class AVSampleCursorSyncInfo {
  constructor(init?: AVSampleCursorSyncInfo);
  sampleIsFullSync: boolean;
  sampleIsPartialSync: boolean;
  sampleIsDroppable: boolean;
}

declare class AVCaptionDimension {
  constructor(init?: AVCaptionDimension);
  value: number;
  units: interop.Enum<typeof AVCaptionUnitsType>;
}

declare function AVSampleBufferAttachContentKey(sbuf: interop.Object, contentKey: AVContentKey, outError: interop.PointerConvertible): boolean;

declare function AVCaptionDimensionMake(value: number, units: interop.Enum<typeof AVCaptionUnitsType>): AVCaptionDimension;

declare function AVCaptionPointMake(x: AVCaptionDimension, y: AVCaptionDimension): AVCaptionPoint;

declare function AVCaptionSizeMake(width: AVCaptionDimension, height: AVCaptionDimension): AVCaptionSize;

declare function AVMakeRectWithAspectRatioInsideRect(aspectRatio: CGSize, boundingRect: CGRect): CGRect;

declare function CMTagCollectionCreateWithVideoOutputPreset(allocator: interop.Object, preset: interop.Enum<typeof CMTagCollectionVideoOutputPreset>, newCollectionOut: interop.PointerConvertible): number;

declare function AVCaptureReactionSystemImageNameForType(reactionType: string): string;

declare function AVCaptureTimecodeCreateMetadataSampleBufferAssociatedWithPresentationTimeStamp(timecode: AVCaptureTimecode, presentationTimeStamp: CMTime): interop.Object;

declare function AVCaptureTimecodeCreateMetadataSampleBufferForDuration(timecode: AVCaptureTimecode, duration: CMTime): interop.Object;

declare function AVCaptureTimecodeAdvancedByFrames(timecode: AVCaptureTimecode, framesToAdd: number): AVCaptureTimecode;

declare interface AVExternalSyncDeviceDelegate extends NSObjectProtocol {
  externalSyncDeviceStatusDidChange?(device: AVExternalSyncDevice): void;

  externalSyncDeviceFailedWithError?(device: AVExternalSyncDevice, error: NSError | null): void;
}

declare class AVExternalSyncDeviceDelegate extends NativeObject implements AVExternalSyncDeviceDelegate {
}

declare interface AVCapturePhotoFileDataRepresentationCustomizer extends NSObjectProtocol {
  replacementMetadataForPhoto?(photo: AVCapturePhoto): NSDictionary;

  replacementEmbeddedThumbnailPixelBufferWithPhotoFormatForPhoto?(replacementEmbeddedThumbnailPhotoFormatOut: interop.PointerConvertible, photo: AVCapturePhoto): interop.Object;

  replacementDepthDataForPhoto?(photo: AVCapturePhoto): AVDepthData;

  replacementPortraitEffectsMatteForPhoto?(photo: AVCapturePhoto): AVPortraitEffectsMatte;

  replacementSemanticSegmentationMatteOfTypeForPhoto?(semanticSegmentationMatteType: string, photo: AVCapturePhoto): AVSemanticSegmentationMatte;

  replacementAppleProRAWCompressionSettingsForPhotoDefaultSettingsMaximumBitDepth?(photo: AVCapturePhoto, defaultSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, maximumBitDepth: number): NSDictionary;
}

declare class AVCapturePhotoFileDataRepresentationCustomizer extends NativeObject implements AVCapturePhotoFileDataRepresentationCustomizer {
}

declare interface AVCaptureTimecodeGeneratorDelegate extends NSObjectProtocol {
  timecodeGeneratorDidReceiveUpdateFromSource(generator: AVCaptureTimecodeGenerator, timecode: AVCaptureTimecode, source: AVCaptureTimecodeSource): void;

  timecodeGeneratorTransitionedToSynchronizationStatusForSource(generator: AVCaptureTimecodeGenerator, synchronizationStatus: interop.Enum<typeof AVCaptureTimecodeGeneratorSynchronizationStatus>, source: AVCaptureTimecodeSource): void;

  timecodeGeneratorDidUpdateAvailableSources(generator: AVCaptureTimecodeGenerator, availableSources: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVCaptureTimecodeGeneratorDelegate extends NativeObject implements AVCaptureTimecodeGeneratorDelegate {
}

declare interface AVCaptureDataOutputSynchronizerDelegate extends NSObjectProtocol {
  dataOutputSynchronizerDidOutputSynchronizedDataCollection(synchronizer: AVCaptureDataOutputSynchronizer, synchronizedDataCollection: AVCaptureSynchronizedDataCollection): void;
}

declare class AVCaptureDataOutputSynchronizerDelegate extends NativeObject implements AVCaptureDataOutputSynchronizerDelegate {
}

declare interface AVCaptureVideoDataOutputSampleBufferDelegate extends NSObjectProtocol {
  captureOutputDidOutputSampleBufferFromConnection?(output: AVCaptureOutput, sampleBuffer: interop.Object, connection: AVCaptureConnection): void;

  captureOutputDidDropSampleBufferFromConnection?(output: AVCaptureOutput, sampleBuffer: interop.Object, connection: AVCaptureConnection): void;
}

declare class AVCaptureVideoDataOutputSampleBufferDelegate extends NativeObject implements AVCaptureVideoDataOutputSampleBufferDelegate {
}

declare interface AVCaptureDepthDataOutputDelegate extends NSObjectProtocol {
  depthDataOutputDidOutputDepthDataTimestampConnection?(output: AVCaptureDepthDataOutput, depthData: AVDepthData, timestamp: CMTime, connection: AVCaptureConnection): void;

  depthDataOutputDidDropDepthDataTimestampConnectionReason?(output: AVCaptureDepthDataOutput, depthData: AVDepthData, timestamp: CMTime, connection: AVCaptureConnection, reason: interop.Enum<typeof AVCaptureOutputDataDroppedReason>): void;
}

declare class AVCaptureDepthDataOutputDelegate extends NativeObject implements AVCaptureDepthDataOutputDelegate {
}

declare interface AVCaptureAudioDataOutputSampleBufferDelegate extends NSObjectProtocol {
  captureOutputDidOutputSampleBufferFromConnection?(output: AVCaptureOutput, sampleBuffer: interop.Object, connection: AVCaptureConnection): void;
}

declare class AVCaptureAudioDataOutputSampleBufferDelegate extends NativeObject implements AVCaptureAudioDataOutputSampleBufferDelegate {
}

declare interface AVCaptureSessionDeferredStartDelegate extends NSObjectProtocol {
  sessionWillRunDeferredStart(session: AVCaptureSession): void;

  sessionDidRunDeferredStart(session: AVCaptureSession): void;
}

declare class AVCaptureSessionDeferredStartDelegate extends NativeObject implements AVCaptureSessionDeferredStartDelegate {
}

declare interface AVCaptureSessionControlsDelegate extends NSObjectProtocol {
  sessionControlsDidBecomeActive(session: AVCaptureSession): void;

  sessionControlsWillEnterFullscreenAppearance(session: AVCaptureSession): void;

  sessionControlsWillExitFullscreenAppearance(session: AVCaptureSession): void;

  sessionControlsDidBecomeInactive(session: AVCaptureSession): void;
}

declare class AVCaptureSessionControlsDelegate extends NativeObject implements AVCaptureSessionControlsDelegate {
}

declare interface AVPlayerItemIntegratedTimelineObserver extends NSObjectProtocol {
}

declare class AVPlayerItemIntegratedTimelineObserver extends NativeObject implements AVPlayerItemIntegratedTimelineObserver {
}

declare interface AVPlayerItemOutputPullDelegate extends NSObjectProtocol {
  outputMediaDataWillChange?(sender: AVPlayerItemOutput): void;

  outputSequenceWasFlushed?(output: AVPlayerItemOutput): void;
}

declare class AVPlayerItemOutputPullDelegate extends NativeObject implements AVPlayerItemOutputPullDelegate {
}

declare interface AVPlaybackCoordinatorPlaybackControlDelegate extends NSObjectProtocol {
  playbackCoordinatorDidIssuePlayCommandCompletionHandler(coordinator: AVDelegatingPlaybackCoordinator, playCommand: AVDelegatingPlaybackCoordinatorPlayCommand, completionHandler: () => void): void;

  playbackCoordinatorDidIssuePauseCommandCompletionHandler(coordinator: AVDelegatingPlaybackCoordinator, pauseCommand: AVDelegatingPlaybackCoordinatorPauseCommand, completionHandler: () => void): void;

  playbackCoordinatorDidIssueSeekCommandCompletionHandler(coordinator: AVDelegatingPlaybackCoordinator, seekCommand: AVDelegatingPlaybackCoordinatorSeekCommand, completionHandler: () => void): void;

  playbackCoordinatorDidIssueBufferingCommandCompletionHandler(coordinator: AVDelegatingPlaybackCoordinator, bufferingCommand: AVDelegatingPlaybackCoordinatorBufferingCommand, completionHandler: () => void): void;
}

declare class AVPlaybackCoordinatorPlaybackControlDelegate extends NativeObject implements AVPlaybackCoordinatorPlaybackControlDelegate {
}

declare interface AVPlayerPlaybackCoordinatorDelegate extends NSObjectProtocol {
  playbackCoordinatorIdentifierForPlayerItem?(coordinator: AVPlayerPlaybackCoordinator, playerItem: AVPlayerItem): string;

  playbackCoordinatorInterstitialTimeRangesForPlayerItem?(coordinator: AVPlayerPlaybackCoordinator, playerItem: AVPlayerItem): NSArray;
}

declare class AVPlayerPlaybackCoordinatorDelegate extends NativeObject implements AVPlayerPlaybackCoordinatorDelegate {
}

declare interface AVMetricEventStreamSubscriber {
  publisherDidReceiveEvent(publisher: AVMetricEventStreamPublisher, event: AVMetricEvent): void;
}

declare class AVMetricEventStreamSubscriber extends NativeObject implements AVMetricEventStreamSubscriber {
}

declare interface AVPlayerItemMetadataOutputPushDelegate extends AVPlayerItemOutputPushDelegate {
  metadataOutputDidOutputTimedMetadataGroupsFromPlayerItemTrack?(output: AVPlayerItemMetadataOutput, groups: NSArray<interop.Object> | Array<interop.Object>, track: AVPlayerItemTrack | null): void;
}

declare class AVPlayerItemMetadataOutputPushDelegate extends NativeObject implements AVPlayerItemMetadataOutputPushDelegate {
}

declare interface AVMetricEventStreamPublisher {
}

declare class AVMetricEventStreamPublisher extends NativeObject implements AVMetricEventStreamPublisher {
}

declare interface AVVideoCompositionValidationHandling extends NSObjectProtocol {
  videoCompositionShouldContinueValidatingAfterFindingInvalidValueForKey?(videoComposition: AVVideoComposition, key: string): boolean;

  videoCompositionShouldContinueValidatingAfterFindingEmptyTimeRange?(videoComposition: AVVideoComposition, timeRange: CMTimeRange): boolean;

  videoCompositionShouldContinueValidatingAfterFindingInvalidTimeRangeInInstruction?(videoComposition: AVVideoComposition, videoCompositionInstruction: AVVideoCompositionInstruction): boolean;

  videoCompositionShouldContinueValidatingAfterFindingInvalidTrackIDInInstructionLayerInstructionAsset?(videoComposition: AVVideoComposition, videoCompositionInstruction: AVVideoCompositionInstruction, layerInstruction: AVVideoCompositionLayerInstruction, asset: AVAsset): boolean;
}

declare class AVVideoCompositionValidationHandling extends NativeObject implements AVVideoCompositionValidationHandling {
}

declare interface AVPlayerItemMetadataCollectorPushDelegate extends NSObjectProtocol {
  metadataCollectorDidCollectDateRangeMetadataGroupsIndexesOfNewGroupsIndexesOfModifiedGroups(metadataCollector: AVPlayerItemMetadataCollector, metadataGroups: NSArray<interop.Object> | Array<interop.Object>, indexesOfNewGroups: NSIndexSet, indexesOfModifiedGroups: NSIndexSet): void;
}

declare class AVPlayerItemMetadataCollectorPushDelegate extends NativeObject implements AVPlayerItemMetadataCollectorPushDelegate {
}

declare interface AVVideoCompositing extends NSObjectProtocol {
  readonly sourcePixelBufferAttributes: NSDictionary;

  readonly requiredPixelBufferAttributesForRenderContext: NSDictionary;

  renderContextChanged(newRenderContext: AVVideoCompositionRenderContext): void;

  startVideoCompositionRequest(asyncVideoCompositionRequest: AVAsynchronousVideoCompositionRequest): void;

  cancelAllPendingVideoCompositionRequests?(): void;

  readonly supportsWideColorSourceFrames?: boolean;

  readonly supportsHDRSourceFrames?: boolean;

  readonly supportsSourceTaggedBuffers?: boolean;

  readonly canConformColorOfSourceFrames?: boolean;

  anticipateRenderingUsingHint?(renderHint: AVVideoCompositionRenderHint): void;

  prerollForRenderingUsingHint?(renderHint: AVVideoCompositionRenderHint): void;
}

declare class AVVideoCompositing extends NativeObject implements AVVideoCompositing {
}

declare interface AVFragmentMinding {
  readonly associatedWithFragmentMinder: boolean;

  isAssociatedWithFragmentMinder(): boolean;
}

declare class AVFragmentMinding extends NativeObject implements AVFragmentMinding {
}

declare interface AVAsynchronousKeyValueLoading {
  statusOfValueForKeyError(key: string, outError: interop.PointerConvertible): interop.Enum<typeof AVKeyValueStatus>;

  loadValuesAsynchronouslyForKeysCompletionHandler(keys: NSArray<interop.Object> | Array<interop.Object>, handler: () => void | null): void;
}

declare class AVAsynchronousKeyValueLoading extends NativeObject implements AVAsynchronousKeyValueLoading {
}

declare interface AVQueuedSampleBufferRendering extends NSObjectProtocol {
  readonly timebase: interop.Object;

  enqueueSampleBuffer(sampleBuffer: interop.Object): void;

  flush(): void;

  readonly readyForMoreMediaData: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  stopRequestingMediaData(): void;

  readonly hasSufficientMediaDataForReliablePlaybackStart: boolean;

  isReadyForMoreMediaData(): boolean;
}

declare class AVQueuedSampleBufferRendering extends NativeObject implements AVQueuedSampleBufferRendering {
}

declare interface AVPlayerItemOutputPushDelegate extends NSObjectProtocol {
  outputSequenceWasFlushed?(output: AVPlayerItemOutput): void;
}

declare class AVPlayerItemOutputPushDelegate extends NativeObject implements AVPlayerItemOutputPushDelegate {
}

declare interface AVCapturePhotoCaptureDelegate extends NSObjectProtocol {
  captureOutputWillBeginCaptureForResolvedSettings?(output: AVCapturePhotoOutput, resolvedSettings: AVCaptureResolvedPhotoSettings): void;

  captureOutputWillCapturePhotoForResolvedSettings?(output: AVCapturePhotoOutput, resolvedSettings: AVCaptureResolvedPhotoSettings): void;

  captureOutputDidCapturePhotoForResolvedSettings?(output: AVCapturePhotoOutput, resolvedSettings: AVCaptureResolvedPhotoSettings): void;

  captureOutputDidFinishProcessingPhotoError?(output: AVCapturePhotoOutput, photo: AVCapturePhoto, error: NSError | null): void;

  captureOutputDidFinishCapturingDeferredPhotoProxyError?(output: AVCapturePhotoOutput, deferredPhotoProxy: AVCaptureDeferredPhotoProxy | null, error: NSError | null): void;

  captureOutputDidFinishProcessingPhotoSampleBufferPreviewPhotoSampleBufferResolvedSettingsBracketSettingsError?(output: AVCapturePhotoOutput, photoSampleBuffer: interop.Object | null, previewPhotoSampleBuffer: interop.Object | null, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings | null, error: NSError | null): void;

  captureOutputDidFinishProcessingRawPhotoSampleBufferPreviewPhotoSampleBufferResolvedSettingsBracketSettingsError?(output: AVCapturePhotoOutput, rawSampleBuffer: interop.Object | null, previewPhotoSampleBuffer: interop.Object | null, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings | null, error: NSError | null): void;

  captureOutputDidFinishRecordingLivePhotoMovieForEventualFileAtURLResolvedSettings?(output: AVCapturePhotoOutput, outputFileURL: NSURL, resolvedSettings: AVCaptureResolvedPhotoSettings): void;

  captureOutputDidFinishProcessingLivePhotoToMovieFileAtURLDurationPhotoDisplayTimeResolvedSettingsError?(output: AVCapturePhotoOutput, outputFileURL: NSURL, duration: CMTime, photoDisplayTime: CMTime, resolvedSettings: AVCaptureResolvedPhotoSettings, error: NSError | null): void;

  captureOutputDidFinishCaptureForResolvedSettingsError?(output: AVCapturePhotoOutput, resolvedSettings: AVCaptureResolvedPhotoSettings, error: NSError | null): void;
}

declare class AVCapturePhotoCaptureDelegate extends NativeObject implements AVCapturePhotoCaptureDelegate {
}

declare interface AVAssetDownloadDelegate extends NSURLSessionTaskDelegate {
  URLSessionAssetDownloadTaskDidFinishDownloadingToURL?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, location: NSURL): void;

  URLSessionAssetDownloadTaskDidLoadTimeRangeTotalTimeRangesLoadedTimeRangeExpectedToLoad?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, timeRange: CMTimeRange, loadedTimeRanges: NSArray<interop.Object> | Array<interop.Object>, timeRangeExpectedToLoad: CMTimeRange): void;

  URLSessionAssetDownloadTaskDidResolveMediaSelection?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, resolvedMediaSelection: AVMediaSelection): void;

  URLSessionAssetDownloadTaskWillDownloadToURL?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, location: NSURL): void;

  URLSessionAggregateAssetDownloadTaskWillDownloadToURL?(session: NSURLSession, aggregateAssetDownloadTask: AVAggregateAssetDownloadTask, location: NSURL): void;

  URLSessionAggregateAssetDownloadTaskDidCompleteForMediaSelection?(session: NSURLSession, aggregateAssetDownloadTask: AVAggregateAssetDownloadTask, mediaSelection: AVMediaSelection): void;

  URLSessionAggregateAssetDownloadTaskDidLoadTimeRangeTotalTimeRangesLoadedTimeRangeExpectedToLoadForMediaSelection?(session: NSURLSession, aggregateAssetDownloadTask: AVAggregateAssetDownloadTask, timeRange: CMTimeRange, loadedTimeRanges: NSArray<interop.Object> | Array<interop.Object>, timeRangeExpectedToLoad: CMTimeRange, mediaSelection: AVMediaSelection): void;

  URLSessionAssetDownloadTaskWillDownloadVariants?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, variants: NSArray<interop.Object> | Array<interop.Object>): void;

  URLSessionAssetDownloadTaskDidReceiveMetricEvent?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, metricEvent: AVMetricEvent): void;
}

declare class AVAssetDownloadDelegate extends NativeObject implements AVAssetDownloadDelegate {
}

declare interface AVAssetResourceLoaderDelegate extends NSObjectProtocol {
  resourceLoaderShouldWaitForLoadingOfRequestedResource?(resourceLoader: AVAssetResourceLoader, loadingRequest: AVAssetResourceLoadingRequest): boolean;

  resourceLoaderShouldWaitForRenewalOfRequestedResource?(resourceLoader: AVAssetResourceLoader, renewalRequest: AVAssetResourceRenewalRequest): boolean;

  resourceLoaderDidCancelLoadingRequest?(resourceLoader: AVAssetResourceLoader, loadingRequest: AVAssetResourceLoadingRequest): void;

  resourceLoaderShouldWaitForResponseToAuthenticationChallenge?(resourceLoader: AVAssetResourceLoader, authenticationChallenge: NSURLAuthenticationChallenge): boolean;

  resourceLoaderDidCancelAuthenticationChallenge?(resourceLoader: AVAssetResourceLoader, authenticationChallenge: NSURLAuthenticationChallenge): void;
}

declare class AVAssetResourceLoaderDelegate extends NativeObject implements AVAssetResourceLoaderDelegate {
}

declare interface AVAssetReaderCaptionValidationHandling extends NSObjectProtocol {
  captionAdaptorDidVendCaptionSkippingUnsupportedSourceSyntaxElements?(adaptor: AVAssetReaderOutputCaptionAdaptor, caption: AVCaption, syntaxElements: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVAssetReaderCaptionValidationHandling extends NativeObject implements AVAssetReaderCaptionValidationHandling {
}

declare interface AVPlayerItemRenderedLegibleOutputPushDelegate extends AVPlayerItemOutputPushDelegate {
  renderedLegibleOutputDidOutputRenderedCaptionImagesForItemTime?(output: AVPlayerItemRenderedLegibleOutput, captionImages: NSArray<interop.Object> | Array<interop.Object>, itemTime: CMTime): void;
}

declare class AVPlayerItemRenderedLegibleOutputPushDelegate extends NativeObject implements AVPlayerItemRenderedLegibleOutputPushDelegate {
}

declare interface AVContentKeyRecipient {
  contentKeySessionDidProvideContentKey?(contentKeySession: AVContentKeySession, contentKey: AVContentKey): void;

  readonly mayRequireContentKeysForMediaDataProcessing: boolean;
}

declare class AVContentKeyRecipient extends NativeObject implements AVContentKeyRecipient {
}

declare interface AVAssetWriterDelegate extends NSObjectProtocol {
  assetWriterDidOutputSegmentDataSegmentTypeSegmentReport?(writer: AVAssetWriter, segmentData: NSData, segmentType: interop.Enum<typeof AVAssetSegmentType>, segmentReport: AVAssetSegmentReport | null): void;

  assetWriterDidOutputSegmentDataSegmentType?(writer: AVAssetWriter, segmentData: NSData, segmentType: interop.Enum<typeof AVAssetSegmentType>): void;
}

declare class AVAssetWriterDelegate extends NativeObject implements AVAssetWriterDelegate {
}

declare interface AVCaptureMetadataOutputObjectsDelegate extends NSObjectProtocol {
  captureOutputDidOutputMetadataObjectsFromConnection?(output: AVCaptureOutput, metadataObjects: NSArray<interop.Object> | Array<interop.Object>, connection: AVCaptureConnection): void;
}

declare class AVCaptureMetadataOutputObjectsDelegate extends NativeObject implements AVCaptureMetadataOutputObjectsDelegate {
}

declare interface AVCaptureFileOutputRecordingDelegate extends NSObjectProtocol {
  captureOutputDidStartRecordingToOutputFileAtURLFromConnections?(output: AVCaptureFileOutput, fileURL: NSURL, connections: NSArray<interop.Object> | Array<interop.Object>): void;

  captureOutputDidStartRecordingToOutputFileAtURLStartPTSFromConnections?(output: AVCaptureFileOutput, fileURL: NSURL, startPTS: CMTime, connections: NSArray<interop.Object> | Array<interop.Object>): void;

  captureOutputDidPauseRecordingToOutputFileAtURLFromConnections?(output: AVCaptureFileOutput, fileURL: NSURL, connections: NSArray<interop.Object> | Array<interop.Object>): void;

  captureOutputDidResumeRecordingToOutputFileAtURLFromConnections?(output: AVCaptureFileOutput, fileURL: NSURL, connections: NSArray<interop.Object> | Array<interop.Object>): void;

  captureOutputDidFinishRecordingToOutputFileAtURLFromConnectionsError(output: AVCaptureFileOutput, outputFileURL: NSURL, connections: NSArray<interop.Object> | Array<interop.Object>, error: NSError | null): void;
}

declare class AVCaptureFileOutputRecordingDelegate extends NativeObject implements AVCaptureFileOutputRecordingDelegate {
}

declare interface AVPlayerItemLegibleOutputPushDelegate extends AVPlayerItemOutputPushDelegate {
  legibleOutputDidOutputAttributedStringsNativeSampleBuffersForItemTime?(output: AVPlayerItemLegibleOutput, strings: NSArray<interop.Object> | Array<interop.Object>, nativeSamples: NSArray<interop.Object> | Array<interop.Object>, itemTime: CMTime): void;
}

declare class AVPlayerItemLegibleOutputPushDelegate extends NativeObject implements AVPlayerItemLegibleOutputPushDelegate {
}

declare interface AVCapturePhotoOutputReadinessCoordinatorDelegate extends NSObjectProtocol {
  readinessCoordinatorCaptureReadinessDidChange?(coordinator: AVCapturePhotoOutputReadinessCoordinator, captureReadiness: interop.Enum<typeof AVCapturePhotoOutputCaptureReadiness>): void;
}

declare class AVCapturePhotoOutputReadinessCoordinatorDelegate extends NativeObject implements AVCapturePhotoOutputReadinessCoordinatorDelegate {
}

declare interface AVContentKeySessionDelegate extends NSObjectProtocol {
  contentKeySessionDidProvideContentKeyRequest(session: AVContentKeySession, keyRequest: AVContentKeyRequest): void;

  contentKeySessionDidProvideRenewingContentKeyRequest?(session: AVContentKeySession, keyRequest: AVContentKeyRequest): void;

  contentKeySessionDidProvidePersistableContentKeyRequest?(session: AVContentKeySession, keyRequest: AVPersistableContentKeyRequest): void;

  contentKeySessionDidUpdatePersistableContentKeyForContentKeyIdentifier?(session: AVContentKeySession, persistableContentKey: NSData, keyIdentifier: interop.Object): void;

  contentKeySessionContentKeyRequestDidFailWithError?(session: AVContentKeySession, keyRequest: AVContentKeyRequest, err: NSError): void;

  contentKeySessionShouldRetryContentKeyRequestReason?(session: AVContentKeySession, keyRequest: AVContentKeyRequest, retryReason: string): boolean;

  contentKeySessionContentKeyRequestDidSucceed?(session: AVContentKeySession, keyRequest: AVContentKeyRequest): void;

  contentKeySessionContentProtectionSessionIdentifierDidChange?(session: AVContentKeySession): void;

  contentKeySessionDidGenerateExpiredSessionReport?(session: AVContentKeySession): void;

  contentKeySessionExternalProtectionStatusDidChangeForContentKey?(session: AVContentKeySession, contentKey: AVContentKey): void;

  contentKeySessionDidProvideContentKeyRequestsForInitializationData?(session: AVContentKeySession, keyRequests: NSArray<interop.Object> | Array<interop.Object>, initializationData: NSData | null): void;
}

declare class AVContentKeySessionDelegate extends NativeObject implements AVContentKeySessionDelegate {
}

declare interface AVVideoCompositionInstructionProtocol extends NSObjectProtocol {
  readonly timeRange: CMTimeRange;

  readonly enablePostProcessing: boolean;

  readonly containsTweening: boolean;

  readonly requiredSourceTrackIDs: NSArray;

  readonly passthroughTrackID: number;

  readonly requiredSourceSampleDataTrackIDs?: NSArray;
}

declare class AVVideoCompositionInstructionProtocol extends NativeObject implements AVVideoCompositionInstructionProtocol {
}

declare class AVExternalStorageDevice extends NSObject {
  readonly displayName: string;

  readonly freeSize: number;

  readonly totalSize: number;

  readonly connected: boolean;

  readonly uuid: NSUUID;

  readonly notRecommendedForCaptureUse: boolean;

  nextAvailableURLsWithPathExtensionsError(extensionArray: NSArray<interop.Object> | Array<interop.Object>, outError: interop.PointerConvertible): NSArray;

  isConnected(): boolean;

  isNotRecommendedForCaptureUse(): boolean;

  static readonly authorizationStatus: interop.Enum<typeof AVAuthorizationStatus>;

  static requestAccessWithCompletionHandler(handler: (p1: boolean) => void): void;
}

declare class AVPlayerItemIntegratedTimeline extends NSObject {
  readonly currentSnapshot: AVPlayerItemIntegratedTimelineSnapshot;

  readonly currentTime: CMTime;

  readonly currentDate: NSDate;

  seekToTimeToleranceBeforeToleranceAfterCompletionHandler(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime, completionHandler: (p1: boolean) => void | null): void;

  seekToDateCompletionHandler(date: NSDate, completionHandler: (p1: boolean) => void | null): void;

  addPeriodicTimeObserverForIntervalQueueUsingBlock(interval: CMTime, queue: NSObject | null, block: (p1: CMTime) => void): AVPlayerItemIntegratedTimelineObserver;

  addBoundaryTimeObserverForSegmentOffsetsIntoSegmentQueueUsingBlock(segment: AVPlayerItemSegment, offsetsIntoSegment: NSArray<interop.Object> | Array<interop.Object>, queue: NSObject | null, block: (p1: boolean) => void): AVPlayerItemIntegratedTimelineObserver;

  removeTimeObserver(observer: AVPlayerItemIntegratedTimelineObserver): void;
}

declare class AVExternalSyncDevice extends NSObject {
  readonly status: interop.Enum<typeof AVExternalSyncDeviceStatus>;

  readonly clock: interop.Object;

  signalCompensationDelay: CMTime;

  readonly uuid: NSUUID;

  readonly vendorID: number;

  readonly productID: number;

  setSignalCompensationDelay(signalCompensationDelay: CMTime): void;
}

declare class AVCaptureTimecodeGenerator extends NSObject {
  readonly availableSources: NSArray;

  readonly currentSource: AVCaptureTimecodeSource;

  readonly delegate: AVCaptureTimecodeGeneratorDelegate;

  readonly delegateCallbackQueue: NSObject;

  setDelegateQueue(delegate: AVCaptureTimecodeGeneratorDelegate | null, callbackQueue: NSObject | null): void;

  synchronizationTimeout: number;

  timecodeAlignmentOffset: number;

  timecodeFrameDuration: CMTime;

  startSynchronizationWithTimecodeSource(source: AVCaptureTimecodeSource): void;

  generateInitialTimecode(): AVCaptureTimecode;

  static readonly frameCountSource: AVCaptureTimecodeSource;

  static readonly realTimeClockSource: AVCaptureTimecodeSource;

  setSynchronizationTimeout(synchronizationTimeout: number): void;

  setTimecodeAlignmentOffset(timecodeAlignmentOffset: number): void;

  setTimecodeFrameDuration(timecodeFrameDuration: CMTime): void;
}

declare class AVDelegatingPlaybackCoordinatorPlaybackControlCommand extends NSObject {
  readonly originator: AVCoordinatedPlaybackParticipant;

  readonly expectedCurrentItemIdentifier: string;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableCompositionTrack extends AVCompositionTrack {
  // @ts-ignore MemberDecl.tsIgnore
  enabled: boolean;

  // @ts-ignore MemberDecl.tsIgnore
  naturalTimeScale: number;

  // @ts-ignore MemberDecl.tsIgnore
  languageCode: string;

  // @ts-ignore MemberDecl.tsIgnore
  extendedLanguageTag: string;

  // @ts-ignore MemberDecl.tsIgnore
  preferredTransform: CGAffineTransform;

  // @ts-ignore MemberDecl.tsIgnore
  preferredVolume: number;

  // @ts-ignore MemberDecl.tsIgnore
  get segments(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set segments(value: NSArray<interop.Object> | Array<interop.Object>);

  insertTimeRangeOfTrackAtTimeError(timeRange: CMTimeRange, track: AVAssetTrack, startTime: CMTime, outError: interop.PointerConvertible): boolean;

  insertTimeRangesOfTracksAtTimeError(timeRanges: NSArray<interop.Object> | Array<interop.Object>, tracks: NSArray<interop.Object> | Array<interop.Object>, startTime: CMTime, outError: interop.PointerConvertible): boolean;

  insertEmptyTimeRange(timeRange: CMTimeRange): void;

  removeTimeRange(timeRange: CMTimeRange): void;

  scaleTimeRangeToDuration(timeRange: CMTimeRange, duration: CMTime): void;

  validateTrackSegmentsError(trackSegments: NSArray<interop.Object> | Array<interop.Object>, outError: interop.PointerConvertible): boolean;

  addTrackAssociationToTrackType(compositionTrack: AVCompositionTrack, trackAssociationType: string): void;

  removeTrackAssociationToTrackType(compositionTrack: AVCompositionTrack, trackAssociationType: string): void;

  isEnabled(): boolean;

  setEnabled(enabled: boolean): void;

  setNaturalTimeScale(naturalTimeScale: number): void;

  setLanguageCode(languageCode: string | null): void;

  setExtendedLanguageTag(extendedLanguageTag: string | null): void;

  setPreferredTransform(preferredTransform: CGAffineTransform): void;

  setPreferredVolume(preferredVolume: number): void;

  setSegments(segments: NSArray<interop.Object> | Array<interop.Object> | null): void;

  replaceFormatDescriptionWithFormatDescription(originalFormatDescription: interop.Object, replacementFormatDescription: interop.Object | null): void;
}

declare class AVQueuePlayer extends AVPlayer {
  static queuePlayerWithItems<This extends abstract new (...args: any) => any>(this: This, items: NSArray<interop.Object> | Array<interop.Object>): InstanceType<This>;

  initWithItems(items: NSArray<interop.Object> | Array<interop.Object>): this;

  items(): NSArray;

  advanceToNextItem(): void;

  canInsertItemAfterItem(item: AVPlayerItem, afterItem: AVPlayerItem | null): boolean;

  insertItemAfterItem(item: AVPlayerItem, afterItem: AVPlayerItem | null): void;

  removeItem(item: AVPlayerItem): void;

  removeAllItems(): void;
}

declare class AVOutputSettingsAssistant extends NSObject {
  static availableOutputSettingsPresets(): NSArray;

  static outputSettingsAssistantWithPreset<This extends abstract new (...args: any) => any>(this: This, presetIdentifier: string): InstanceType<This>;

  readonly audioSettings: NSDictionary;

  readonly videoSettings: NSDictionary;

  readonly outputFileType: string;

  sourceAudioFormat: interop.Object;

  sourceVideoFormat: interop.Object;

  sourceVideoAverageFrameDuration: CMTime;

  sourceVideoMinFrameDuration: CMTime;

  setSourceAudioFormat(sourceAudioFormat: interop.Object | null): void;

  setSourceVideoFormat(sourceVideoFormat: interop.Object | null): void;

  setSourceVideoAverageFrameDuration(sourceVideoAverageFrameDuration: CMTime): void;

  setSourceVideoMinFrameDuration(sourceVideoMinFrameDuration: CMTime): void;
}

declare class AVCaptureBracketedStillImageSettings extends NSObject {
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVFragmentedMovie extends AVMovie implements AVFragmentMinding {
  readonly tracks: NSArray;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVFragmentedMovieTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVFragmentedMovieTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly associatedWithFragmentMinder: boolean;

  isAssociatedWithFragmentMinder(): boolean;
}

declare class AVPersistableContentKeyRequest extends AVContentKeyRequest {
  persistableContentKeyFromKeyVendorResponseOptionsError(keyVendorResponse: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): NSData;
}

declare class AVSampleBufferRenderSynchronizer extends NSObject {
  readonly timebase: interop.Object;

  rate: number;

  currentTime(): CMTime;

  setRateTime(rate: number, time: CMTime): void;

  setRateTimeAtHostTime(rate: number, time: CMTime, hostTime: CMTime): void;

  delaysRateChangeUntilHasSufficientMediaData: boolean;

  setRate(rate: number): void;

  setDelaysRateChangeUntilHasSufficientMediaData(delaysRateChangeUntilHasSufficientMediaData: boolean): void;

  readonly renderers: NSArray;

  addRenderer(renderer: AVQueuedSampleBufferRendering): void;

  removeRendererAtTimeCompletionHandler(renderer: AVQueuedSampleBufferRendering, time: CMTime, completionHandler: (p1: boolean) => void | null): void;

  addPeriodicTimeObserverForIntervalQueueUsingBlock(interval: CMTime, queue: NSObject | null, block: (p1: CMTime) => void): interop.Object;

  addBoundaryTimeObserverForTimesQueueUsingBlock(times: NSArray<interop.Object> | Array<interop.Object>, queue: NSObject | null, block: () => void): interop.Object;

  removeTimeObserver(observer: interop.Object): void;
}

declare class AVMovieTrack extends AVAssetTrack {
  readonly mediaPresentationTimeRange: CMTimeRange;

  readonly mediaDecodeTimeRange: CMTimeRange;

  readonly alternateGroupID: number;

  readonly mediaDataStorage: AVMediaDataStorage;
}

declare class AVMediaDataStorage extends NSObject {
  initWithURLOptions(URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  URL(): NSURL;
}

declare class AVAssetImageGenerator extends NSObject {
  readonly asset: AVAsset;

  appliesPreferredTrackTransform: boolean;

  maximumSize: CGSize;

  apertureMode: string;

  dynamicRangePolicy: string;

  videoComposition: AVVideoComposition;

  readonly customVideoCompositor: AVVideoCompositing;

  requestedTimeToleranceBefore: CMTime;

  requestedTimeToleranceAfter: CMTime;

  static assetImageGeneratorWithAsset<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset): InstanceType<This>;

  initWithAsset(asset: AVAsset): this;

  copyCGImageAtTimeActualTimeError(requestedTime: CMTime, actualTime: interop.PointerConvertible, outError: interop.PointerConvertible): interop.Object;

  generateCGImagesAsynchronouslyForTimesCompletionHandler(requestedTimes: NSArray<interop.Object> | Array<interop.Object>, handler: (p1: CMTime, p2: interop.PointerConvertible, p3: CMTime, p4: interop.Enum<typeof AVAssetImageGeneratorResult>, p5: NSError) => void): void;

  generateCGImageAsynchronouslyForTimeCompletionHandler(requestedTime: CMTime, handler: (p1: interop.PointerConvertible, p2: CMTime, p3: NSError) => void | null): void;

  cancelAllCGImageGeneration(): void;

  setAppliesPreferredTrackTransform(appliesPreferredTrackTransform: boolean): void;

  setMaximumSize(maximumSize: CGSize): void;

  setApertureMode(apertureMode: string | null): void;

  setDynamicRangePolicy(dynamicRangePolicy: string): void;

  setVideoComposition(videoComposition: AVVideoComposition | null): void;

  setRequestedTimeToleranceBefore(requestedTimeToleranceBefore: CMTime): void;

  setRequestedTimeToleranceAfter(requestedTimeToleranceAfter: CMTime): void;
}

declare class AVAudioMixInputParameters extends NSObject implements NSCopying, NSMutableCopying {
  readonly trackID: number;

  readonly audioTimePitchAlgorithm: string;

  readonly audioTapProcessor: interop.Object;

  getVolumeRampForTimeStartVolumeEndVolumeTimeRange(time: CMTime, startVolume: interop.PointerConvertible, endVolume: interop.PointerConvertible, timeRange: interop.PointerConvertible): boolean;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptureMovieFileOutput extends AVCaptureFileOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  movieFragmentInterval: CMTime;

  get metadata(): NSArray;
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly availableVideoCodecTypes: NSArray;

  supportedOutputSettingsKeysForConnection(connection: AVCaptureConnection): NSArray;

  outputSettingsForConnection(connection: AVCaptureConnection): NSDictionary;

  setOutputSettingsForConnection(outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, connection: AVCaptureConnection): void;

  recordsVideoOrientationAndMirroringChangesAsMetadataTrackForConnection(connection: AVCaptureConnection): boolean;

  setRecordsVideoOrientationAndMirroringChangesAsMetadataTrackForConnection(doRecordChanges: boolean, connection: AVCaptureConnection): void;

  primaryConstituentDeviceSwitchingBehaviorForRecordingEnabled: boolean;

  setPrimaryConstituentDeviceSwitchingBehaviorForRecordingRestrictedSwitchingBehaviorConditions(switchingBehavior: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>, restrictedSwitchingBehaviorConditions: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>): void;

  readonly primaryConstituentDeviceSwitchingBehaviorForRecording: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>;

  readonly primaryConstituentDeviceRestrictedSwitchingBehaviorConditionsForRecording: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>;

  readonly spatialVideoCaptureSupported: boolean;

  spatialVideoCaptureEnabled: boolean;

  setMovieFragmentInterval(movieFragmentInterval: CMTime): void;

  setMetadata(metadata: NSArray<interop.Object> | Array<interop.Object> | null): void;

  isPrimaryConstituentDeviceSwitchingBehaviorForRecordingEnabled(): boolean;

  setPrimaryConstituentDeviceSwitchingBehaviorForRecordingEnabled(primaryConstituentDeviceSwitchingBehaviorForRecordingEnabled: boolean): void;

  isSpatialVideoCaptureSupported(): boolean;

  isSpatialVideoCaptureEnabled(): boolean;

  setSpatialVideoCaptureEnabled(spatialVideoCaptureEnabled: boolean): void;
}

declare class AVCaptureSlider extends AVCaptureControl {
  initWithLocalizedTitleSymbolNameMinValueMaxValue(localizedTitle: string, symbolName: string, minValue: number, maxValue: number): this;

  initWithLocalizedTitleSymbolNameMinValueMaxValueStep(localizedTitle: string, symbolName: string, minValue: number, maxValue: number, step: number): this;

  initWithLocalizedTitleSymbolNameValues(localizedTitle: string, symbolName: string, values: NSArray<interop.Object> | Array<interop.Object>): this;

  value: number;

  localizedValueFormat: string;

  get prominentValues(): NSArray;
  set prominentValues(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly localizedTitle: string;

  readonly symbolName: string;

  accessibilityIdentifier: string;

  setActionQueueAction(actionQueue: NSObject, action: (p1: number) => void): void;

  setValue(value: number): void;

  setLocalizedValueFormat(localizedValueFormat: string | null): void;

  setProminentValues(prominentValues: NSArray<interop.Object> | Array<interop.Object>): void;

  setAccessibilityIdentifier(accessibilityIdentifier: string | null): void;
}

declare class AVMetricHLSPlaylistRequestEvent extends AVMetricEvent {
  readonly url: NSURL;

  readonly isMultivariantPlaylist: boolean;

  readonly mediaType: string;

  readonly mediaResourceRequestEvent: AVMetricMediaResourceRequestEvent;
}

declare class AVMetricPlayerItemRateChangeEvent extends AVMetricEvent {
  readonly rate: number;

  readonly previousRate: number;

  readonly variant: AVAssetVariant;
}

declare class AVPlayerVideoOutput extends NSObject {
  initWithSpecification(specification: AVVideoOutputSpecification): this;

  copyTaggedBufferGroupForHostTimePresentationTimeStampActiveConfiguration(hostTime: CMTime, presentationTimeStampOut: interop.PointerConvertible, activeConfigurationOut: interop.PointerConvertible): interop.Pointer;
}

declare class AVCaptureDeferredPhotoProxy extends AVCapturePhoto {
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVCompositionTrack extends AVAssetTrack {
  readonly segments: NSArray;

  // @ts-ignore MemberDecl.tsIgnore
  segmentForTrackTime(trackTime: CMTime): AVCompositionTrackSegment;

  readonly formatDescriptionReplacements: NSArray;

  hasMediaCharacteristic(mediaCharacteristic: string): boolean;

  samplePresentationTimeForTrackTime(trackTime: CMTime): CMTime;

  metadataForFormat(format: string): NSArray;

  associatedTracksOfType(trackAssociationType: string): NSArray;
}

declare class AVPlayerItemTrack extends NSObject {
  readonly assetTrack: AVAssetTrack;

  enabled: boolean;

  readonly currentVideoFrameRate: number;

  isEnabled(): boolean;

  setEnabled(enabled: boolean): void;
}

declare class AVCameraCalibrationData extends NSObject {
  readonly intrinsicMatrix: simd_float3x3;

  readonly intrinsicMatrixReferenceDimensions: CGSize;

  readonly extrinsicMatrix: simd_float4x3;

  readonly pixelSize: number;

  readonly lensDistortionLookupTable: NSData;

  readonly inverseLensDistortionLookupTable: NSData;

  readonly lensDistortionCenter: CGPoint;
}

declare class AVPlayerInterstitialEvent extends NSObject implements NSCopying {
  static interstitialEventWithPrimaryItemIdentifierTimeTemplateItemsRestrictionsResumptionOffsetPlayoutLimitUserDefinedAttributes<This extends abstract new (...args: any) => any>(this: This, primaryItem: AVPlayerItem, identifier: string | null, time: CMTime, templateItems: NSArray<interop.Object> | Array<interop.Object>, restrictions: interop.Enum<typeof AVPlayerInterstitialEventRestrictions>, resumptionOffset: CMTime, playoutLimit: CMTime, userDefinedAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static interstitialEventWithPrimaryItemIdentifierDateTemplateItemsRestrictionsResumptionOffsetPlayoutLimitUserDefinedAttributes<This extends abstract new (...args: any) => any>(this: This, primaryItem: AVPlayerItem, identifier: string | null, date: NSDate, templateItems: NSArray<interop.Object> | Array<interop.Object>, restrictions: interop.Enum<typeof AVPlayerInterstitialEventRestrictions>, resumptionOffset: CMTime, playoutLimit: CMTime, userDefinedAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static interstitialEventWithPrimaryItemTime<This extends abstract new (...args: any) => any>(this: This, primaryItem: AVPlayerItem, time: CMTime): InstanceType<This>;

  static interstitialEventWithPrimaryItemDate<This extends abstract new (...args: any) => any>(this: This, primaryItem: AVPlayerItem, date: NSDate): InstanceType<This>;

  readonly primaryItem: AVPlayerItem | null;

  readonly identifier: string;

  readonly time: CMTime;

  readonly date: NSDate;

  readonly templateItems: NSArray;

  readonly restrictions: interop.Enum<typeof AVPlayerInterstitialEventRestrictions>;

  readonly resumptionOffset: CMTime;

  readonly playoutLimit: CMTime;

  readonly alignsStartWithPrimarySegmentBoundary: boolean;

  readonly alignsResumptionWithPrimarySegmentBoundary: boolean;

  readonly cue: string;

  readonly willPlayOnce: boolean;

  readonly userDefinedAttributes: NSDictionary;

  readonly assetListResponse: NSDictionary;

  readonly timelineOccupancy: interop.Enum<typeof AVPlayerInterstitialEventTimelineOccupancy>;

  readonly supplementsPrimaryContent: boolean;

  readonly contentMayVary: boolean;

  readonly skipControlTimeRange: CMTimeRange;

  readonly skipControlLocalizedLabelBundleKey: string;

  plannedDuration: CMTime;

  setPrimaryItem(primaryItem: AVPlayerItem | null): void;

  setIdentifier(identifier: string): void;

  setTime(time: CMTime): void;

  setDate(date: NSDate | null): void;

  setTemplateItems(templateItems: NSArray<interop.Object> | Array<interop.Object>): void;

  setRestrictions(restrictions: interop.Enum<typeof AVPlayerInterstitialEventRestrictions>): void;

  setResumptionOffset(resumptionOffset: CMTime): void;

  setPlayoutLimit(playoutLimit: CMTime): void;

  setAlignsStartWithPrimarySegmentBoundary(alignsStartWithPrimarySegmentBoundary: boolean): void;

  setAlignsResumptionWithPrimarySegmentBoundary(alignsResumptionWithPrimarySegmentBoundary: boolean): void;

  setCue(cue: string): void;

  setWillPlayOnce(willPlayOnce: boolean): void;

  setUserDefinedAttributes(userDefinedAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): void;

  setTimelineOccupancy(timelineOccupancy: interop.Enum<typeof AVPlayerInterstitialEventTimelineOccupancy>): void;

  setSupplementsPrimaryContent(supplementsPrimaryContent: boolean): void;

  setContentMayVary(contentMayVary: boolean): void;

  setPlannedDuration(plannedDuration: CMTime): void;

  setSkipControlTimeRange(skipControlTimeRange: CMTimeRange): void;

  setSkipControlLocalizedLabelBundleKey(skipControlLocalizedLabelBundleKey: string | null): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCapturePhotoOutputReadinessCoordinator extends NSObject {
  initWithPhotoOutput(photoOutput: AVCapturePhotoOutput): this;

  delegate: AVCapturePhotoOutputReadinessCoordinatorDelegate;

  readonly captureReadiness: interop.Enum<typeof AVCapturePhotoOutputCaptureReadiness>;

  startTrackingCaptureRequestUsingPhotoSettings(settings: AVCapturePhotoSettings): void;

  stopTrackingCaptureRequestUsingPhotoSettingsUniqueID(settingsUniqueID: number): void;

  setDelegate(delegate: AVCapturePhotoOutputReadinessCoordinatorDelegate | null): void;
}

declare class AVMetadataDogHeadObject extends AVMetadataObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptureFileOutput extends AVCaptureOutput {
  readonly outputFileURL: NSURL;

  startRecordingToOutputFileURLRecordingDelegate(outputFileURL: NSURL, delegate: AVCaptureFileOutputRecordingDelegate): void;

  stopRecording(): void;

  readonly recording: boolean;

  readonly recordingPaused: boolean;

  pauseRecording(): void;

  resumeRecording(): void;

  readonly recordedDuration: CMTime;

  readonly recordedFileSize: number;

  maxRecordedDuration: CMTime;

  maxRecordedFileSize: number;

  minFreeDiskSpaceLimit: number;

  isRecording(): boolean;

  isRecordingPaused(): boolean;

  setMaxRecordedDuration(maxRecordedDuration: CMTime): void;

  setMaxRecordedFileSize(maxRecordedFileSize: number): void;

  setMinFreeDiskSpaceLimit(minFreeDiskSpaceLimit: number): void;
}

declare class AVMetricPlayerItemLikelyToKeepUpEvent extends AVMetricEvent {
  readonly variant: AVAssetVariant;

  readonly timeTaken: number;

  readonly loadedTimeRanges: NSArray;
}

declare class AVPlayerLooper extends NSObject {
  static playerLooperWithPlayerTemplateItemTimeRange<This extends abstract new (...args: any) => any>(this: This, player: AVQueuePlayer, itemToLoop: AVPlayerItem, loopRange: CMTimeRange): InstanceType<This>;

  static playerLooperWithPlayerTemplateItem<This extends abstract new (...args: any) => any>(this: This, player: AVQueuePlayer, itemToLoop: AVPlayerItem): InstanceType<This>;

  initWithPlayerTemplateItemTimeRange(player: AVQueuePlayer, itemToLoop: AVPlayerItem, loopRange: CMTimeRange): this;

  initWithPlayerTemplateItemTimeRangeExistingItemsOrdering(player: AVQueuePlayer, itemToLoop: AVPlayerItem, loopRange: CMTimeRange, itemOrdering: interop.Enum<typeof AVPlayerLooperItemOrdering>): this;

  readonly status: interop.Enum<typeof AVPlayerLooperStatus>;

  readonly error: NSError;

  disableLooping(): void;

  readonly loopCount: number;

  readonly loopingPlayerItems: NSArray;
}

declare class AVMetadataGroup extends NSObject {
  readonly items: NSArray;

  readonly classifyingLabel: string;

  readonly uniqueID: string;
}

declare class AVExposureBiasRange extends NSObject {
  readonly minExposureBias: number;

  readonly maxExposureBias: number;

  containsExposureBias(exposureBias: number): boolean;
}

declare class AVAssetResourceLoadingDataRequest extends NSObject {
  readonly requestedOffset: number;

  readonly requestedLength: number;

  readonly requestsAllDataToEndOfResource: boolean;

  readonly currentOffset: number;

  respondWithData(data: NSData): void;
}

declare class AVMetricPlayerItemInitialLikelyToKeepUpEvent extends AVMetricPlayerItemLikelyToKeepUpEvent {
  readonly playlistRequestEvents: NSArray;

  readonly mediaSegmentRequestEvents: NSArray;

  readonly contentKeyRequestEvents: NSArray;
}

declare class AVAssetReaderSampleReferenceOutput extends AVAssetReaderOutput {
  static assetReaderSampleReferenceOutputWithTrack<This extends abstract new (...args: any) => any>(this: This, track: AVAssetTrack): InstanceType<This>;

  initWithTrack(track: AVAssetTrack): this;

  readonly track: AVAssetTrack;
}

declare class AVCaptureDeviceRotationCoordinator extends NSObject {
  initWithDevicePreviewLayer(device: AVCaptureDevice, previewLayer: CALayer | null): this;

  readonly device: AVCaptureDevice;

  readonly previewLayer: CALayer;

  readonly videoRotationAngleForHorizonLevelPreview: number;

  readonly videoRotationAngleForHorizonLevelCapture: number;
}

declare class AVCaptureInputPort extends NSObject {
  readonly input: AVCaptureInput;

  readonly mediaType: string;

  readonly formatDescription: interop.Object;

  enabled: boolean;

  readonly clock: interop.Object;

  readonly sourceDeviceType: string;

  readonly sourceDevicePosition: interop.Enum<typeof AVCaptureDevicePosition>;

  isEnabled(): boolean;

  setEnabled(enabled: boolean): void;
}

declare class AVMetadataFaceObject extends AVMetadataObject implements NSCopying {
  readonly faceID: number;

  readonly hasRollAngle: boolean;

  readonly rollAngle: number;

  readonly hasYawAngle: boolean;

  readonly yawAngle: number;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptureSpatialAudioMetadataSampleGenerator extends NSObject {
  readonly timedMetadataSampleBufferFormatDescription: interop.Object;

  analyzeAudioSample(sbuf: interop.Object): number;

  newTimedMetadataSampleBufferAndResetAnalyzer(): interop.Object;

  resetAnalyzer(): void;
}

declare class AVPortraitEffectsMatte extends NSObject {
  static portraitEffectsMatteFromDictionaryRepresentationError<This extends abstract new (...args: any) => any>(this: This, imageSourceAuxDataInfoDictionary: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, outError: interop.PointerConvertible): InstanceType<This>;

  portraitEffectsMatteByApplyingExifOrientation(exifOrientation: interop.Enum<typeof CGImagePropertyOrientation>): this;

  portraitEffectsMatteByReplacingPortraitEffectsMatteWithPixelBufferError(pixelBuffer: interop.Object, outError: interop.PointerConvertible): this;

  dictionaryRepresentationForAuxiliaryDataType(outAuxDataType: interop.PointerConvertible): NSDictionary;

  readonly pixelFormatType: number;

  readonly mattingImage: interop.Object;
}

declare class AVCaptureVideoPreviewLayer extends CALayer {
  static layerWithSession<This extends abstract new (...args: any) => any>(this: This, session: AVCaptureSession): InstanceType<This>;

  initWithSession(session: AVCaptureSession): this;

  static layerWithSessionWithNoConnection<This extends abstract new (...args: any) => any>(this: This, session: AVCaptureSession): InstanceType<This>;

  initWithSessionWithNoConnection(session: AVCaptureSession): this;

  session: AVCaptureSession;

  setSessionWithNoConnection(session: AVCaptureSession): void;

  readonly connection: AVCaptureConnection;

  videoGravity: string;

  readonly previewing: boolean;

  captureDevicePointOfInterestForPoint(pointInLayer: CGPoint): CGPoint;

  pointForCaptureDevicePointOfInterest(captureDevicePointOfInterest: CGPoint): CGPoint;

  metadataOutputRectOfInterestForRect(rectInLayerCoordinates: CGRect): CGRect;

  rectForMetadataOutputRectOfInterest(rectInMetadataOutputCoordinates: CGRect): CGRect;

  transformedMetadataObjectForMetadataObject(metadataObject: AVMetadataObject): AVMetadataObject;

  readonly orientationSupported: boolean;

  orientation: interop.Enum<typeof AVCaptureVideoOrientation>;

  readonly mirroringSupported: boolean;

  automaticallyAdjustsMirroring: boolean;

  mirrored: boolean;

  readonly deferredStartSupported: boolean;

  deferredStartEnabled: boolean;

  setSession(session: AVCaptureSession | null): void;

  setVideoGravity(videoGravity: string): void;

  isPreviewing(): boolean;

  isOrientationSupported(): boolean;

  setOrientation(orientation: interop.Enum<typeof AVCaptureVideoOrientation>): void;

  isMirroringSupported(): boolean;

  setAutomaticallyAdjustsMirroring(automaticallyAdjustsMirroring: boolean): void;

  isMirrored(): boolean;

  setMirrored(mirrored: boolean): void;

  isDeferredStartSupported(): boolean;

  isDeferredStartEnabled(): boolean;

  setDeferredStartEnabled(deferredStartEnabled: boolean): void;
}

declare class AVCaptureTimecodeSource extends NSObject implements NSCopying {
  readonly displayName: string;

  readonly type: interop.Enum<typeof AVCaptureTimecodeSourceType>;

  readonly uuid: NSUUID;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptureSystemZoomSlider extends AVCaptureControl {
  initWithDevice(device: AVCaptureDevice): this;

  initWithDeviceAction(device: AVCaptureDevice, action: (p1: number) => void): this;
}

declare class AVCaptureSystemPressureState extends NSObject {
  readonly level: string;

  readonly factors: interop.Enum<typeof AVCaptureSystemPressureFactors>;
}

declare class AVCaptureSystemExposureBiasSlider extends AVCaptureControl {
  initWithDevice(device: AVCaptureDevice): this;

  initWithDeviceAction(device: AVCaptureDevice, action: (p1: number) => void): this;
}

declare class AVCaptureMetadataInput extends AVCaptureInput {
  static metadataInputWithFormatDescriptionClock<This extends abstract new (...args: any) => any>(this: This, desc: interop.Object, clock: interop.Object): InstanceType<This>;

  initWithFormatDescriptionClock(desc: interop.Object, clock: interop.Object): this;

  appendTimedMetadataGroupError(metadata: AVTimedMetadataGroup, outError: interop.PointerConvertible): boolean;
}

declare class AVCaptureDeviceInput extends AVCaptureInput {
  static deviceInputWithDeviceError<This extends abstract new (...args: any) => any>(this: This, device: AVCaptureDevice, outError: interop.PointerConvertible): InstanceType<This>;

  initWithDeviceError(device: AVCaptureDevice, outError: interop.PointerConvertible): this;

  readonly device: AVCaptureDevice;

  unifiedAutoExposureDefaultsEnabled: boolean;

  portsWithMediaTypeSourceDeviceTypeSourceDevicePosition(mediaType: string | null, sourceDeviceType: string | null, sourceDevicePosition: interop.Enum<typeof AVCaptureDevicePosition>): NSArray;

  videoMinFrameDurationOverride: CMTime;

  readonly lockedVideoFrameDurationSupported: boolean;

  activeLockedVideoFrameDuration: CMTime;

  readonly externalSyncSupported: boolean;

  followExternalSyncDeviceVideoFrameDurationDelegate(externalSyncDevice: AVExternalSyncDevice, frameDuration: CMTime, delegate: AVExternalSyncDeviceDelegate | null): void;

  readonly activeExternalSyncVideoFrameDuration: CMTime;

  readonly externalSyncDevice: AVExternalSyncDevice;

  unfollowExternalSyncDevice(): void;

  isMultichannelAudioModeSupported(multichannelAudioMode: interop.Enum<typeof AVCaptureMultichannelAudioMode>): boolean;

  multichannelAudioMode: interop.Enum<typeof AVCaptureMultichannelAudioMode>;

  readonly windNoiseRemovalSupported: boolean;

  windNoiseRemovalEnabled: boolean;

  readonly cinematicVideoCaptureSupported: boolean;

  cinematicVideoCaptureEnabled: boolean;

  simulatedAperture: number;

  setUnifiedAutoExposureDefaultsEnabled(unifiedAutoExposureDefaultsEnabled: boolean): void;

  setVideoMinFrameDurationOverride(videoMinFrameDurationOverride: CMTime): void;

  isLockedVideoFrameDurationSupported(): boolean;

  setActiveLockedVideoFrameDuration(activeLockedVideoFrameDuration: CMTime): void;

  isExternalSyncSupported(): boolean;

  setMultichannelAudioMode(multichannelAudioMode: interop.Enum<typeof AVCaptureMultichannelAudioMode>): void;

  isWindNoiseRemovalSupported(): boolean;

  isWindNoiseRemovalEnabled(): boolean;

  setWindNoiseRemovalEnabled(windNoiseRemovalEnabled: boolean): void;

  isCinematicVideoCaptureSupported(): boolean;

  isCinematicVideoCaptureEnabled(): boolean;

  setCinematicVideoCaptureEnabled(cinematicVideoCaptureEnabled: boolean): void;

  setSimulatedAperture(simulatedAperture: number): void;
}

declare class AVCaptureInput extends NSObject {
  readonly ports: NSArray;
}

declare class AVCaptureExternalDisplayConfigurator extends NSObject {
  initWithDevicePreviewLayerConfiguration(device: AVCaptureDevice, previewLayer: CALayer, configuration: AVCaptureExternalDisplayConfiguration): this;

  readonly device: AVCaptureDevice;

  readonly previewLayer: CALayer;

  readonly active: boolean;

  stop(): void;

  readonly activeExternalDisplayFrameRate: number;

  static readonly shouldMatchFrameRateSupported: boolean;

  static readonly supportsBypassingColorSpaceConversion: boolean;

  static readonly supportsPreferredResolution: boolean;

  isActive(): boolean;

  static isMatchingFrameRateSupported(): boolean;

  static isBypassingColorSpaceConversionSupported(): boolean;

  static isPreferredResolutionSupported(): boolean;
}

declare class AVCaptureSynchronizedSampleBufferData extends AVCaptureSynchronizedData {
  readonly sampleBuffer: interop.Object;

  readonly sampleBufferWasDropped: boolean;

  readonly droppedReason: interop.Enum<typeof AVCaptureOutputDataDroppedReason>;
}

declare class AVCaptureDataOutputSynchronizer extends NSObject {
  initWithDataOutputs(dataOutputs: NSArray<interop.Object> | Array<interop.Object>): this;

  readonly dataOutputs: NSArray;

  setDelegateQueue(delegate: AVCaptureDataOutputSynchronizerDelegate | null, delegateCallbackQueue: NSObject | null): void;

  readonly delegate: AVCaptureDataOutputSynchronizerDelegate;

  readonly delegateCallbackQueue: NSObject;
}

declare class AVCaptureVideoDataOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  setSampleBufferDelegateQueue(sampleBufferDelegate: AVCaptureVideoDataOutputSampleBufferDelegate | null, sampleBufferCallbackQueue: NSObject | null): void;

  readonly sampleBufferDelegate: AVCaptureVideoDataOutputSampleBufferDelegate;

  readonly sampleBufferCallbackQueue: NSObject;

  get videoSettings(): NSDictionary;
  set videoSettings(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  recommendedVideoSettingsForAssetWriterWithOutputFileType(outputFileType: string): NSDictionary;

  availableVideoCodecTypesForAssetWriterWithOutputFileType(outputFileType: string): NSArray;

  recommendedVideoSettingsForVideoCodecTypeAssetWriterOutputFileType(videoCodecType: string, outputFileType: string): NSDictionary;

  recommendedVideoSettingsForVideoCodecTypeAssetWriterOutputFileTypeOutputFileURL(videoCodecType: string, outputFileType: string, outputFileURL: NSURL | null): NSDictionary;

  recommendedMovieMetadataForVideoCodecTypeAssetWriterOutputFileType(videoCodecType: string, outputFileType: string): NSArray;

  readonly recommendedMediaTimeScaleForAssetWriter: number;

  readonly availableVideoCVPixelFormatTypes: NSArray;

  readonly availableVideoCodecTypes: NSArray;

  minFrameDuration: CMTime;

  alwaysDiscardsLateVideoFrames: boolean;

  automaticallyConfiguresOutputBufferDimensions: boolean;

  deliversPreviewSizedOutputBuffers: boolean;

  preparesCellularRadioForNetworkConnection: boolean;

  preservesDynamicHDRMetadata: boolean;

  setVideoSettings(videoSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): void;

  setMinFrameDuration(minFrameDuration: CMTime): void;

  setAlwaysDiscardsLateVideoFrames(alwaysDiscardsLateVideoFrames: boolean): void;

  setAutomaticallyConfiguresOutputBufferDimensions(automaticallyConfiguresOutputBufferDimensions: boolean): void;

  setDeliversPreviewSizedOutputBuffers(deliversPreviewSizedOutputBuffers: boolean): void;

  setPreparesCellularRadioForNetworkConnection(preparesCellularRadioForNetworkConnection: boolean): void;

  setPreservesDynamicHDRMetadata(preservesDynamicHDRMetadata: boolean): void;
}

declare class AVCaptureStillImageOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  get outputSettings(): NSDictionary;
  set outputSettings(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  readonly availableImageDataCVPixelFormatTypes: NSArray;

  readonly availableImageDataCodecTypes: NSArray;

  readonly stillImageStabilizationSupported: boolean;

  automaticallyEnablesStillImageStabilizationWhenAvailable: boolean;

  readonly stillImageStabilizationActive: boolean;

  highResolutionStillImageOutputEnabled: boolean;

  readonly cameraSensorOrientationCompensationSupported: boolean;

  cameraSensorOrientationCompensationEnabled: boolean;

  readonly capturingStillImage: boolean;

  captureStillImageAsynchronouslyFromConnectionCompletionHandler(connection: AVCaptureConnection, handler: (p1: interop.PointerConvertible, p2: NSError) => void | null): void;

  static jpegStillImageNSDataRepresentation(jpegSampleBuffer: interop.Object): NSData;

  setOutputSettings(outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): void;

  isStillImageStabilizationSupported(): boolean;

  setAutomaticallyEnablesStillImageStabilizationWhenAvailable(automaticallyEnablesStillImageStabilizationWhenAvailable: boolean): void;

  isStillImageStabilizationActive(): boolean;

  isHighResolutionStillImageOutputEnabled(): boolean;

  setHighResolutionStillImageOutputEnabled(highResolutionStillImageOutputEnabled: boolean): void;

  isCameraSensorOrientationCompensationSupported(): boolean;

  isCameraSensorOrientationCompensationEnabled(): boolean;

  setCameraSensorOrientationCompensationEnabled(cameraSensorOrientationCompensationEnabled: boolean): void;

  isCapturingStillImage(): boolean;

  readonly maxBracketedCaptureStillImageCount: number;

  readonly lensStabilizationDuringBracketedCaptureSupported: boolean;

  lensStabilizationDuringBracketedCaptureEnabled: boolean;

  prepareToCaptureStillImageBracketFromConnectionWithSettingsArrayCompletionHandler(connection: AVCaptureConnection, settings: NSArray<interop.Object> | Array<interop.Object>, handler: (p1: boolean, p2: NSError) => void | null): void;

  captureStillImageBracketAsynchronouslyFromConnectionWithSettingsArrayCompletionHandler(connection: AVCaptureConnection, settings: NSArray<interop.Object> | Array<interop.Object>, handler: (p1: interop.PointerConvertible, p2: AVCaptureBracketedStillImageSettings, p3: NSError) => void | null): void;

  isLensStabilizationDuringBracketedCaptureSupported(): boolean;

  isLensStabilizationDuringBracketedCaptureEnabled(): boolean;

  setLensStabilizationDuringBracketedCaptureEnabled(lensStabilizationDuringBracketedCaptureEnabled: boolean): void;
}

declare class AVRenderedCaptionImage extends NSObject {
  readonly pixelBuffer: interop.Object;

  readonly position: CGPoint;
}

declare class AVCaptureResolvedPhotoSettings extends NSObject {
  readonly uniqueID: number;

  readonly photoDimensions: CMVideoDimensions;

  readonly rawPhotoDimensions: CMVideoDimensions;

  readonly previewDimensions: CMVideoDimensions;

  readonly embeddedThumbnailDimensions: CMVideoDimensions;

  readonly rawEmbeddedThumbnailDimensions: CMVideoDimensions;

  readonly portraitEffectsMatteDimensions: CMVideoDimensions;

  dimensionsForSemanticSegmentationMatteOfType(semanticSegmentationMatteType: string): CMVideoDimensions;

  readonly livePhotoMovieDimensions: CMVideoDimensions;

  readonly flashEnabled: boolean;

  readonly redEyeReductionEnabled: boolean;

  readonly deferredPhotoProxyDimensions: CMVideoDimensions;

  readonly stillImageStabilizationEnabled: boolean;

  readonly virtualDeviceFusionEnabled: boolean;

  readonly dualCameraFusionEnabled: boolean;

  readonly expectedPhotoCount: number;

  readonly photoProcessingTimeRange: CMTimeRange;

  readonly contentAwareDistortionCorrectionEnabled: boolean;

  readonly fastCapturePrioritizationEnabled: boolean;

  isFlashEnabled(): boolean;

  isRedEyeReductionEnabled(): boolean;

  isStillImageStabilizationEnabled(): boolean;

  isVirtualDeviceFusionEnabled(): boolean;

  isDualCameraFusionEnabled(): boolean;

  isContentAwareDistortionCorrectionEnabled(): boolean;

  isFastCapturePrioritizationEnabled(): boolean;
}

declare class AVCaptureMetadataOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  setMetadataObjectsDelegateQueue(objectsDelegate: AVCaptureMetadataOutputObjectsDelegate | null, objectsCallbackQueue: NSObject | null): void;

  readonly metadataObjectsDelegate: AVCaptureMetadataOutputObjectsDelegate;

  readonly metadataObjectsCallbackQueue: NSObject;

  readonly availableMetadataObjectTypes: NSArray;

  get metadataObjectTypes(): NSArray;
  set metadataObjectTypes(value: NSArray<interop.Object> | Array<interop.Object>);

  rectOfInterest: CGRect;

  readonly requiredMetadataObjectTypesForCinematicVideoCapture: NSArray;

  setMetadataObjectTypes(metadataObjectTypes: NSArray<interop.Object> | Array<interop.Object> | null): void;

  setRectOfInterest(rectOfInterest: CGRect): void;
}

declare class AVMetadataSalientObject extends AVMetadataObject implements NSCopying {
  readonly objectID: number;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataCatBodyObject extends AVMetadataBodyObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataCatHeadObject extends AVMetadataObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataBodyObject extends AVMetadataObject implements NSCopying {
  readonly bodyID: number;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataObject extends NSObject {
  readonly time: CMTime;

  readonly duration: CMTime;

  readonly bounds: CGRect;

  readonly type: string;

  readonly groupID: number;

  readonly objectID: number;

  readonly cinematicVideoFocusMode: interop.Enum<typeof AVCaptureCinematicVideoFocusMode>;

  readonly fixedFocus: boolean;

  isFixedFocus(): boolean;
}

declare class AVCaptureControl extends NSObject {
  enabled: boolean;

  isEnabled(): boolean;

  setEnabled(enabled: boolean): void;
}

declare class AVCaptureAudioDataOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  setSampleBufferDelegateQueue(sampleBufferDelegate: AVCaptureAudioDataOutputSampleBufferDelegate | null, sampleBufferCallbackQueue: NSObject | null): void;

  readonly sampleBufferDelegate: AVCaptureAudioDataOutputSampleBufferDelegate;

  readonly sampleBufferCallbackQueue: NSObject;

  spatialAudioChannelLayoutTag: number;

  recommendedAudioSettingsForAssetWriterWithOutputFileType(outputFileType: string): NSDictionary;

  setSpatialAudioChannelLayoutTag(spatialAudioChannelLayoutTag: number): void;
}

declare class AVCaptureOutput extends NSObject {
  readonly connections: NSArray;

  connectionWithMediaType(mediaType: string): AVCaptureConnection;

  transformedMetadataObjectForMetadataObjectConnection(metadataObject: AVMetadataObject, connection: AVCaptureConnection): AVMetadataObject;

  metadataOutputRectOfInterestForRect(rectInOutputCoordinates: CGRect): CGRect;

  rectForMetadataOutputRectOfInterest(rectInMetadataOutputCoordinates: CGRect): CGRect;

  readonly deferredStartSupported: boolean;

  deferredStartEnabled: boolean;

  isDeferredStartSupported(): boolean;

  isDeferredStartEnabled(): boolean;

  setDeferredStartEnabled(deferredStartEnabled: boolean): void;
}

declare class AVCaptureConnection extends NSObject {
  static connectionWithInputPortsOutput<This extends abstract new (...args: any) => any>(this: This, ports: NSArray<interop.Object> | Array<interop.Object>, output: AVCaptureOutput): InstanceType<This>;

  static connectionWithInputPortVideoPreviewLayer<This extends abstract new (...args: any) => any>(this: This, port: AVCaptureInputPort, layer: AVCaptureVideoPreviewLayer): InstanceType<This>;

  initWithInputPortsOutput(ports: NSArray<interop.Object> | Array<interop.Object>, output: AVCaptureOutput): this;

  initWithInputPortVideoPreviewLayer(port: AVCaptureInputPort, layer: AVCaptureVideoPreviewLayer): this;

  readonly inputPorts: NSArray;

  readonly output: AVCaptureOutput;

  readonly videoPreviewLayer: AVCaptureVideoPreviewLayer;

  enabled: boolean;

  readonly active: boolean;

  readonly audioChannels: NSArray;

  readonly supportsVideoMirroring: boolean;

  videoMirrored: boolean;

  automaticallyAdjustsVideoMirroring: boolean;

  isVideoRotationAngleSupported(videoRotationAngle: number): boolean;

  videoRotationAngle: number;

  readonly supportsVideoOrientation: boolean;

  videoOrientation: interop.Enum<typeof AVCaptureVideoOrientation>;

  readonly supportsVideoMinFrameDuration: boolean;

  videoMinFrameDuration: CMTime;

  readonly supportsVideoMaxFrameDuration: boolean;

  videoMaxFrameDuration: CMTime;

  readonly videoMaxScaleAndCropFactor: number;

  videoScaleAndCropFactor: number;

  preferredVideoStabilizationMode: interop.Enum<typeof AVCaptureVideoStabilizationMode>;

  readonly activeVideoStabilizationMode: interop.Enum<typeof AVCaptureVideoStabilizationMode>;

  readonly supportsVideoStabilization: boolean;

  readonly videoStabilizationEnabled: boolean;

  enablesVideoStabilizationWhenAvailable: boolean;

  readonly cameraIntrinsicMatrixDeliverySupported: boolean;

  cameraIntrinsicMatrixDeliveryEnabled: boolean;

  isEnabled(): boolean;

  setEnabled(enabled: boolean): void;

  isActive(): boolean;

  isVideoMirroringSupported(): boolean;

  isVideoMirrored(): boolean;

  setVideoMirrored(videoMirrored: boolean): void;

  setAutomaticallyAdjustsVideoMirroring(automaticallyAdjustsVideoMirroring: boolean): void;

  setVideoRotationAngle(videoRotationAngle: number): void;

  isVideoOrientationSupported(): boolean;

  setVideoOrientation(videoOrientation: interop.Enum<typeof AVCaptureVideoOrientation>): void;

  isVideoMinFrameDurationSupported(): boolean;

  setVideoMinFrameDuration(videoMinFrameDuration: CMTime): void;

  isVideoMaxFrameDurationSupported(): boolean;

  setVideoMaxFrameDuration(videoMaxFrameDuration: CMTime): void;

  setVideoScaleAndCropFactor(videoScaleAndCropFactor: number): void;

  setPreferredVideoStabilizationMode(preferredVideoStabilizationMode: interop.Enum<typeof AVCaptureVideoStabilizationMode>): void;

  isVideoStabilizationSupported(): boolean;

  isVideoStabilizationEnabled(): boolean;

  setEnablesVideoStabilizationWhenAvailable(enablesVideoStabilizationWhenAvailable: boolean): void;

  isCameraIntrinsicMatrixDeliverySupported(): boolean;

  isCameraIntrinsicMatrixDeliveryEnabled(): boolean;

  setCameraIntrinsicMatrixDeliveryEnabled(cameraIntrinsicMatrixDeliveryEnabled: boolean): void;
}

declare class AVCaptureMultiCamSession extends AVCaptureSession {
  static readonly multiCamSupported: boolean;

  readonly hardwareCost: number;

  readonly systemPressureCost: number;

  static isMultiCamSupported(): boolean;
}

declare class AVCaptureFraming extends NSObject {
  readonly aspectRatio: string;

  readonly zoomFactor: number;
}

declare class AVCaptureReactionEffectState extends NSObject {
  readonly reactionType: string;

  readonly startTime: CMTime;

  readonly endTime: CMTime;
}

declare class AVAssetDownloadURLSession extends NSURLSession {
  static sessionWithConfigurationAssetDownloadDelegateDelegateQueue(configuration: NSURLSessionConfiguration, delegate: AVAssetDownloadDelegate | null, delegateQueue: NSOperationQueue | null): AVAssetDownloadURLSession;

  assetDownloadTaskWithURLAssetDestinationURLOptions(URLAsset: AVURLAsset, destinationURL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): AVAssetDownloadTask;

  assetDownloadTaskWithURLAssetAssetTitleAssetArtworkDataOptions(URLAsset: AVURLAsset, title: string, artworkData: NSData | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): AVAssetDownloadTask;

  aggregateAssetDownloadTaskWithURLAssetMediaSelectionsAssetTitleAssetArtworkDataOptions(URLAsset: AVURLAsset, mediaSelections: NSArray<interop.Object> | Array<interop.Object>, title: string, artworkData: NSData | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): AVAggregateAssetDownloadTask;

  assetDownloadTaskWithConfiguration(downloadConfiguration: AVAssetDownloadConfiguration): AVAssetDownloadTask;
}

declare class AVAssetWriterInputGroup extends AVMediaSelectionGroup {
  static assetWriterInputGroupWithInputsDefaultInput<This extends abstract new (...args: any) => any>(this: This, inputs: NSArray<interop.Object> | Array<interop.Object>, defaultInput: AVAssetWriterInput | null): InstanceType<This>;

  initWithInputsDefaultInput(inputs: NSArray<interop.Object> | Array<interop.Object>, defaultInput: AVAssetWriterInput | null): this;

  readonly inputs: NSArray;

  readonly defaultInput: AVAssetWriterInput;
}

declare class AVSynchronizedLayer extends CALayer {
  static synchronizedLayerWithPlayerItem(playerItem: AVPlayerItem): AVSynchronizedLayer;

  playerItem: AVPlayerItem;

  setPlayerItem(playerItem: AVPlayerItem): void;
}

declare class AVSampleBufferVideoRenderer extends NSObject implements AVQueuedSampleBufferRendering {
  readonly status: interop.Enum<typeof AVQueuedSampleBufferRenderingStatus>;

  readonly error: NSError;

  readonly requiresFlushToResumeDecoding: boolean;

  flushWithRemovalOfDisplayedImageCompletionHandler(removeDisplayedImage: boolean, handler: () => void | null): void;

  copyDisplayedPixelBuffer(): interop.Object;

  expectMinimumUpcomingSampleBufferPresentationTime(minimumUpcomingPresentationTime: CMTime): void;

  expectMonotonicallyIncreasingUpcomingSampleBufferPresentationTimes(): void;

  resetUpcomingSampleBufferPresentationTimeExpectations(): void;

  readonly recommendedPixelBufferAttributes: NSDictionary;

  loadVideoPerformanceMetricsWithCompletionHandler(completionHandler: (p1: AVVideoPerformanceMetrics) => void | null): void;

  readonly timebase: interop.Object;

  enqueueSampleBuffer(sampleBuffer: interop.Object): void;

  flush(): void;

  readonly readyForMoreMediaData: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  stopRequestingMediaData(): void;

  readonly hasSufficientMediaDataForReliablePlaybackStart: boolean;

  isReadyForMoreMediaData(): boolean;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;
}

declare class AVMetadataItemValueRequest extends NSObject {
  readonly metadataItem: AVMetadataItem | null;

  respondWithValue(value: NSCopying): void;

  respondWithError(error: NSError): void;
}

declare class AVSampleBufferGeneratorBatch extends NSObject {
  makeDataReadyWithCompletionHandler(completionHandler: (p1: NSError) => void | null): void;

  cancel(): void;
}

declare class AVSampleBufferGenerator extends NSObject {
  initWithAssetTimebase(asset: AVAsset, timebase: interop.Object | null): this;

  createSampleBufferForRequestError(request: AVSampleBufferRequest, outError: interop.PointerConvertible): interop.Object;

  makeBatch(): AVSampleBufferGeneratorBatch;

  createSampleBufferForRequestAddingToBatchError(request: AVSampleBufferRequest, batch: AVSampleBufferGeneratorBatch, outError: interop.PointerConvertible): interop.Object;

  static notifyOfDataReadyForSampleBufferCompletionHandler(sbuf: interop.Object, completionHandler: (p1: boolean, p2: NSError) => void | null): void;
}

declare class AVSampleBufferDisplayLayer extends CALayer {
  controlTimebase: interop.Object;

  videoGravity: string;

  readonly readyForDisplay: boolean;

  setControlTimebase(controlTimebase: interop.Object | null): void;

  setVideoGravity(videoGravity: string): void;

  isReadyForDisplay(): boolean;

  readonly timebase: interop.Object;

  readonly status: interop.Enum<typeof AVQueuedSampleBufferRenderingStatus>;

  readonly error: NSError;

  enqueueSampleBuffer(sampleBuffer: interop.Object): void;

  flush(): void;

  flushAndRemoveImage(): void;

  readonly requiresFlushToResumeDecoding: boolean;

  readonly readyForMoreMediaData: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  stopRequestingMediaData(): void;

  readonly hasSufficientMediaDataForReliablePlaybackStart: boolean;

  isReadyForMoreMediaData(): boolean;

  preventsCapture: boolean;

  setPreventsCapture(preventsCapture: boolean): void;

  preventsDisplaySleepDuringVideoPlayback: boolean;

  setPreventsDisplaySleepDuringVideoPlayback(preventsDisplaySleepDuringVideoPlayback: boolean): void;

  readonly outputObscuredDueToInsufficientExternalProtection: boolean;

  readonly sampleBufferRenderer: AVSampleBufferVideoRenderer;
}

declare class AVAssetVariantQualifier extends NSObject implements NSCopying {
  static assetVariantQualifierWithPredicate<This extends abstract new (...args: any) => any>(this: This, predicate: NSPredicate): InstanceType<This>;

  static assetVariantQualifierWithVariant<This extends abstract new (...args: any) => any>(this: This, variant: AVAssetVariant): InstanceType<This>;

  static predicateForChannelCountMediaSelectionOptionOperatorType(channelCount: number, mediaSelectionOption: AVMediaSelectionOption | null, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  static predicateForBinauralAudioMediaSelectionOption(isBinauralAudio: boolean, mediaSelectionOption: AVMediaSelectionOption | null): NSPredicate;

  static predicateForImmersiveAudioMediaSelectionOption(isImmersiveAudio: boolean, mediaSelectionOption: AVMediaSelectionOption | null): NSPredicate;

  static predicateForDownmixAudioMediaSelectionOption(isDownmixAudio: boolean, mediaSelectionOption: AVMediaSelectionOption | null): NSPredicate;

  static predicateForPresentationWidthOperatorType(width: number, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  static predicateForPresentationHeightOperatorType(height: number, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  static predicateForAudioSampleRateMediaSelectionOptionOperatorType(sampleRate: number, mediaSelectionOption: AVMediaSelectionOption | null, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  static predicateForChannelCountOperatorType(channelCount: number, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  static predicateForBinauralAudio(isBinauralAudio: boolean): NSPredicate;

  static predicateForImmersiveAudio(isImmersiveAudio: boolean): NSPredicate;

  static predicateForDownmixAudio(isDownmixAudio: boolean): NSPredicate;

  static predicateForAudioSampleRateOperatorType(sampleRate: number, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVSampleBufferAudioRenderer extends NSObject implements AVQueuedSampleBufferRendering {
  readonly status: interop.Enum<typeof AVQueuedSampleBufferRenderingStatus>;

  readonly error: NSError;

  audioTimePitchAlgorithm: string;

  allowedAudioSpatializationFormats: interop.Enum<typeof AVAudioSpatializationFormats>;

  setAudioTimePitchAlgorithm(audioTimePitchAlgorithm: string): void;

  setAllowedAudioSpatializationFormats(allowedAudioSpatializationFormats: interop.Enum<typeof AVAudioSpatializationFormats>): void;

  volume: number;

  muted: boolean;

  setVolume(volume: number): void;

  isMuted(): boolean;

  setMuted(muted: boolean): void;

  flushFromSourceTimeCompletionHandler(time: CMTime, completionHandler: (p1: boolean) => void): void;

  readonly timebase: interop.Object;

  enqueueSampleBuffer(sampleBuffer: interop.Object): void;

  flush(): void;

  readonly readyForMoreMediaData: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  stopRequestingMediaData(): void;

  readonly hasSufficientMediaDataForReliablePlaybackStart: boolean;

  isReadyForMoreMediaData(): boolean;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVPlayerInterstitialEventController extends AVPlayerInterstitialEventMonitor {
  static interstitialEventControllerWithPrimaryPlayer<This extends abstract new (...args: any) => any>(this: This, primaryPlayer: AVPlayer): InstanceType<This>;

  initWithPrimaryPlayer(primaryPlayer: AVPlayer): this;

  // @ts-ignore MemberDecl.tsIgnore
  get events(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set events(value: NSArray<interop.Object> | Array<interop.Object>);

  cancelCurrentEventWithResumptionOffset(resumptionOffset: CMTime): void;

  skipCurrentEvent(): void;

  localizedStringsBundle: NSBundle;

  localizedStringsTableName: string;

  setEvents(events: NSArray<interop.Object> | Array<interop.Object> | null): void;

  setLocalizedStringsBundle(localizedStringsBundle: NSBundle | null): void;

  setLocalizedStringsTableName(localizedStringsTableName: string | null): void;
}

declare class AVPlayerItemMetadataOutput extends AVPlayerItemOutput {
  initWithIdentifiers(identifiers: NSArray<interop.Object> | Array<interop.Object> | null): this;

  setDelegateQueue(delegate: AVPlayerItemMetadataOutputPushDelegate | null, delegateQueue: NSObject | null): void;

  readonly delegate: AVPlayerItemMetadataOutputPushDelegate;

  readonly delegateQueue: NSObject;

  advanceIntervalForDelegateInvocation: number;

  setAdvanceIntervalForDelegateInvocation(advanceIntervalForDelegateInvocation: number): void;
}

declare class AVPlayerItemLegibleOutput extends AVPlayerItemOutput {
  setDelegateQueue(delegate: AVPlayerItemLegibleOutputPushDelegate | null, delegateQueue: NSObject | null): void;

  readonly delegate: AVPlayerItemLegibleOutputPushDelegate;

  readonly delegateQueue: NSObject;

  advanceIntervalForDelegateInvocation: number;

  setAdvanceIntervalForDelegateInvocation(advanceIntervalForDelegateInvocation: number): void;

  initWithMediaSubtypesForNativeRepresentation(subtypes: NSArray<interop.Object> | Array<interop.Object>): this;

  textStylingResolution: string;

  setTextStylingResolution(textStylingResolution: string): void;
}

declare class AVPlayerItemVideoOutput extends AVPlayerItemOutput {
  initWithPixelBufferAttributes(pixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  initWithOutputSettings(outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  hasNewPixelBufferForItemTime(itemTime: CMTime): boolean;

  copyPixelBufferForItemTimeItemTimeForDisplay(itemTime: CMTime, outItemTimeForDisplay: interop.PointerConvertible): interop.Object;

  setDelegateQueue(delegate: AVPlayerItemOutputPullDelegate | null, delegateQueue: NSObject | null): void;

  requestNotificationOfMediaDataChangeWithAdvanceInterval(interval: number): void;

  readonly delegate: AVPlayerItemOutputPullDelegate;

  readonly delegateQueue: NSObject;
}

declare class AVPlayerItemOutput extends NSObject {
  itemTimeForHostTime(hostTimeInSeconds: number): CMTime;

  itemTimeForMachAbsoluteTime(machAbsoluteTime: number): CMTime;

  suppressesPlayerRendering: boolean;

  setSuppressesPlayerRendering(suppressesPlayerRendering: boolean): void;
}

declare class AVPlaybackCoordinator extends NSObject {
  readonly otherParticipants: NSArray;

  readonly suspensionReasons: NSArray;

  beginSuspensionForReason(suspensionReason: string): AVCoordinatedPlaybackSuspension;

  expectedItemTimeAtHostTime(hostClockTime: CMTime): CMTime;

  setParticipantLimitForWaitingOutSuspensionsWithReason(participantLimit: number, reason: string): void;

  participantLimitForWaitingOutSuspensionsWithReason(reason: string): number;

  get suspensionReasonsThatTriggerWaiting(): NSArray;
  set suspensionReasonsThatTriggerWaiting(value: NSArray<interop.Object> | Array<interop.Object>);

  pauseSnapsToMediaTimeOfOriginator: boolean;

  setSuspensionReasonsThatTriggerWaiting(suspensionReasonsThatTriggerWaiting: NSArray<interop.Object> | Array<interop.Object>): void;

  setPauseSnapsToMediaTimeOfOriginator(pauseSnapsToMediaTimeOfOriginator: boolean): void;
}

declare class AVPlayerItemMetadataCollector extends AVPlayerItemMediaDataCollector {
  initWithIdentifiersClassifyingLabels(identifiers: NSArray<interop.Object> | Array<interop.Object> | null, classifyingLabels: NSArray<interop.Object> | Array<interop.Object> | null): this;

  setDelegateQueue(delegate: AVPlayerItemMetadataCollectorPushDelegate | null, delegateQueue: NSObject | null): void;

  readonly delegate: AVPlayerItemMetadataCollectorPushDelegate;

  readonly delegateQueue: NSObject;
}

declare class AVPlayerItemAccessLogEvent extends NSObject implements NSCopying {
  readonly numberOfSegmentsDownloaded: number;

  readonly numberOfMediaRequests: number;

  readonly playbackStartDate: NSDate;

  readonly URI: string;

  readonly serverAddress: string;

  readonly numberOfServerAddressChanges: number;

  readonly playbackSessionID: string;

  readonly playbackStartOffset: number;

  readonly segmentsDownloadedDuration: number;

  readonly durationWatched: number;

  readonly numberOfStalls: number;

  readonly numberOfBytesTransferred: number;

  readonly transferDuration: number;

  readonly observedBitrate: number;

  readonly indicatedBitrate: number;

  readonly indicatedAverageBitrate: number;

  readonly averageVideoBitrate: number;

  readonly averageAudioBitrate: number;

  readonly numberOfDroppedVideoFrames: number;

  readonly startupTime: number;

  readonly downloadOverdue: number;

  readonly observedMaxBitrate: number;

  readonly observedMinBitrate: number;

  readonly observedBitrateStandardDeviation: number;

  readonly playbackType: string;

  readonly mediaRequestsWWAN: number;

  readonly switchBitrate: number;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVVideoOutputSpecification extends NSObject implements NSCopying {
  initWithTagCollections(tagCollections: NSArray<interop.Object> | Array<interop.Object>): this;

  setOutputPixelBufferAttributesForTagCollection(pixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, tagCollection: interop.PointerConvertible): void;

  setOutputSettingsForTagCollection(outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, tagCollection: interop.PointerConvertible): void;

  readonly preferredTagCollections: NSArray;

  get defaultPixelBufferAttributes(): NSDictionary;
  set defaultPixelBufferAttributes(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  get defaultOutputSettings(): NSDictionary;
  set defaultOutputSettings(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  setDefaultPixelBufferAttributes(defaultPixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): void;

  setDefaultOutputSettings(defaultOutputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVDelegatingPlaybackCoordinatorSeekCommand extends AVDelegatingPlaybackCoordinatorPlaybackControlCommand {
  readonly itemTime: CMTime;

  readonly shouldBufferInAnticipationOfPlayback: boolean;

  readonly anticipatedPlaybackRate: number;

  readonly completionDueDate: NSDate;
}

declare class AVDelegatingPlaybackCoordinatorPauseCommand extends AVDelegatingPlaybackCoordinatorPlaybackControlCommand {
  readonly shouldBufferInAnticipationOfPlayback: boolean;

  readonly anticipatedPlaybackRate: number;
}

declare class AVPlayerLayer extends CALayer {
  static playerLayerWithPlayer(player: AVPlayer | null): AVPlayerLayer;

  player: AVPlayer;

  videoGravity: string;

  readonly readyForDisplay: boolean;

  readonly videoRect: CGRect;

  get pixelBufferAttributes(): NSDictionary;
  set pixelBufferAttributes(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  copyDisplayedPixelBuffer(): interop.Object;

  setPlayer(player: AVPlayer | null): void;

  setVideoGravity(videoGravity: string): void;

  isReadyForDisplay(): boolean;

  setPixelBufferAttributes(pixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): void;
}

declare class AVDelegatingPlaybackCoordinatorBufferingCommand extends AVDelegatingPlaybackCoordinatorPlaybackControlCommand {
  readonly anticipatedPlaybackRate: number;

  readonly completionDueDate: NSDate;
}

declare class AVDelegatingPlaybackCoordinatorPlayCommand extends AVDelegatingPlaybackCoordinatorPlaybackControlCommand {
  readonly rate: number;

  readonly itemTime: CMTime;

  readonly hostClockTime: CMTime;
}

declare class AVAssetExportSession extends NSObject {
  static exportSessionWithAssetPresetName<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset, presetName: string): InstanceType<This>;

  initWithAssetPresetName(asset: AVAsset, presetName: string): this;

  readonly presetName: string;

  readonly asset: AVAsset;

  outputFileType: string;

  outputURL: NSURL;

  shouldOptimizeForNetworkUse: boolean;

  readonly status: interop.Enum<typeof AVAssetExportSessionStatus>;

  readonly error: NSError;

  exportAsynchronouslyWithCompletionHandler(handler: () => void): void;

  readonly progress: number;

  cancelExport(): void;

  setOutputFileType(outputFileType: string | null): void;

  setOutputURL(outputURL: NSURL | null): void;

  setShouldOptimizeForNetworkUse(shouldOptimizeForNetworkUse: boolean): void;

  static allExportPresets(): NSArray;

  static exportPresetsCompatibleWithAsset(asset: AVAsset): NSArray;

  static determineCompatibilityOfExportPresetWithAssetOutputFileTypeCompletionHandler(presetName: string, asset: AVAsset, outputFileType: string | null, handler: (p1: boolean) => void): void;

  readonly supportedFileTypes: NSArray;

  determineCompatibleFileTypesWithCompletionHandler(handler: (p1: NSArray<interop.Object> | Array<interop.Object>) => void): void;

  timeRange: CMTimeRange;

  readonly maxDuration: CMTime;

  readonly estimatedOutputFileLength: number;

  fileLengthLimit: number;

  estimateMaximumDurationWithCompletionHandler(handler: (p1: CMTime, p2: NSError) => void | null): void;

  estimateOutputFileLengthWithCompletionHandler(handler: (p1: number, p2: NSError) => void | null): void;

  setTimeRange(timeRange: CMTimeRange): void;

  setFileLengthLimit(fileLengthLimit: number): void;

  get metadata(): NSArray;
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  metadataItemFilter: AVMetadataItemFilter;

  setMetadata(metadata: NSArray<interop.Object> | Array<interop.Object> | null): void;

  setMetadataItemFilter(metadataItemFilter: AVMetadataItemFilter): void;

  audioTimePitchAlgorithm: string;

  audioMix: AVAudioMix;

  videoComposition: AVVideoComposition;

  readonly customVideoCompositor: AVVideoCompositing;

  audioTrackGroupHandling: interop.Enum<typeof AVAssetTrackGroupOutputHandling>;

  setAudioTimePitchAlgorithm(audioTimePitchAlgorithm: string): void;

  setAudioMix(audioMix: AVAudioMix | null): void;

  setVideoComposition(videoComposition: AVVideoComposition | null): void;

  setAudioTrackGroupHandling(audioTrackGroupHandling: interop.Enum<typeof AVAssetTrackGroupOutputHandling>): void;

  canPerformMultiplePassesOverSourceMediaData: boolean;

  directoryForTemporaryFiles: NSURL;

  setCanPerformMultiplePassesOverSourceMediaData(canPerformMultiplePassesOverSourceMediaData: boolean): void;

  setDirectoryForTemporaryFiles(directoryForTemporaryFiles: NSURL): void;
}

declare class AVCoordinatedPlaybackSuspension extends NSObject {
  readonly reason: string;

  readonly beginDate: NSDate;

  end(): void;

  endProposingNewTime(time: CMTime): void;
}

declare class AVPlayer extends NSObject {
  init(): this;

  static playerWithURL<This extends abstract new (...args: any) => any>(this: This, URL: NSURL): InstanceType<This>;

  static playerWithPlayerItem<This extends abstract new (...args: any) => any>(this: This, item: AVPlayerItem | null): InstanceType<This>;

  initWithURL(URL: NSURL): this;

  initWithPlayerItem(item: AVPlayerItem | null): this;

  readonly status: interop.Enum<typeof AVPlayerStatus>;

  readonly error: NSError;

  rate: number;

  defaultRate: number;

  play(): void;

  pause(): void;

  readonly timeControlStatus: interop.Enum<typeof AVPlayerTimeControlStatus>;

  readonly reasonForWaitingToPlay: string;

  playImmediatelyAtRate(rate: number): void;

  setRate(rate: number): void;

  setDefaultRate(defaultRate: number): void;

  readonly currentItem: AVPlayerItem;

  replaceCurrentItemWithPlayerItem(item: AVPlayerItem | null): void;

  actionAtItemEnd: interop.Enum<typeof AVPlayerActionAtItemEnd>;

  setActionAtItemEnd(actionAtItemEnd: interop.Enum<typeof AVPlayerActionAtItemEnd>): void;

  currentTime(): CMTime;

  seekToDate(date: NSDate): void;

  seekToDateCompletionHandler(date: NSDate, completionHandler: (p1: boolean) => void): void;

  seekToTime(time: CMTime): void;

  seekToTimeToleranceBeforeToleranceAfter(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime): void;

  seekToTimeCompletionHandler(time: CMTime, completionHandler: (p1: boolean) => void): void;

  seekToTimeToleranceBeforeToleranceAfterCompletionHandler(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime, completionHandler: (p1: boolean) => void): void;

  automaticallyWaitsToMinimizeStalling: boolean;

  setRateTimeAtHostTime(rate: number, itemTime: CMTime, hostClockTime: CMTime): void;

  prerollAtRateCompletionHandler(rate: number, completionHandler: (p1: boolean) => void | null): void;

  cancelPendingPrerolls(): void;

  sourceClock: interop.Object;

  setAutomaticallyWaitsToMinimizeStalling(automaticallyWaitsToMinimizeStalling: boolean): void;

  setSourceClock(sourceClock: interop.Object | null): void;

  addPeriodicTimeObserverForIntervalQueueUsingBlock(interval: CMTime, queue: NSObject | null, block: (p1: CMTime) => void): interop.Object;

  addBoundaryTimeObserverForTimesQueueUsingBlock(times: NSArray<interop.Object> | Array<interop.Object>, queue: NSObject | null, block: () => void): interop.Object;

  removeTimeObserver(observer: interop.Object): void;

  volume: number;

  muted: boolean;

  setVolume(volume: number): void;

  isMuted(): boolean;

  setMuted(muted: boolean): void;

  appliesMediaSelectionCriteriaAutomatically: boolean;

  setMediaSelectionCriteriaForMediaCharacteristic(criteria: AVPlayerMediaSelectionCriteria | null, mediaCharacteristic: string): void;

  mediaSelectionCriteriaForMediaCharacteristic(mediaCharacteristic: string): AVPlayerMediaSelectionCriteria;

  setAppliesMediaSelectionCriteriaAutomatically(appliesMediaSelectionCriteriaAutomatically: boolean): void;

  allowsExternalPlayback: boolean;

  readonly externalPlaybackActive: boolean;

  usesExternalPlaybackWhileExternalScreenIsActive: boolean;

  externalPlaybackVideoGravity: string;

  setAllowsExternalPlayback(allowsExternalPlayback: boolean): void;

  isExternalPlaybackActive(): boolean;

  setUsesExternalPlaybackWhileExternalScreenIsActive(usesExternalPlaybackWhileExternalScreenIsActive: boolean): void;

  setExternalPlaybackVideoGravity(externalPlaybackVideoGravity: string): void;

  allowsAirPlayVideo: boolean;

  readonly airPlayVideoActive: boolean;

  usesAirPlayVideoWhileAirPlayScreenIsActive: boolean;

  setAllowsAirPlayVideo(allowsAirPlayVideo: boolean): void;

  isAirPlayVideoActive(): boolean;

  setUsesAirPlayVideoWhileAirPlayScreenIsActive(usesAirPlayVideoWhileAirPlayScreenIsActive: boolean): void;

  readonly outputObscuredDueToInsufficientExternalProtection: boolean;

  static readonly availableHDRModes: interop.Enum<typeof AVPlayerHDRMode>;

  static readonly eligibleForHDRPlayback: boolean;

  preventsDisplaySleepDuringVideoPlayback: boolean;

  setPreventsDisplaySleepDuringVideoPlayback(preventsDisplaySleepDuringVideoPlayback: boolean): void;

  audiovisualBackgroundPlaybackPolicy: interop.Enum<typeof AVPlayerAudiovisualBackgroundPlaybackPolicy>;

  setAudiovisualBackgroundPlaybackPolicy(audiovisualBackgroundPlaybackPolicy: interop.Enum<typeof AVPlayerAudiovisualBackgroundPlaybackPolicy>): void;

  readonly playbackCoordinator: AVPlayerPlaybackCoordinator;

  videoOutput: AVPlayerVideoOutput;

  setVideoOutput(videoOutput: AVPlayerVideoOutput | null): void;

  networkResourcePriority: interop.Enum<typeof AVPlayerNetworkResourcePriority>;

  setNetworkResourcePriority(networkResourcePriority: interop.Enum<typeof AVPlayerNetworkResourcePriority>): void;

  readonly audioOutputSuppressedDueToNonMixableAudioRoute: boolean;

  static observationEnabled: boolean;

  static isObservationEnabled(): boolean;

  static setObservationEnabled(observationEnabled: boolean): void;

  closedCaptionDisplayEnabled: boolean;

  masterClock: interop.Object;

  isClosedCaptionDisplayEnabled(): boolean;

  setClosedCaptionDisplayEnabled(closedCaptionDisplayEnabled: boolean): void;

  setMasterClock(masterClock: interop.Object): void;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableMovie extends AVMovie {
  static movieWithURLOptionsError<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): InstanceType<This>;

  initWithURLOptionsError(URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): this;

  static movieWithDataOptionsError<This extends abstract new (...args: any) => any>(this: This, data: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): InstanceType<This>;

  initWithDataOptionsError(data: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): this;

  static movieWithSettingsFromMovieOptionsError<This extends abstract new (...args: any) => any>(this: This, movie: AVMovie | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): InstanceType<This>;

  initWithSettingsFromMovieOptionsError(movie: AVMovie | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): this;

  // @ts-ignore MemberDecl.tsIgnore
  preferredRate: number;

  // @ts-ignore MemberDecl.tsIgnore
  preferredVolume: number;

  // @ts-ignore MemberDecl.tsIgnore
  preferredTransform: CGAffineTransform;

  timescale: number;

  readonly tracks: NSArray;

  setPreferredRate(preferredRate: number): void;

  setPreferredVolume(preferredVolume: number): void;

  setPreferredTransform(preferredTransform: CGAffineTransform): void;

  setTimescale(timescale: number): void;

  modified: boolean;

  // @ts-ignore MemberDecl.tsIgnore
  defaultMediaDataStorage: AVMediaDataStorage;

  interleavingPeriod: CMTime;

  insertTimeRangeOfAssetAtTimeCopySampleDataError(timeRange: CMTimeRange, asset: AVAsset, startTime: CMTime, copySampleData: boolean, outError: interop.PointerConvertible): boolean;

  insertEmptyTimeRange(timeRange: CMTimeRange): void;

  removeTimeRange(timeRange: CMTimeRange): void;

  scaleTimeRangeToDuration(timeRange: CMTimeRange, duration: CMTime): void;

  isModified(): boolean;

  setModified(modified: boolean): void;

  setDefaultMediaDataStorage(defaultMediaDataStorage: AVMediaDataStorage | null): void;

  setInterleavingPeriod(interleavingPeriod: CMTime): void;

  mutableTrackCompatibleWithTrack(track: AVAssetTrack): AVMutableMovieTrack;

  addMutableTrackWithMediaTypeCopySettingsFromTrackOptions(mediaType: string, track: AVAssetTrack | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): AVMutableMovieTrack;

  addMutableTracksCopyingSettingsFromTracksOptions(existingTracks: NSArray<interop.Object> | Array<interop.Object>, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): NSArray;

  removeTrack(track: AVMovieTrack): void;

  // @ts-ignore MemberDecl.tsIgnore
  get metadata(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  setMetadata(metadata: NSArray<interop.Object> | Array<interop.Object>): void;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVMutableMovieTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVMutableMovieTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  metadataForFormat(format: string): NSArray;

  chapterMetadataGroupsWithTitleLocaleContainingItemsWithCommonKeys(locale: NSLocale, commonKeys: NSArray<interop.Object> | Array<interop.Object> | null): NSArray;

  chapterMetadataGroupsBestMatchingPreferredLanguages(preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  mediaSelectionGroupForMediaCharacteristic(mediaCharacteristic: string): AVMediaSelectionGroup;

  unusedTrackID(): number;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMovie extends AVAsset implements NSCopying, NSMutableCopying {
  static movieTypes(): NSArray;

  static movieWithURLOptions<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithURLOptions(URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  static movieWithDataOptions<This extends abstract new (...args: any) => any>(this: This, data: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithDataOptions(data: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly URL: NSURL;

  readonly data: NSData;

  readonly defaultMediaDataStorage: AVMediaDataStorage;

  readonly tracks: NSArray;

  readonly canContainMovieFragments: boolean;

  readonly containsMovieFragments: boolean;

  movieHeaderWithFileTypeError(fileType: string, outError: interop.PointerConvertible): NSData;

  writeMovieHeaderToURLFileTypeOptionsError(URL: NSURL, fileType: string, options: interop.Enum<typeof AVMovieWritingOptions>, outError: interop.PointerConvertible): boolean;

  isCompatibleWithFileType(fileType: string): boolean;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVMovieTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVMovieTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVFragmentedMovieTrack extends AVMovieTrack {
}

declare class AVMetadataItemFilter extends NSObject {
  static metadataItemFilterForSharing(): AVMetadataItemFilter;
}

declare class AVCompositionTrackSegment extends AVAssetTrackSegment {
  static compositionTrackSegmentWithURLTrackIDSourceTimeRangeTargetTimeRange<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, trackID: number, sourceTimeRange: CMTimeRange, targetTimeRange: CMTimeRange): InstanceType<This>;

  static compositionTrackSegmentWithTimeRange<This extends abstract new (...args: any) => any>(this: This, timeRange: CMTimeRange): InstanceType<This>;

  initWithURLTrackIDSourceTimeRangeTargetTimeRange(URL: NSURL, trackID: number, sourceTimeRange: CMTimeRange, targetTimeRange: CMTimeRange): this;

  initWithTimeRange(timeRange: CMTimeRange): this;

  readonly empty: boolean;

  readonly sourceURL: NSURL;

  readonly sourceTrackID: number;

  isEmpty(): boolean;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVComposition extends AVAsset implements NSMutableCopying {
  readonly tracks: NSArray;

  readonly naturalSize: CGSize;

  readonly URLAssetInitializationOptions: NSDictionary;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVCompositionTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVCompositionTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  metadataForFormat(format: string): NSArray;

  chapterMetadataGroupsWithTitleLocaleContainingItemsWithCommonKeys(locale: NSLocale, commonKeys: NSArray<interop.Object> | Array<interop.Object> | null): NSArray;

  chapterMetadataGroupsBestMatchingPreferredLanguages(preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  mediaSelectionGroupForMediaCharacteristic(mediaCharacteristic: string): AVMediaSelectionGroup;

  unusedTrackID(): number;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVPlayerInterstitialEventMonitor extends NSObject {
  static interstitialEventMonitorWithPrimaryPlayer<This extends abstract new (...args: any) => any>(this: This, primaryPlayer: AVPlayer): InstanceType<This>;

  initWithPrimaryPlayer(primaryPlayer: AVPlayer): this;

  readonly primaryPlayer: AVPlayer | null;

  readonly interstitialPlayer: AVQueuePlayer;

  readonly events: NSArray;

  readonly currentEvent: AVPlayerInterstitialEvent;

  readonly currentEventSkippableState: interop.Enum<typeof AVPlayerInterstitialEventSkippableEventState>;

  readonly currentEventSkipControlLabel: string;
}

declare class AVTextStyleRule extends NSObject implements NSCopying {
  static propertyListForTextStyleRules(textStyleRules: NSArray<interop.Object> | Array<interop.Object>): interop.Object;

  static textStyleRulesFromPropertyList(plist: interop.Object): NSArray;

  static textStyleRuleWithTextMarkupAttributes(textMarkupAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): AVTextStyleRule;

  static textStyleRuleWithTextMarkupAttributesTextSelector(textMarkupAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, textSelector: string | null): AVTextStyleRule;

  initWithTextMarkupAttributes(textMarkupAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  initWithTextMarkupAttributesTextSelector(textMarkupAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, textSelector: string | null): this;

  readonly textMarkupAttributes: NSDictionary;

  readonly textSelector: string;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetricHLSMediaSegmentRequestEvent extends AVMetricEvent {
  readonly url: NSURL;

  readonly isMapSegment: boolean;

  readonly mediaType: string;

  readonly byteRange: _NSRange;

  readonly indexFileURL: NSURL;

  readonly segmentDuration: number;

  readonly mediaResourceRequestEvent: AVMetricMediaResourceRequestEvent;
}

declare class AVCaptionConversionAdjustment extends NSObject {
  readonly adjustmentType: string;
}

declare class AVAssetDownloadStorageManager extends NSObject {
  static sharedDownloadStorageManager(): AVAssetDownloadStorageManager;

  setStorageManagementPolicyForURL(storageManagementPolicy: AVAssetDownloadStorageManagementPolicy, downloadStorageURL: NSURL): void;

  storageManagementPolicyForURL(downloadStorageURL: NSURL): AVAssetDownloadStorageManagementPolicy;
}

declare class AVCaptionConversionWarning extends NSObject {
  readonly warningType: string;

  readonly rangeOfCaptions: _NSRange;

  readonly adjustment: AVCaptionConversionAdjustment;
}

declare class AVCaption extends NSObject implements NSCopying, NSMutableCopying, NSSecureCoding {
  initWithTextTimeRange(text: string, timeRange: CMTimeRange): this;

  readonly text: string;

  readonly timeRange: CMTimeRange;

  textColorAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Object;

  backgroundColorAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Object;

  fontWeightAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Enum<typeof AVCaptionFontWeight>;

  fontStyleAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Enum<typeof AVCaptionFontStyle>;

  decorationAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Enum<typeof AVCaptionDecoration>;

  textCombineAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Enum<typeof AVCaptionTextCombine>;

  rubyAtIndexRange(index: number, outRange: interop.PointerConvertible): AVCaptionRuby;

  readonly region: AVCaptionRegion;

  readonly textAlignment: interop.Enum<typeof AVCaptionTextAlignment>;

  readonly animation: interop.Enum<typeof AVCaptionAnimation>;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableCaptionRegion extends AVCaptionRegion {
  init(): this;

  initWithIdentifier(identifier: string): this;

  // @ts-ignore MemberDecl.tsIgnore
  origin: AVCaptionPoint;

  // @ts-ignore MemberDecl.tsIgnore
  size: AVCaptionSize;

  // @ts-ignore MemberDecl.tsIgnore
  scroll: interop.Enum<typeof AVCaptionRegionScroll>;

  // @ts-ignore MemberDecl.tsIgnore
  displayAlignment: interop.Enum<typeof AVCaptionRegionDisplayAlignment>;

  // @ts-ignore MemberDecl.tsIgnore
  writingMode: interop.Enum<typeof AVCaptionRegionWritingMode>;

  setOrigin(origin: AVCaptionPoint): void;

  setSize(size: AVCaptionSize): void;

  setScroll(scroll: interop.Enum<typeof AVCaptionRegionScroll>): void;

  setDisplayAlignment(displayAlignment: interop.Enum<typeof AVCaptionRegionDisplayAlignment>): void;

  setWritingMode(writingMode: interop.Enum<typeof AVCaptionRegionWritingMode>): void;
}

declare class AVCaptionRegion extends NSObject implements NSCopying, NSMutableCopying, NSSecureCoding {
  static readonly appleITTTopRegion: AVCaptionRegion;

  static readonly appleITTBottomRegion: AVCaptionRegion;

  static readonly appleITTLeftRegion: AVCaptionRegion;

  static readonly appleITTRightRegion: AVCaptionRegion;

  static readonly subRipTextBottomRegion: AVCaptionRegion;

  readonly identifier: string;

  readonly origin: AVCaptionPoint;

  readonly size: AVCaptionSize;

  readonly scroll: interop.Enum<typeof AVCaptionRegionScroll>;

  readonly displayAlignment: interop.Enum<typeof AVCaptionRegionDisplayAlignment>;

  readonly writingMode: interop.Enum<typeof AVCaptionRegionWritingMode>;

  encodeWithCoder(encoder: NSCoder): void;

  isEqual(object: interop.Object): boolean;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  static readonly supportsSecureCoding: boolean;

  initWithCoder(coder: NSCoder): this;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableAssetDownloadStorageManagementPolicy extends AVAssetDownloadStorageManagementPolicy {
  // @ts-ignore MemberDecl.tsIgnore
  priority: string;

  // @ts-ignore MemberDecl.tsIgnore
  expirationDate: NSDate;

  setPriority(priority: string): void;

  setExpirationDate(expirationDate: NSDate): void;
}

declare class AVAggregateAssetDownloadTask extends NSURLSessionTask {
  readonly URLAsset: AVURLAsset;
}

declare class AVAssetDownloadConfiguration extends NSObject {
  static downloadConfigurationWithAssetTitle<This extends abstract new (...args: any) => any>(this: This, asset: AVURLAsset, title: string): InstanceType<This>;

  artworkData: NSData;

  readonly primaryContentConfiguration: AVAssetDownloadContentConfiguration;

  get auxiliaryContentConfigurations(): NSArray;
  set auxiliaryContentConfigurations(value: NSArray<interop.Object> | Array<interop.Object>);

  optimizesAuxiliaryContentConfigurations: boolean;

  setInterstitialMediaSelectionCriteriaForMediaCharacteristic(criteria: NSArray<interop.Object> | Array<interop.Object>, mediaCharacteristic: string): void;

  setArtworkData(artworkData: NSData | null): void;

  setAuxiliaryContentConfigurations(auxiliaryContentConfigurations: NSArray<interop.Object> | Array<interop.Object>): void;

  setOptimizesAuxiliaryContentConfigurations(optimizesAuxiliaryContentConfigurations: boolean): void;
}

declare class AVAssetDownloadTask extends NSURLSessionTask {
  readonly URLAsset: AVURLAsset;

  readonly destinationURL: NSURL;

  readonly options: NSDictionary;

  readonly loadedTimeRanges: NSArray;
}

declare class AVMetricMediaResourceRequestEvent extends AVMetricEvent {
  readonly url: NSURL;

  readonly serverAddress: string;

  readonly requestStartTime: NSDate;

  readonly requestEndTime: NSDate;

  readonly responseStartTime: NSDate;

  readonly responseEndTime: NSDate;

  readonly byteRange: _NSRange;

  readonly readFromCache: boolean;

  readonly errorEvent: AVMetricErrorEvent;

  readonly networkTransactionMetrics: NSURLSessionTaskMetrics;

  wasReadFromCache(): boolean;
}

declare class AVMetricPlayerItemPlaybackSummaryEvent extends AVMetricEvent {
  readonly errorEvent: AVMetricErrorEvent;

  readonly recoverableErrorCount: number;

  readonly stallCount: number;

  readonly variantSwitchCount: number;

  readonly playbackDuration: number;

  readonly mediaResourceRequestCount: number;

  readonly timeSpentRecoveringFromStall: number;

  readonly timeSpentInInitialStartup: number;

  readonly timeWeightedAverageBitrate: number;

  readonly timeWeightedPeakBitrate: number;
}

declare class AVMetricPlayerItemSeekDidCompleteEvent extends AVMetricPlayerItemRateChangeEvent {
  readonly didSeekInBuffer: boolean;
}

declare class AVMetricPlayerItemSeekEvent extends AVMetricPlayerItemRateChangeEvent {
}

declare class AVAssetResourceLoadingRequest extends NSObject {
  readonly request: NSURLRequest;

  readonly finished: boolean;

  readonly cancelled: boolean;

  readonly contentInformationRequest: AVAssetResourceLoadingContentInformationRequest;

  readonly dataRequest: AVAssetResourceLoadingDataRequest;

  response: NSURLResponse;

  redirect: NSURLRequest;

  readonly requestor: AVAssetResourceLoadingRequestor;

  finishLoading(): void;

  finishLoadingWithError(error: NSError | null): void;

  isFinished(): boolean;

  isCancelled(): boolean;

  setResponse(response: NSURLResponse): void;

  setRedirect(redirect: NSURLRequest): void;

  streamingContentKeyRequestDataForAppContentIdentifierOptionsError(appIdentifier: NSData, contentIdentifier: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): NSData;

  persistentContentKeyFromKeyVendorResponseOptionsError(keyVendorResponse: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): NSData;

  finishLoadingWithResponseDataRedirect(response: NSURLResponse | null, data: NSData | null, redirect: NSURLRequest | null): void;
}

declare class AVAssetDownloadStorageManagementPolicy extends NSObject implements NSCopying, NSMutableCopying {
  readonly priority: string;

  readonly expirationDate: NSDate;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetricContentKeyRequestEvent extends AVMetricEvent {
  readonly contentKeySpecifier: AVContentKeySpecifier;

  readonly mediaType: string;

  readonly isClientInitiated: boolean;

  readonly mediaResourceRequestEvent: AVMetricMediaResourceRequestEvent;
}

declare class AVMetricErrorEvent extends AVMetricEvent {
  readonly didRecover: boolean;

  readonly error: NSError;
}

declare class AVMetricEvent extends NSObject implements NSSecureCoding {
  readonly date: NSDate;

  readonly mediaTime: CMTime;

  readonly sessionID: string;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVMetricEventStream extends NSObject {
  static eventStream<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  addPublisher(publisher: AVMetricEventStreamPublisher): boolean;

  setSubscriberQueue(subscriber: AVMetricEventStreamSubscriber, queue: NSObject | null): boolean;

  subscribeToMetricEvent(metricEventClass: interop.Object): void;

  subscribeToMetricEvents(metricEventClasses: NSArray<interop.Object> | Array<interop.Object>): void;

  subscribeToAllMetricEvents(): void;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableAudioMix extends AVAudioMix {
  static audioMix<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  // @ts-ignore MemberDecl.tsIgnore
  get inputParameters(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set inputParameters(value: NSArray<interop.Object> | Array<interop.Object>);

  setInputParameters(inputParameters: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVFrameRateRange extends NSObject {
  readonly minFrameRate: number;

  readonly maxFrameRate: number;

  readonly maxFrameDuration: CMTime;

  readonly minFrameDuration: CMTime;
}

declare class AVAssetWriterInputCaptionAdaptor extends NSObject {
  static assetWriterInputCaptionAdaptorWithAssetWriterInput<This extends abstract new (...args: any) => any>(this: This, input: AVAssetWriterInput): InstanceType<This>;

  initWithAssetWriterInput(input: AVAssetWriterInput): this;

  readonly assetWriterInput: AVAssetWriterInput;

  appendCaption(caption: AVCaption): boolean;

  appendCaptionGroup(captionGroup: AVCaptionGroup): boolean;
}

declare class AVAssetWriterInputMetadataAdaptor extends NSObject {
  static assetWriterInputMetadataAdaptorWithAssetWriterInput<This extends abstract new (...args: any) => any>(this: This, input: AVAssetWriterInput): InstanceType<This>;

  initWithAssetWriterInput(input: AVAssetWriterInput): this;

  readonly assetWriterInput: AVAssetWriterInput;

  appendTimedMetadataGroup(timedMetadataGroup: AVTimedMetadataGroup): boolean;
}

declare class AVAssetWriterInputPixelBufferAdaptor extends NSObject {
  static assetWriterInputPixelBufferAdaptorWithAssetWriterInputSourcePixelBufferAttributes<This extends abstract new (...args: any) => any>(this: This, input: AVAssetWriterInput, sourcePixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithAssetWriterInputSourcePixelBufferAttributes(input: AVAssetWriterInput, sourcePixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly assetWriterInput: AVAssetWriterInput;

  readonly sourcePixelBufferAttributes: NSDictionary;

  readonly pixelBufferPool: interop.Object;

  appendPixelBufferWithPresentationTime(pixelBuffer: interop.Object, presentationTime: CMTime): boolean;
}

declare class AVAssetWriterInputPassDescription extends NSObject {
  readonly sourceTimeRanges: NSArray;
}

declare class AVAssetWriterInput extends NSObject {
  static assetWriterInputWithMediaTypeOutputSettings<This extends abstract new (...args: any) => any>(this: This, mediaType: string, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static assetWriterInputWithMediaTypeOutputSettingsSourceFormatHint<This extends abstract new (...args: any) => any>(this: This, mediaType: string, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, sourceFormatHint: interop.Object | null): InstanceType<This>;

  initWithMediaTypeOutputSettings(mediaType: string, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  initWithMediaTypeOutputSettingsSourceFormatHint(mediaType: string, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, sourceFormatHint: interop.Object | null): this;

  readonly mediaType: string;

  readonly outputSettings: NSDictionary;

  readonly sourceFormatHint: interop.Object;

  get metadata(): NSArray;
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly readyForMoreMediaData: boolean;

  expectsMediaDataInRealTime: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  appendSampleBuffer(sampleBuffer: interop.Object): boolean;

  markAsFinished(): void;

  setMetadata(metadata: NSArray<interop.Object> | Array<interop.Object>): void;

  isReadyForMoreMediaData(): boolean;

  setExpectsMediaDataInRealTime(expectsMediaDataInRealTime: boolean): void;

  languageCode: string;

  extendedLanguageTag: string;

  setLanguageCode(languageCode: string): void;

  setExtendedLanguageTag(extendedLanguageTag: string): void;

  naturalSize: CGSize;

  transform: CGAffineTransform;

  setNaturalSize(naturalSize: CGSize): void;

  setTransform(transform: CGAffineTransform): void;

  preferredVolume: number;

  setPreferredVolume(preferredVolume: number): void;

  marksOutputTrackAsEnabled: boolean;

  mediaTimeScale: number;

  preferredMediaChunkDuration: CMTime;

  preferredMediaChunkAlignment: number;

  sampleReferenceBaseURL: NSURL;

  mediaDataLocation: string;

  setMarksOutputTrackAsEnabled(marksOutputTrackAsEnabled: boolean): void;

  setMediaTimeScale(mediaTimeScale: number): void;

  setPreferredMediaChunkDuration(preferredMediaChunkDuration: CMTime): void;

  setPreferredMediaChunkAlignment(preferredMediaChunkAlignment: number): void;

  setSampleReferenceBaseURL(sampleReferenceBaseURL: NSURL): void;

  setMediaDataLocation(mediaDataLocation: string): void;

  canAddTrackAssociationWithTrackOfInputType(input: AVAssetWriterInput, trackAssociationType: string): boolean;

  addTrackAssociationWithTrackOfInputType(input: AVAssetWriterInput, trackAssociationType: string): void;

  performsMultiPassEncodingIfSupported: boolean;

  readonly canPerformMultiplePasses: boolean;

  readonly currentPassDescription: AVAssetWriterInputPassDescription;

  respondToEachPassDescriptionOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  markCurrentPassAsFinished(): void;

  setPerformsMultiPassEncodingIfSupported(performsMultiPassEncodingIfSupported: boolean): void;
}

declare class AVAssetSegmentReportSampleInformation extends NSObject {
  readonly presentationTimeStamp: CMTime;

  readonly offset: number;

  readonly length: number;

  readonly isSyncSample: boolean;
}

declare class AVAssetSegmentReport extends NSObject {
  readonly segmentType: interop.Enum<typeof AVAssetSegmentType>;

  readonly trackReports: NSArray;
}

declare class AVMediaPresentationSelector extends NSObject implements NSCopying {
  readonly identifier: string;

  displayNameForLocaleIdentifier(localeIdentifier: string): string;

  readonly settings: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAudioMix extends NSObject implements NSCopying, NSMutableCopying {
  readonly inputParameters: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCustomMediaSelectionScheme extends NSObject implements NSCopying {
  readonly shouldOfferLanguageSelection: boolean;

  readonly availableLanguages: NSArray;

  readonly selectors: NSArray;

  mediaPresentationSettingsForSelectorComplementaryToLanguageSettings(selector: AVMediaPresentationSelector, language: string | null, settings: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVPlayerPlaybackCoordinator extends AVPlaybackCoordinator {
  readonly player: AVPlayer | null;

  delegate: AVPlayerPlaybackCoordinatorDelegate | null;

  setDelegate(delegate: AVPlayerPlaybackCoordinatorDelegate | null): void;

  coordinateUsingCoordinationMediumError(coordinationMedium: AVPlaybackCoordinationMedium | null, outError: interop.PointerConvertible): boolean;

  readonly playbackCoordinationMedium: AVPlaybackCoordinationMedium;
}

declare class AVMediaSelectionGroup extends NSObject implements NSCopying {
  readonly options: NSArray;

  readonly defaultOption: AVMediaSelectionOption;

  readonly allowsEmptySelection: boolean;

  mediaSelectionOptionWithPropertyList(plist: interop.Object): AVMediaSelectionOption;

  static playableMediaSelectionOptionsFromArray(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  static mediaSelectionOptionsFromArrayFilteredAndSortedAccordingToPreferredLanguages(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>, preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  static mediaSelectionOptionsFromArrayWithLocale(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>, locale: NSLocale): NSArray;

  static mediaSelectionOptionsFromArrayWithMediaCharacteristics(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>, mediaCharacteristics: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  static mediaSelectionOptionsFromArrayWithoutMediaCharacteristics(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>, mediaCharacteristics: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  readonly customMediaSelectionScheme: AVCustomMediaSelectionScheme;

  makeNowPlayingInfoLanguageOptionGroup(): MPNowPlayingInfoLanguageOptionGroup;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptionFormatConformer extends NSObject {
  static captionFormatConformerWithConversionSettings<This extends abstract new (...args: any) => any>(this: This, conversionSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): InstanceType<This>;

  initWithConversionSettings(conversionSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  conformsCaptionsToTimeRange: boolean;

  conformedCaptionForCaptionError(caption: AVCaption, outError: interop.PointerConvertible): AVCaption;

  setConformsCaptionsToTimeRange(conformsCaptionsToTimeRange: boolean): void;
}

declare class AVAssetTrackGroup extends NSObject implements NSCopying {
  readonly trackIDs: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetTrackSegment extends NSObject {
  readonly timeMapping: CMTimeMapping;

  readonly empty: boolean;

  isEmpty(): boolean;
}

declare class AVURLAsset extends AVAsset {
  static audiovisualTypes(): NSArray;

  static audiovisualMIMETypes(): NSArray;

  static readonly audiovisualContentTypes: NSArray;

  static isPlayableExtendedMIMEType(extendedMIMEType: string): boolean;

  static URLAssetWithURLOptions<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithURLOptions(URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly URL: NSURL;

  readonly httpSessionIdentifier: NSUUID;

  readonly resourceLoader: AVAssetResourceLoader;

  readonly assetCache: AVAssetCache;

  compatibleTrackForCompositionTrack(compositionTrack: AVCompositionTrack): AVAssetTrack;

  findCompatibleTrackForCompositionTrackCompletionHandler(compositionTrack: AVCompositionTrack, completionHandler: (p1: AVAssetTrack, p2: NSError) => void | null): void;

  readonly variants: NSArray;

  readonly mayRequireContentKeysForMediaDataProcessing: boolean;
}

declare class AVAssetReaderVideoCompositionOutput extends AVAssetReaderOutput {
  static assetReaderVideoCompositionOutputWithVideoTracksVideoSettings<This extends abstract new (...args: any) => any>(this: This, videoTracks: NSArray<interop.Object> | Array<interop.Object>, videoSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithVideoTracksVideoSettings(videoTracks: NSArray<interop.Object> | Array<interop.Object>, videoSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly videoTracks: NSArray;

  readonly videoSettings: NSDictionary;

  videoComposition: AVVideoComposition;

  readonly customVideoCompositor: AVVideoCompositing;

  setVideoComposition(videoComposition: AVVideoComposition | null): void;
}

declare class AVAssetReaderOutput extends NSObject {
  readonly mediaType: string;

  alwaysCopiesSampleData: boolean;

  copyNextSampleBuffer(): interop.Object;

  setAlwaysCopiesSampleData(alwaysCopiesSampleData: boolean): void;

  supportsRandomAccess: boolean;

  resetForReadingTimeRanges(timeRanges: NSArray<interop.Object> | Array<interop.Object>): void;

  markConfigurationAsFinal(): void;

  setSupportsRandomAccess(supportsRandomAccess: boolean): void;
}

declare class AVVideoCompositionCoreAnimationTool extends NSObject {
  static videoCompositionCoreAnimationToolWithAdditionalLayerAsTrackID<This extends abstract new (...args: any) => any>(this: This, layer: CALayer, trackID: number): InstanceType<This>;

  static videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayerInLayer<This extends abstract new (...args: any) => any>(this: This, videoLayer: CALayer, animationLayer: CALayer): InstanceType<This>;

  static videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayersInLayer<This extends abstract new (...args: any) => any>(this: This, videoLayers: NSArray<interop.Object> | Array<interop.Object>, animationLayer: CALayer): InstanceType<This>;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableVideoCompositionLayerInstruction extends AVVideoCompositionLayerInstruction {
  static videoCompositionLayerInstructionWithAssetTrack<This extends abstract new (...args: any) => any>(this: This, track: AVAssetTrack): InstanceType<This>;

  static videoCompositionLayerInstruction<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  // @ts-ignore MemberDecl.tsIgnore
  trackID: number;

  setTransformRampFromStartTransformToEndTransformTimeRange(startTransform: CGAffineTransform, endTransform: CGAffineTransform, timeRange: CMTimeRange): void;

  setTransformAtTime(transform: CGAffineTransform, time: CMTime): void;

  setOpacityRampFromStartOpacityToEndOpacityTimeRange(startOpacity: number, endOpacity: number, timeRange: CMTimeRange): void;

  setOpacityAtTime(opacity: number, time: CMTime): void;

  setCropRectangleRampFromStartCropRectangleToEndCropRectangleTimeRange(startCropRectangle: CGRect, endCropRectangle: CGRect, timeRange: CMTimeRange): void;

  setCropRectangleAtTime(cropRectangle: CGRect, time: CMTime): void;

  setTrackID(trackID: number): void;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableVideoCompositionInstruction extends AVVideoCompositionInstruction {
  static videoCompositionInstruction<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  // @ts-ignore MemberDecl.tsIgnore
  timeRange: CMTimeRange;

  // @ts-ignore MemberDecl.tsIgnore
  backgroundColor: interop.Object;

  // @ts-ignore MemberDecl.tsIgnore
  get layerInstructions(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set layerInstructions(value: NSArray<interop.Object> | Array<interop.Object>);

  // @ts-ignore MemberDecl.tsIgnore
  enablePostProcessing: boolean;

  // @ts-ignore MemberDecl.tsIgnore
  get requiredSourceSampleDataTrackIDs(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set requiredSourceSampleDataTrackIDs(value: NSArray<interop.Object> | Array<interop.Object>);

  setTimeRange(timeRange: CMTimeRange): void;

  setBackgroundColor(backgroundColor: interop.Object | null): void;

  setLayerInstructions(layerInstructions: NSArray<interop.Object> | Array<interop.Object>): void;

  setEnablePostProcessing(enablePostProcessing: boolean): void;

  setRequiredSourceSampleDataTrackIDs(requiredSourceSampleDataTrackIDs: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVVideoCompositionInstruction extends NSObject implements NSSecureCoding, NSCopying, NSMutableCopying, AVVideoCompositionInstructionProtocol {
  readonly timeRange: CMTimeRange;

  readonly backgroundColor: interop.Object;

  readonly layerInstructions: NSArray;

  readonly enablePostProcessing: boolean;

  readonly requiredSourceTrackIDs: NSArray;

  readonly passthroughTrackID: number;

  readonly requiredSourceSampleDataTrackIDs: NSArray;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;

  readonly containsTweening: boolean;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableVideoComposition extends AVVideoComposition {
  static videoComposition(): AVMutableVideoComposition;

  // @ts-ignore MemberDecl.tsIgnore
  static videoCompositionWithPropertiesOfAsset(asset: AVAsset): AVMutableVideoComposition;

  // @ts-ignore MemberDecl.tsIgnore
  static videoCompositionWithPropertiesOfAssetCompletionHandler(asset: AVAsset, completionHandler: (p1: AVMutableVideoComposition, p2: NSError) => void | null): void;

  static videoCompositionWithPropertiesOfAssetPrototypeInstruction(asset: AVAsset, prototypeInstruction: AVVideoCompositionInstruction): AVMutableVideoComposition;

  static videoCompositionWithPropertiesOfAssetPrototypeInstructionCompletionHandler(asset: AVAsset, prototypeInstruction: AVVideoCompositionInstruction, completionHandler: (p1: AVMutableVideoComposition, p2: NSError) => void | null): void;

  // @ts-ignore MemberDecl.tsIgnore
  customVideoCompositorClass: AVVideoCompositing;

  // @ts-ignore MemberDecl.tsIgnore
  frameDuration: CMTime;

  // @ts-ignore MemberDecl.tsIgnore
  sourceTrackIDForFrameTiming: number;

  // @ts-ignore MemberDecl.tsIgnore
  renderSize: CGSize;

  // @ts-ignore MemberDecl.tsIgnore
  renderScale: number;

  // @ts-ignore MemberDecl.tsIgnore
  get instructions(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set instructions(value: NSArray<interop.Object> | Array<interop.Object>);

  // @ts-ignore MemberDecl.tsIgnore
  animationTool: AVVideoCompositionCoreAnimationTool;

  // @ts-ignore MemberDecl.tsIgnore
  get sourceSampleDataTrackIDs(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set sourceSampleDataTrackIDs(value: NSArray<interop.Object> | Array<interop.Object>);

  // @ts-ignore MemberDecl.tsIgnore
  get outputBufferDescription(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set outputBufferDescription(value: NSArray<interop.Object> | Array<interop.Object>);

  setCustomVideoCompositorClass(customVideoCompositorClass: AVVideoCompositing): void;

  setFrameDuration(frameDuration: CMTime): void;

  setSourceTrackIDForFrameTiming(sourceTrackIDForFrameTiming: number): void;

  setRenderSize(renderSize: CGSize): void;

  setRenderScale(renderScale: number): void;

  setInstructions(instructions: NSArray<interop.Object> | Array<interop.Object>): void;

  setAnimationTool(animationTool: AVVideoCompositionCoreAnimationTool | null): void;

  setSourceSampleDataTrackIDs(sourceSampleDataTrackIDs: NSArray<interop.Object> | Array<interop.Object>): void;

  setOutputBufferDescription(outputBufferDescription: NSArray<interop.Object> | Array<interop.Object>): void;

  // @ts-ignore MemberDecl.tsIgnore
  colorPrimaries: string;

  // @ts-ignore MemberDecl.tsIgnore
  colorYCbCrMatrix: string;

  // @ts-ignore MemberDecl.tsIgnore
  colorTransferFunction: string;

  // @ts-ignore MemberDecl.tsIgnore
  perFrameHDRDisplayMetadataPolicy: string;

  setColorPrimaries(colorPrimaries: string): void;

  setColorYCbCrMatrix(colorYCbCrMatrix: string): void;

  setColorTransferFunction(colorTransferFunction: string): void;

  setPerFrameHDRDisplayMetadataPolicy(perFrameHDRDisplayMetadataPolicy: string): void;

  // @ts-ignore MemberDecl.tsIgnore
  static videoCompositionWithAssetApplyingCIFiltersWithHandler(asset: AVAsset, applier: (p1: AVAsynchronousCIImageFilteringRequest) => void): AVMutableVideoComposition;

  // @ts-ignore MemberDecl.tsIgnore
  static videoCompositionWithAssetApplyingCIFiltersWithHandlerCompletionHandler(asset: AVAsset, applier: (p1: AVAsynchronousCIImageFilteringRequest) => void, completionHandler: (p1: AVMutableVideoComposition, p2: NSError) => void | null): void;
}

declare class AVVideoComposition extends NSObject implements NSCopying, NSMutableCopying {
  static videoCompositionWithPropertiesOfAsset(asset: AVAsset): AVVideoComposition;

  static videoCompositionWithPropertiesOfAssetCompletionHandler(asset: AVAsset, completionHandler: (p1: AVVideoComposition, p2: NSError) => void | null): void;

  readonly customVideoCompositorClass: AVVideoCompositing;

  readonly frameDuration: CMTime;

  readonly sourceTrackIDForFrameTiming: number;

  readonly renderSize: CGSize;

  readonly renderScale: number;

  readonly instructions: NSArray;

  readonly animationTool: AVVideoCompositionCoreAnimationTool;

  readonly sourceSampleDataTrackIDs: NSArray;

  readonly outputBufferDescription: NSArray;

  readonly spatialVideoConfigurations: NSArray;

  readonly colorPrimaries: string;

  readonly colorYCbCrMatrix: string;

  readonly colorTransferFunction: string;

  readonly perFrameHDRDisplayMetadataPolicy: string;

  static videoCompositionWithAssetApplyingCIFiltersWithHandler(asset: AVAsset, applier: (p1: AVAsynchronousCIImageFilteringRequest) => void): AVVideoComposition;

  static videoCompositionWithAssetApplyingCIFiltersWithHandlerCompletionHandler(asset: AVAsset, applier: (p1: AVAsynchronousCIImageFilteringRequest) => void, completionHandler: (p1: AVVideoComposition, p2: NSError) => void | null): void;

  isValidForAssetTimeRangeValidationDelegate(asset: AVAsset | null, timeRange: CMTimeRange, validationDelegate: AVVideoCompositionValidationHandling | null): boolean;

  determineValidityForAssetTimeRangeValidationDelegateCompletionHandler(asset: AVAsset | null, timeRange: CMTimeRange, validationDelegate: AVVideoCompositionValidationHandling | null, completionHandler: (p1: boolean, p2: NSError) => void | null): void;

  isValidForTracksAssetDurationTimeRangeValidationDelegate(tracks: NSArray<interop.Object> | Array<interop.Object>, duration: CMTime, timeRange: CMTimeRange, validationDelegate: AVVideoCompositionValidationHandling | null): boolean;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAsynchronousCIImageFilteringRequest extends NSObject implements NSCopying {
  readonly renderSize: CGSize;

  readonly compositionTime: CMTime;

  readonly sourceImage: CIImage;

  finishWithImageContext(filteredImage: CIImage, context: CIContext | null): void;

  finishWithError(error: NSError): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVVideoCompositionRenderHint extends NSObject {
  readonly startCompositionTime: CMTime;

  readonly endCompositionTime: CMTime;
}

declare class AVDateRangeMetadataGroup extends AVMetadataGroup implements NSCopying, NSMutableCopying {
  initWithItemsStartDateEndDate(items: NSArray<interop.Object> | Array<interop.Object>, startDate: NSDate, endDate: NSDate | null): this;

  readonly startDate: NSDate;

  readonly endDate: NSDate;

  readonly items: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetCache extends NSObject {
  readonly playableOffline: boolean;

  mediaSelectionOptionsInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): NSArray;

  isPlayableOffline(): boolean;

  mediaPresentationSettingsForMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): NSDictionary;

  mediaPresentationLanguagesForMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): NSArray;
}

declare class AVFragmentedAssetMinder extends NSObject {
  static fragmentedAssetMinderWithAssetMindingInterval<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset, mindingInterval: number): InstanceType<This>;

  initWithAssetMindingInterval(asset: AVAsset, mindingInterval: number): this;

  mindingInterval: number;

  readonly assets: NSArray;

  addFragmentedAsset(asset: AVAsset): void;

  removeFragmentedAsset(asset: AVAsset): void;

  setMindingInterval(mindingInterval: number): void;
}

declare class AVAssetVariantAudioRenditionSpecificAttributes extends NSObject {
  readonly channelCount: number;

  readonly binaural: boolean;

  readonly immersive: boolean;

  readonly downmix: boolean;

  isBinaural(): boolean;

  isImmersive(): boolean;

  isDownmix(): boolean;
}

declare class AVContentKeySpecifier extends NSObject {
  static contentKeySpecifierForKeySystemIdentifierOptions<This extends abstract new (...args: any) => any>(this: This, keySystem: string, contentKeyIdentifier: interop.Object, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): InstanceType<This>;

  initForKeySystemIdentifierOptions(keySystem: string, contentKeyIdentifier: interop.Object, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  readonly keySystem: string;

  readonly identifier: interop.Object;

  readonly options: NSDictionary;
}

declare class AVContentKeyRequest extends NSObject {
  readonly status: interop.Enum<typeof AVContentKeyRequestStatus>;

  readonly error: NSError;

  readonly identifier: interop.Object;

  readonly initializationData: NSData;

  readonly options: NSDictionary;

  readonly canProvidePersistableContentKey: boolean;

  readonly contentKeySpecifier: AVContentKeySpecifier;

  readonly contentKey: AVContentKey;

  readonly originatingRecipient: AVContentKeyRecipient;

  makeStreamingContentKeyRequestDataForAppContentIdentifierOptionsCompletionHandler(appIdentifier: NSData, contentIdentifier: NSData | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, handler: (p1: NSData, p2: NSError) => void | null): void;

  processContentKeyResponse(keyResponse: AVContentKeyResponse): void;

  processContentKeyResponseError(error: NSError): void;

  respondByRequestingPersistableContentKeyRequest(): void;

  respondByRequestingPersistableContentKeyRequestAndReturnError(outError: interop.PointerConvertible): boolean;

  readonly renewsExpiringResponseData: boolean;
}

declare class AVMediaSelectionOption extends NSObject implements NSCopying {
  readonly mediaType: string;

  readonly mediaSubTypes: NSArray;

  hasMediaCharacteristic(mediaCharacteristic: string): boolean;

  readonly playable: boolean;

  readonly extendedLanguageTag: string;

  readonly locale: NSLocale;

  readonly commonMetadata: NSArray;

  readonly availableMetadataFormats: NSArray;

  metadataForFormat(format: string): NSArray;

  associatedMediaSelectionOptionInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): AVMediaSelectionOption;

  propertyList(): interop.Object;

  displayNameWithLocale(locale: NSLocale): string;

  readonly displayName: string;

  isPlayable(): boolean;

  makeNowPlayingInfoLanguageOption(): MPNowPlayingInfoLanguageOption;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableComposition extends AVComposition {
  readonly tracks: NSArray;

  // @ts-ignore MemberDecl.tsIgnore
  naturalSize: CGSize;

  static composition<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  static compositionWithURLAssetInitializationOptions<This extends abstract new (...args: any) => any>(this: This, URLAssetInitializationOptions: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  setNaturalSize(naturalSize: CGSize): void;

  insertTimeRangeOfAssetAtTimeError(timeRange: CMTimeRange, asset: AVAsset, startTime: CMTime, outError: interop.PointerConvertible): boolean;

  insertTimeRangeOfAssetAtTimeCompletionHandler(timeRange: CMTimeRange, asset: AVAsset, startTime: CMTime, completionHandler: (p1: NSError) => void | null): void;

  insertEmptyTimeRange(timeRange: CMTimeRange): void;

  removeTimeRange(timeRange: CMTimeRange): void;

  scaleTimeRangeToDuration(timeRange: CMTimeRange, duration: CMTime): void;

  addMutableTrackWithMediaTypePreferredTrackID(mediaType: string, preferredTrackID: number): AVMutableCompositionTrack;

  removeTrack(track: AVCompositionTrack): void;

  mutableTrackCompatibleWithTrack(track: AVAssetTrack): AVMutableCompositionTrack;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVMutableCompositionTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVMutableCompositionTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  addTracksForCinematicAssetInfoPreferredStartingTrackID(assetInfo: CNAssetInfo, preferredStartingTrackID: number): CNCompositionInfo;
}

declare class AVCapturePhotoSettings extends NSObject implements NSCopying {
  static photoSettings<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  static photoSettingsWithFormat<This extends abstract new (...args: any) => any>(this: This, format: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static photoSettingsWithRawPixelFormatType<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number): InstanceType<This>;

  static photoSettingsWithRawPixelFormatTypeProcessedFormat<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number, processedFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static photoSettingsWithRawPixelFormatTypeRawFileTypeProcessedFormatProcessedFileType<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number, rawFileType: string | null, processedFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, processedFileType: string | null): InstanceType<This>;

  static photoSettingsFromPhotoSettings<This extends abstract new (...args: any) => any>(this: This, photoSettings: AVCapturePhotoSettings): InstanceType<This>;

  readonly uniqueID: number;

  readonly format: NSDictionary;

  get rawFileFormat(): NSDictionary;
  set rawFileFormat(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  readonly processedFileType: string;

  readonly rawPhotoPixelFormatType: number;

  readonly rawFileType: string;

  flashMode: interop.Enum<typeof AVCaptureFlashMode>;

  autoRedEyeReductionEnabled: boolean;

  photoQualityPrioritization: interop.Enum<typeof AVCapturePhotoQualityPrioritization>;

  autoStillImageStabilizationEnabled: boolean;

  autoVirtualDeviceFusionEnabled: boolean;

  autoDualCameraFusionEnabled: boolean;

  get virtualDeviceConstituentPhotoDeliveryEnabledDevices(): NSArray;
  set virtualDeviceConstituentPhotoDeliveryEnabledDevices(value: NSArray<interop.Object> | Array<interop.Object>);

  dualCameraDualPhotoDeliveryEnabled: boolean;

  highResolutionPhotoEnabled: boolean;

  maxPhotoDimensions: CMVideoDimensions;

  depthDataDeliveryEnabled: boolean;

  embedsDepthDataInPhoto: boolean;

  depthDataFiltered: boolean;

  cameraCalibrationDataDeliveryEnabled: boolean;

  portraitEffectsMatteDeliveryEnabled: boolean;

  embedsPortraitEffectsMatteInPhoto: boolean;

  get enabledSemanticSegmentationMatteTypes(): NSArray;
  set enabledSemanticSegmentationMatteTypes(value: NSArray<interop.Object> | Array<interop.Object>);

  embedsSemanticSegmentationMattesInPhoto: boolean;

  get metadata(): NSDictionary;
  set metadata(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  livePhotoMovieFileURL: NSURL;

  livePhotoVideoCodecType: string;

  get livePhotoMovieMetadata(): NSArray;
  set livePhotoMovieMetadata(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly availablePreviewPhotoPixelFormatTypes: NSArray;

  get previewPhotoFormat(): NSDictionary;
  set previewPhotoFormat(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  readonly availableEmbeddedThumbnailPhotoCodecTypes: NSArray;

  get embeddedThumbnailPhotoFormat(): NSDictionary;
  set embeddedThumbnailPhotoFormat(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  readonly availableRawEmbeddedThumbnailPhotoCodecTypes: NSArray;

  get rawEmbeddedThumbnailPhotoFormat(): NSDictionary;
  set rawEmbeddedThumbnailPhotoFormat(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  autoContentAwareDistortionCorrectionEnabled: boolean;

  constantColorEnabled: boolean;

  constantColorFallbackPhotoDeliveryEnabled: boolean;

  shutterSoundSuppressionEnabled: boolean;

  setRawFileFormat(rawFileFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): void;

  setFlashMode(flashMode: interop.Enum<typeof AVCaptureFlashMode>): void;

  isAutoRedEyeReductionEnabled(): boolean;

  setAutoRedEyeReductionEnabled(autoRedEyeReductionEnabled: boolean): void;

  setPhotoQualityPrioritization(photoQualityPrioritization: interop.Enum<typeof AVCapturePhotoQualityPrioritization>): void;

  isAutoStillImageStabilizationEnabled(): boolean;

  setAutoStillImageStabilizationEnabled(autoStillImageStabilizationEnabled: boolean): void;

  isAutoVirtualDeviceFusionEnabled(): boolean;

  setAutoVirtualDeviceFusionEnabled(autoVirtualDeviceFusionEnabled: boolean): void;

  isAutoDualCameraFusionEnabled(): boolean;

  setAutoDualCameraFusionEnabled(autoDualCameraFusionEnabled: boolean): void;

  setVirtualDeviceConstituentPhotoDeliveryEnabledDevices(virtualDeviceConstituentPhotoDeliveryEnabledDevices: NSArray<interop.Object> | Array<interop.Object>): void;

  isDualCameraDualPhotoDeliveryEnabled(): boolean;

  setDualCameraDualPhotoDeliveryEnabled(dualCameraDualPhotoDeliveryEnabled: boolean): void;

  isHighResolutionPhotoEnabled(): boolean;

  setHighResolutionPhotoEnabled(highResolutionPhotoEnabled: boolean): void;

  setMaxPhotoDimensions(maxPhotoDimensions: CMVideoDimensions): void;

  isDepthDataDeliveryEnabled(): boolean;

  setDepthDataDeliveryEnabled(depthDataDeliveryEnabled: boolean): void;

  setEmbedsDepthDataInPhoto(embedsDepthDataInPhoto: boolean): void;

  isDepthDataFiltered(): boolean;

  setDepthDataFiltered(depthDataFiltered: boolean): void;

  isCameraCalibrationDataDeliveryEnabled(): boolean;

  setCameraCalibrationDataDeliveryEnabled(cameraCalibrationDataDeliveryEnabled: boolean): void;

  isPortraitEffectsMatteDeliveryEnabled(): boolean;

  setPortraitEffectsMatteDeliveryEnabled(portraitEffectsMatteDeliveryEnabled: boolean): void;

  setEmbedsPortraitEffectsMatteInPhoto(embedsPortraitEffectsMatteInPhoto: boolean): void;

  setEnabledSemanticSegmentationMatteTypes(enabledSemanticSegmentationMatteTypes: NSArray<interop.Object> | Array<interop.Object>): void;

  setEmbedsSemanticSegmentationMattesInPhoto(embedsSemanticSegmentationMattesInPhoto: boolean): void;

  setMetadata(metadata: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): void;

  setLivePhotoMovieFileURL(livePhotoMovieFileURL: NSURL): void;

  setLivePhotoVideoCodecType(livePhotoVideoCodecType: string): void;

  setLivePhotoMovieMetadata(livePhotoMovieMetadata: NSArray<interop.Object> | Array<interop.Object> | null): void;

  setPreviewPhotoFormat(previewPhotoFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): void;

  setEmbeddedThumbnailPhotoFormat(embeddedThumbnailPhotoFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): void;

  setRawEmbeddedThumbnailPhotoFormat(rawEmbeddedThumbnailPhotoFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): void;

  isAutoContentAwareDistortionCorrectionEnabled(): boolean;

  setAutoContentAwareDistortionCorrectionEnabled(autoContentAwareDistortionCorrectionEnabled: boolean): void;

  isConstantColorEnabled(): boolean;

  setConstantColorEnabled(constantColorEnabled: boolean): void;

  isConstantColorFallbackPhotoDeliveryEnabled(): boolean;

  setConstantColorFallbackPhotoDeliveryEnabled(constantColorFallbackPhotoDeliveryEnabled: boolean): void;

  isShutterSoundSuppressionEnabled(): boolean;

  setShutterSoundSuppressionEnabled(shutterSoundSuppressionEnabled: boolean): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVExternalStorageDeviceDiscoverySession extends NSObject {
  static readonly sharedSession: AVExternalStorageDeviceDiscoverySession;

  readonly externalStorageDevices: NSArray;

  static readonly supported: boolean;

  static isSupported(): boolean;
}

declare class AVSpatialVideoConfiguration extends NSObject {
  get cameraCalibrationDataLensCollection(): NSArray;
  set cameraCalibrationDataLensCollection(value: NSArray<interop.Object> | Array<interop.Object>);

  horizontalFieldOfView: NSNumber;

  cameraSystemBaseline: NSNumber;

  disparityAdjustment: NSNumber;

  init(): this;

  initWithFormatDescription(formatDescription: interop.Object): this;

  setCameraCalibrationDataLensCollection(cameraCalibrationDataLensCollection: NSArray<interop.Object> | Array<interop.Object> | null): void;

  setHorizontalFieldOfView(horizontalFieldOfView: NSNumber | null): void;

  setCameraSystemBaseline(cameraSystemBaseline: NSNumber | null): void;

  setDisparityAdjustment(disparityAdjustment: NSNumber | null): void;
}

declare class AVAssetTrack extends NSObject implements NSCopying, AVAsynchronousKeyValueLoading {
  readonly asset: AVAsset | null;

  readonly trackID: number;

  readonly mediaType: string;

  readonly formatDescriptions: NSArray;

  readonly playable: boolean;

  readonly decodable: boolean;

  readonly enabled: boolean;

  readonly selfContained: boolean;

  readonly totalSampleDataLength: number;

  hasMediaCharacteristic(mediaCharacteristic: string): boolean;

  isPlayable(): boolean;

  isDecodable(): boolean;

  isEnabled(): boolean;

  isSelfContained(): boolean;

  readonly timeRange: CMTimeRange;

  readonly naturalTimeScale: number;

  readonly estimatedDataRate: number;

  readonly languageCode: string;

  readonly extendedLanguageTag: string;

  readonly naturalSize: CGSize;

  readonly preferredTransform: CGAffineTransform;

  readonly preferredVolume: number;

  readonly hasAudioSampleDependencies: boolean;

  readonly nominalFrameRate: number;

  readonly minFrameDuration: CMTime;

  readonly requiresFrameReordering: boolean;

  readonly segments: NSArray;

  segmentForTrackTime(trackTime: CMTime): AVAssetTrackSegment;

  loadSegmentForTrackTimeCompletionHandler(trackTime: CMTime, completionHandler: (p1: AVAssetTrackSegment, p2: NSError) => void | null): void;

  samplePresentationTimeForTrackTime(trackTime: CMTime): CMTime;

  loadSamplePresentationTimeForTrackTimeCompletionHandler(trackTime: CMTime, completionHandler: (p1: CMTime, p2: NSError) => void | null): void;

  readonly commonMetadata: NSArray;

  readonly metadata: NSArray;

  readonly availableMetadataFormats: NSArray;

  metadataForFormat(format: string): NSArray;

  loadMetadataForFormatCompletionHandler(format: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly availableTrackAssociationTypes: NSArray;

  associatedTracksOfType(trackAssociationType: string): NSArray;

  loadAssociatedTracksOfTypeCompletionHandler(trackAssociationType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly canProvideSampleCursors: boolean;

  makeSampleCursorWithPresentationTimeStamp(presentationTimeStamp: CMTime): AVSampleCursor;

  makeSampleCursorAtFirstSampleInDecodeOrder(): AVSampleCursor;

  makeSampleCursorAtLastSampleInDecodeOrder(): AVSampleCursor;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  statusOfValueForKeyError(key: string, outError: interop.PointerConvertible): interop.Enum<typeof AVKeyValueStatus>;

  loadValuesAsynchronouslyForKeysCompletionHandler(keys: NSArray<interop.Object> | Array<interop.Object>, handler: () => void | null): void;
}

declare class AVSemanticSegmentationMatte extends NSObject {
  static semanticSegmentationMatteFromImageSourceAuxiliaryDataTypeDictionaryRepresentationError<This extends abstract new (...args: any) => any>(this: This, imageSourceAuxiliaryDataType: interop.Object, imageSourceAuxiliaryDataInfoDictionary: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, outError: interop.PointerConvertible): InstanceType<This>;

  readonly matteType: string;

  semanticSegmentationMatteByApplyingExifOrientation(exifOrientation: interop.Enum<typeof CGImagePropertyOrientation>): this;

  semanticSegmentationMatteByReplacingSemanticSegmentationMatteWithPixelBufferError(pixelBuffer: interop.Object, outError: interop.PointerConvertible): this;

  dictionaryRepresentationForAuxiliaryDataType(outAuxDataType: interop.PointerConvertible): NSDictionary;

  readonly pixelFormatType: number;

  readonly mattingImage: interop.Object;
}

declare class AVAssetReaderTrackOutput extends AVAssetReaderOutput {
  static assetReaderTrackOutputWithTrackOutputSettings<This extends abstract new (...args: any) => any>(this: This, track: AVAssetTrack, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithTrackOutputSettings(track: AVAssetTrack, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly track: AVAssetTrack;

  readonly outputSettings: NSDictionary;

  audioTimePitchAlgorithm: string;

  setAudioTimePitchAlgorithm(audioTimePitchAlgorithm: string): void;
}

declare class AVPlayerItemErrorLogEvent extends NSObject implements NSCopying {
  readonly date: NSDate;

  readonly URI: string;

  readonly serverAddress: string;

  readonly playbackSessionID: string;

  readonly errorStatusCode: number;

  readonly errorDomain: string;

  readonly errorComment: string;

  readonly allHTTPResponseHeaderFields: NSDictionary;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCapturePhotoOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  capturePhotoWithSettingsDelegate(settings: AVCapturePhotoSettings, delegate: AVCapturePhotoCaptureDelegate): void;

  readonly preparedPhotoSettingsArray: NSArray;

  setPreparedPhotoSettingsArrayCompletionHandler(preparedPhotoSettingsArray: NSArray<interop.Object> | Array<interop.Object>, completionHandler: (p1: boolean, p2: NSError) => void | null): void;

  readonly availablePhotoPixelFormatTypes: NSArray;

  readonly availablePhotoCodecTypes: NSArray;

  readonly availableRawPhotoCodecTypes: NSArray;

  readonly appleProRAWSupported: boolean;

  appleProRAWEnabled: boolean;

  static isBayerRAWPixelFormat(pixelFormat: number): boolean;

  static isAppleProRAWPixelFormat(pixelFormat: number): boolean;

  readonly availableRawPhotoPixelFormatTypes: NSArray;

  readonly availablePhotoFileTypes: NSArray;

  readonly availableRawPhotoFileTypes: NSArray;

  supportedPhotoPixelFormatTypesForFileType(fileType: string): NSArray;

  supportedPhotoCodecTypesForFileType(fileType: string): NSArray;

  supportedRawPhotoCodecTypesForRawPhotoPixelFormatTypeFileType(pixelFormatType: number, fileType: string): NSArray;

  supportedRawPhotoPixelFormatTypesForFileType(fileType: string): NSArray;

  maxPhotoQualityPrioritization: interop.Enum<typeof AVCapturePhotoQualityPrioritization>;

  fastCapturePrioritizationSupported: boolean;

  fastCapturePrioritizationEnabled: boolean;

  readonly autoDeferredPhotoDeliverySupported: boolean;

  autoDeferredPhotoDeliveryEnabled: boolean;

  readonly stillImageStabilizationSupported: boolean;

  readonly isStillImageStabilizationScene: boolean;

  readonly virtualDeviceFusionSupported: boolean;

  readonly dualCameraFusionSupported: boolean;

  readonly virtualDeviceConstituentPhotoDeliverySupported: boolean;

  readonly dualCameraDualPhotoDeliverySupported: boolean;

  virtualDeviceConstituentPhotoDeliveryEnabled: boolean;

  dualCameraDualPhotoDeliveryEnabled: boolean;

  readonly cameraCalibrationDataDeliverySupported: boolean;

  readonly supportedFlashModes: NSArray;

  readonly autoRedEyeReductionSupported: boolean;

  readonly isFlashScene: boolean;

  photoSettingsForSceneMonitoring: AVCapturePhotoSettings;

  highResolutionCaptureEnabled: boolean;

  maxPhotoDimensions: CMVideoDimensions;

  readonly maxBracketedCapturePhotoCount: number;

  readonly lensStabilizationDuringBracketedCaptureSupported: boolean;

  readonly livePhotoCaptureSupported: boolean;

  livePhotoCaptureEnabled: boolean;

  livePhotoCaptureSuspended: boolean;

  preservesLivePhotoCaptureSuspendedOnSessionStop: boolean;

  livePhotoAutoTrimmingEnabled: boolean;

  readonly availableLivePhotoVideoCodecTypes: NSArray;

  static JPEGPhotoDataRepresentationForJPEGSampleBufferPreviewPhotoSampleBuffer(JPEGSampleBuffer: interop.Object, previewPhotoSampleBuffer: interop.Object | null): NSData;

  static DNGPhotoDataRepresentationForRawSampleBufferPreviewPhotoSampleBuffer(rawSampleBuffer: interop.Object, previewPhotoSampleBuffer: interop.Object | null): NSData;

  readonly contentAwareDistortionCorrectionSupported: boolean;

  contentAwareDistortionCorrectionEnabled: boolean;

  readonly zeroShutterLagSupported: boolean;

  zeroShutterLagEnabled: boolean;

  readonly responsiveCaptureSupported: boolean;

  responsiveCaptureEnabled: boolean;

  readonly captureReadiness: interop.Enum<typeof AVCapturePhotoOutputCaptureReadiness>;

  readonly constantColorSupported: boolean;

  constantColorEnabled: boolean;

  readonly shutterSoundSuppressionSupported: boolean;

  readonly cameraSensorOrientationCompensationSupported: boolean;

  cameraSensorOrientationCompensationEnabled: boolean;

  isAppleProRAWSupported(): boolean;

  isAppleProRAWEnabled(): boolean;

  setAppleProRAWEnabled(appleProRAWEnabled: boolean): void;

  setMaxPhotoQualityPrioritization(maxPhotoQualityPrioritization: interop.Enum<typeof AVCapturePhotoQualityPrioritization>): void;

  isFastCapturePrioritizationSupported(): boolean;

  setFastCapturePrioritizationSupported(fastCapturePrioritizationSupported: boolean): void;

  isFastCapturePrioritizationEnabled(): boolean;

  setFastCapturePrioritizationEnabled(fastCapturePrioritizationEnabled: boolean): void;

  isAutoDeferredPhotoDeliverySupported(): boolean;

  isAutoDeferredPhotoDeliveryEnabled(): boolean;

  setAutoDeferredPhotoDeliveryEnabled(autoDeferredPhotoDeliveryEnabled: boolean): void;

  isStillImageStabilizationSupported(): boolean;

  isVirtualDeviceFusionSupported(): boolean;

  isDualCameraFusionSupported(): boolean;

  isVirtualDeviceConstituentPhotoDeliverySupported(): boolean;

  isDualCameraDualPhotoDeliverySupported(): boolean;

  isVirtualDeviceConstituentPhotoDeliveryEnabled(): boolean;

  setVirtualDeviceConstituentPhotoDeliveryEnabled(virtualDeviceConstituentPhotoDeliveryEnabled: boolean): void;

  isDualCameraDualPhotoDeliveryEnabled(): boolean;

  setDualCameraDualPhotoDeliveryEnabled(dualCameraDualPhotoDeliveryEnabled: boolean): void;

  isCameraCalibrationDataDeliverySupported(): boolean;

  isAutoRedEyeReductionSupported(): boolean;

  setPhotoSettingsForSceneMonitoring(photoSettingsForSceneMonitoring: AVCapturePhotoSettings): void;

  isHighResolutionCaptureEnabled(): boolean;

  setHighResolutionCaptureEnabled(highResolutionCaptureEnabled: boolean): void;

  setMaxPhotoDimensions(maxPhotoDimensions: CMVideoDimensions): void;

  isLensStabilizationDuringBracketedCaptureSupported(): boolean;

  isLivePhotoCaptureSupported(): boolean;

  isLivePhotoCaptureEnabled(): boolean;

  setLivePhotoCaptureEnabled(livePhotoCaptureEnabled: boolean): void;

  isLivePhotoCaptureSuspended(): boolean;

  setLivePhotoCaptureSuspended(livePhotoCaptureSuspended: boolean): void;

  setPreservesLivePhotoCaptureSuspendedOnSessionStop(preservesLivePhotoCaptureSuspendedOnSessionStop: boolean): void;

  isLivePhotoAutoTrimmingEnabled(): boolean;

  setLivePhotoAutoTrimmingEnabled(livePhotoAutoTrimmingEnabled: boolean): void;

  isContentAwareDistortionCorrectionSupported(): boolean;

  isContentAwareDistortionCorrectionEnabled(): boolean;

  setContentAwareDistortionCorrectionEnabled(contentAwareDistortionCorrectionEnabled: boolean): void;

  isZeroShutterLagSupported(): boolean;

  isZeroShutterLagEnabled(): boolean;

  setZeroShutterLagEnabled(zeroShutterLagEnabled: boolean): void;

  isResponsiveCaptureSupported(): boolean;

  isResponsiveCaptureEnabled(): boolean;

  setResponsiveCaptureEnabled(responsiveCaptureEnabled: boolean): void;

  isConstantColorSupported(): boolean;

  isConstantColorEnabled(): boolean;

  setConstantColorEnabled(constantColorEnabled: boolean): void;

  isShutterSoundSuppressionSupported(): boolean;

  isCameraSensorOrientationCompensationSupported(): boolean;

  isCameraSensorOrientationCompensationEnabled(): boolean;

  setCameraSensorOrientationCompensationEnabled(cameraSensorOrientationCompensationEnabled: boolean): void;

  readonly depthDataDeliverySupported: boolean;

  depthDataDeliveryEnabled: boolean;

  readonly portraitEffectsMatteDeliverySupported: boolean;

  portraitEffectsMatteDeliveryEnabled: boolean;

  readonly availableSemanticSegmentationMatteTypes: NSArray;

  get enabledSemanticSegmentationMatteTypes(): NSArray;
  set enabledSemanticSegmentationMatteTypes(value: NSArray<interop.Object> | Array<interop.Object>);

  isDepthDataDeliverySupported(): boolean;

  isDepthDataDeliveryEnabled(): boolean;

  setDepthDataDeliveryEnabled(depthDataDeliveryEnabled: boolean): void;

  isPortraitEffectsMatteDeliverySupported(): boolean;

  isPortraitEffectsMatteDeliveryEnabled(): boolean;

  setPortraitEffectsMatteDeliveryEnabled(portraitEffectsMatteDeliveryEnabled: boolean): void;

  setEnabledSemanticSegmentationMatteTypes(enabledSemanticSegmentationMatteTypes: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVCaptureDeviceDiscoverySession extends NSObject {
  static discoverySessionWithDeviceTypesMediaTypePosition<This extends abstract new (...args: any) => any>(this: This, deviceTypes: NSArray<interop.Object> | Array<interop.Object>, mediaType: string | null, position: interop.Enum<typeof AVCaptureDevicePosition>): InstanceType<This>;

  readonly devices: NSArray;

  readonly supportedMultiCamDeviceSets: NSArray;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableCaption extends AVCaption {
  // @ts-ignore MemberDecl.tsIgnore
  text: string;

  // @ts-ignore MemberDecl.tsIgnore
  timeRange: CMTimeRange;

  setText(text: string): void;

  setTimeRange(timeRange: CMTimeRange): void;

  setTextColorInRange(color: interop.Object, range: _NSRange): void;

  setBackgroundColorInRange(color: interop.Object, range: _NSRange): void;

  setFontWeightInRange(fontWeight: interop.Enum<typeof AVCaptionFontWeight>, range: _NSRange): void;

  setFontStyleInRange(fontStyle: interop.Enum<typeof AVCaptionFontStyle>, range: _NSRange): void;

  setDecorationInRange(decoration: interop.Enum<typeof AVCaptionDecoration>, range: _NSRange): void;

  setTextCombineInRange(textCombine: interop.Enum<typeof AVCaptionTextCombine>, range: _NSRange): void;

  setRubyInRange(ruby: AVCaptionRuby, range: _NSRange): void;

  removeTextColorInRange(range: _NSRange): void;

  removeBackgroundColorInRange(range: _NSRange): void;

  removeFontWeightInRange(range: _NSRange): void;

  removeFontStyleInRange(range: _NSRange): void;

  removeDecorationInRange(range: _NSRange): void;

  removeTextCombineInRange(range: _NSRange): void;

  removeRubyInRange(range: _NSRange): void;

  // @ts-ignore MemberDecl.tsIgnore
  region: AVCaptionRegion;

  // @ts-ignore MemberDecl.tsIgnore
  textAlignment: interop.Enum<typeof AVCaptionTextAlignment>;

  setRegion(region: AVCaptionRegion): void;

  setTextAlignment(textAlignment: interop.Enum<typeof AVCaptionTextAlignment>): void;

  // @ts-ignore MemberDecl.tsIgnore
  animation: interop.Enum<typeof AVCaptionAnimation>;

  setAnimation(animation: interop.Enum<typeof AVCaptionAnimation>): void;
}

declare class AVMetadataHumanFullBodyObject extends AVMetadataBodyObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataHumanBodyObject extends AVMetadataBodyObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptureAutoExposureBracketedStillImageSettings extends AVCaptureBracketedStillImageSettings {
  static autoExposureSettingsWithExposureTargetBias<This extends abstract new (...args: any) => any>(this: This, exposureTargetBias: number): InstanceType<This>;

  readonly exposureTargetBias: number;
}

declare class AVMetricMediaRendition extends NSObject implements NSSecureCoding {
  readonly stableID: string;

  readonly URL: NSURL;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVPlayerItemSegment extends NSObject {
  readonly segmentType: interop.Enum<typeof AVPlayerItemSegmentType>;

  readonly timeMapping: CMTimeMapping;

  readonly loadedTimeRanges: NSArray;

  readonly startDate: NSDate;

  readonly interstitialEvent: AVPlayerInterstitialEvent;
}

declare class AVCapturePhotoBracketSettings extends AVCapturePhotoSettings {
  static photoBracketSettingsWithRawPixelFormatTypeProcessedFormatBracketedSettings<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number, processedFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, bracketedSettings: NSArray<interop.Object> | Array<interop.Object>): InstanceType<This>;

  static photoBracketSettingsWithRawPixelFormatTypeRawFileTypeProcessedFormatProcessedFileTypeBracketedSettings<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number, rawFileType: string | null, processedFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, processedFileType: string | null, bracketedSettings: NSArray<interop.Object> | Array<interop.Object>): InstanceType<This>;

  readonly bracketedSettings: NSArray;

  lensStabilizationEnabled: boolean;

  isLensStabilizationEnabled(): boolean;

  setLensStabilizationEnabled(lensStabilizationEnabled: boolean): void;
}

declare class AVAssetResourceLoadingContentInformationRequest extends NSObject {
  contentType: string;

  readonly allowedContentTypes: NSArray;

  contentLength: number;

  byteRangeAccessSupported: boolean;

  renewalDate: NSDate;

  entireLengthAvailableOnDemand: boolean;

  setContentType(contentType: string | null): void;

  setContentLength(contentLength: number): void;

  isByteRangeAccessSupported(): boolean;

  setByteRangeAccessSupported(byteRangeAccessSupported: boolean): void;

  setRenewalDate(renewalDate: NSDate): void;

  isEntireLengthAvailableOnDemand(): boolean;

  setEntireLengthAvailableOnDemand(entireLengthAvailableOnDemand: boolean): void;
}

declare class AVMediaPresentationSetting extends NSObject implements NSCopying {
  readonly mediaCharacteristic: string;

  displayNameForLocaleIdentifier(localeIdentifier: string): string;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptureDevice extends NSObject {
  static devices(): NSArray;

  static devicesWithMediaType(mediaType: string): NSArray;

  static defaultDeviceWithMediaType(mediaType: string): AVCaptureDevice;

  static deviceWithUniqueID(deviceUniqueID: string): AVCaptureDevice;

  readonly uniqueID: string;

  readonly modelID: string;

  readonly localizedName: string;

  readonly manufacturer: string;

  hasMediaType(mediaType: string): boolean;

  lockForConfiguration(outError: interop.PointerConvertible): boolean;

  unlockForConfiguration(): void;

  supportsAVCaptureSessionPreset(preset: string): boolean;

  readonly connected: boolean;

  readonly suspended: boolean;

  readonly formats: NSArray;

  activeFormat: AVCaptureDeviceFormat;

  activeVideoMinFrameDuration: CMTime;

  activeVideoMaxFrameDuration: CMTime;

  readonly videoFrameDurationLocked: boolean;

  readonly minSupportedLockedVideoFrameDuration: CMTime;

  readonly followingExternalSyncDevice: boolean;

  readonly minSupportedExternalSyncFrameDuration: CMTime;

  autoVideoFrameRateEnabled: boolean;

  isConnected(): boolean;

  isSuspended(): boolean;

  setActiveFormat(activeFormat: AVCaptureDeviceFormat): void;

  setActiveVideoMinFrameDuration(activeVideoMinFrameDuration: CMTime): void;

  setActiveVideoMaxFrameDuration(activeVideoMaxFrameDuration: CMTime): void;

  isVideoFrameDurationLocked(): boolean;

  isFollowingExternalSyncDevice(): boolean;

  isAutoVideoFrameRateEnabled(): boolean;

  setAutoVideoFrameRateEnabled(autoVideoFrameRateEnabled: boolean): void;

  readonly position: interop.Enum<typeof AVCaptureDevicePosition>;

  readonly deviceType: string;

  static defaultDeviceWithDeviceTypeMediaTypePosition(deviceType: string, mediaType: string | null, position: interop.Enum<typeof AVCaptureDevicePosition>): AVCaptureDevice;

  static userPreferredCamera: AVCaptureDevice;

  static readonly systemPreferredCamera: AVCaptureDevice;

  static setUserPreferredCamera(userPreferredCamera: AVCaptureDevice): void;

  readonly systemPressureState: AVCaptureSystemPressureState;

  readonly virtualDevice: boolean;

  readonly constituentDevices: NSArray;

  readonly virtualDeviceSwitchOverVideoZoomFactors: NSArray;

  setPrimaryConstituentDeviceSwitchingBehaviorRestrictedSwitchingBehaviorConditions(switchingBehavior: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>, restrictedSwitchingBehaviorConditions: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>): void;

  readonly primaryConstituentDeviceSwitchingBehavior: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>;

  readonly primaryConstituentDeviceRestrictedSwitchingBehaviorConditions: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>;

  readonly activePrimaryConstituentDeviceSwitchingBehavior: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>;

  readonly activePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>;

  readonly activePrimaryConstituentDevice: AVCaptureDevice;

  readonly supportedFallbackPrimaryConstituentDevices: NSArray;

  get fallbackPrimaryConstituentDevices(): NSArray;
  set fallbackPrimaryConstituentDevices(value: NSArray<interop.Object> | Array<interop.Object>);

  isVirtualDevice(): boolean;

  setFallbackPrimaryConstituentDevices(fallbackPrimaryConstituentDevices: NSArray<interop.Object> | Array<interop.Object>): void;

  readonly hasFlash: boolean;

  readonly flashAvailable: boolean;

  readonly flashActive: boolean;

  isFlashModeSupported(flashMode: interop.Enum<typeof AVCaptureFlashMode>): boolean;

  flashMode: interop.Enum<typeof AVCaptureFlashMode>;

  isFlashAvailable(): boolean;

  isFlashActive(): boolean;

  setFlashMode(flashMode: interop.Enum<typeof AVCaptureFlashMode>): void;

  readonly hasTorch: boolean;

  readonly torchAvailable: boolean;

  readonly torchActive: boolean;

  readonly torchLevel: number;

  isTorchModeSupported(torchMode: interop.Enum<typeof AVCaptureTorchMode>): boolean;

  torchMode: interop.Enum<typeof AVCaptureTorchMode>;

  setTorchModeOnWithLevelError(torchLevel: number, outError: interop.PointerConvertible): boolean;

  isTorchAvailable(): boolean;

  isTorchActive(): boolean;

  setTorchMode(torchMode: interop.Enum<typeof AVCaptureTorchMode>): void;

  isFocusModeSupported(focusMode: interop.Enum<typeof AVCaptureFocusMode>): boolean;

  readonly lockingFocusWithCustomLensPositionSupported: boolean;

  focusMode: interop.Enum<typeof AVCaptureFocusMode>;

  readonly focusPointOfInterestSupported: boolean;

  focusPointOfInterest: CGPoint;

  readonly focusRectOfInterestSupported: boolean;

  readonly minFocusRectOfInterestSize: CGSize;

  focusRectOfInterest: CGRect;

  defaultRectForFocusPointOfInterest(pointOfInterest: CGPoint): CGRect;

  readonly adjustingFocus: boolean;

  readonly autoFocusRangeRestrictionSupported: boolean;

  autoFocusRangeRestriction: interop.Enum<typeof AVCaptureAutoFocusRangeRestriction>;

  readonly smoothAutoFocusSupported: boolean;

  smoothAutoFocusEnabled: boolean;

  automaticallyAdjustsFaceDrivenAutoFocusEnabled: boolean;

  faceDrivenAutoFocusEnabled: boolean;

  readonly lensPosition: number;

  setFocusModeLockedWithLensPositionCompletionHandler(lensPosition: number, handler: (p1: CMTime) => void | null): void;

  readonly minimumFocusDistance: number;

  setCinematicVideoTrackingFocusWithDetectedObjectIDFocusMode(detectedObjectID: number, focusMode: interop.Enum<typeof AVCaptureCinematicVideoFocusMode>): void;

  setCinematicVideoTrackingFocusAtPointFocusMode(point: CGPoint, focusMode: interop.Enum<typeof AVCaptureCinematicVideoFocusMode>): void;

  setCinematicVideoFixedFocusAtPointFocusMode(point: CGPoint, focusMode: interop.Enum<typeof AVCaptureCinematicVideoFocusMode>): void;

  isLockingFocusWithCustomLensPositionSupported(): boolean;

  setFocusMode(focusMode: interop.Enum<typeof AVCaptureFocusMode>): void;

  isFocusPointOfInterestSupported(): boolean;

  setFocusPointOfInterest(focusPointOfInterest: CGPoint): void;

  isFocusRectOfInterestSupported(): boolean;

  setFocusRectOfInterest(focusRectOfInterest: CGRect): void;

  isAdjustingFocus(): boolean;

  isAutoFocusRangeRestrictionSupported(): boolean;

  setAutoFocusRangeRestriction(autoFocusRangeRestriction: interop.Enum<typeof AVCaptureAutoFocusRangeRestriction>): void;

  isSmoothAutoFocusSupported(): boolean;

  isSmoothAutoFocusEnabled(): boolean;

  setSmoothAutoFocusEnabled(smoothAutoFocusEnabled: boolean): void;

  setAutomaticallyAdjustsFaceDrivenAutoFocusEnabled(automaticallyAdjustsFaceDrivenAutoFocusEnabled: boolean): void;

  isFaceDrivenAutoFocusEnabled(): boolean;

  setFaceDrivenAutoFocusEnabled(faceDrivenAutoFocusEnabled: boolean): void;

  isExposureModeSupported(exposureMode: interop.Enum<typeof AVCaptureExposureMode>): boolean;

  exposureMode: interop.Enum<typeof AVCaptureExposureMode>;

  readonly exposurePointOfInterestSupported: boolean;

  exposurePointOfInterest: CGPoint;

  readonly exposureRectOfInterestSupported: boolean;

  readonly minExposureRectOfInterestSize: CGSize;

  exposureRectOfInterest: CGRect;

  defaultRectForExposurePointOfInterest(pointOfInterest: CGPoint): CGRect;

  automaticallyAdjustsFaceDrivenAutoExposureEnabled: boolean;

  faceDrivenAutoExposureEnabled: boolean;

  activeMaxExposureDuration: CMTime;

  readonly adjustingExposure: boolean;

  readonly lensAperture: number;

  readonly exposureDuration: CMTime;

  readonly ISO: number;

  setExposureModeCustomWithDurationISOCompletionHandler(duration: CMTime, ISO: number, handler: (p1: CMTime) => void | null): void;

  readonly exposureTargetOffset: number;

  readonly exposureTargetBias: number;

  readonly minExposureTargetBias: number;

  readonly maxExposureTargetBias: number;

  setExposureTargetBiasCompletionHandler(bias: number, handler: (p1: CMTime) => void | null): void;

  setExposureMode(exposureMode: interop.Enum<typeof AVCaptureExposureMode>): void;

  isExposurePointOfInterestSupported(): boolean;

  setExposurePointOfInterest(exposurePointOfInterest: CGPoint): void;

  isExposureRectOfInterestSupported(): boolean;

  setExposureRectOfInterest(exposureRectOfInterest: CGRect): void;

  setAutomaticallyAdjustsFaceDrivenAutoExposureEnabled(automaticallyAdjustsFaceDrivenAutoExposureEnabled: boolean): void;

  isFaceDrivenAutoExposureEnabled(): boolean;

  setFaceDrivenAutoExposureEnabled(faceDrivenAutoExposureEnabled: boolean): void;

  setActiveMaxExposureDuration(activeMaxExposureDuration: CMTime): void;

  isAdjustingExposure(): boolean;

  globalToneMappingEnabled: boolean;

  isGlobalToneMappingEnabled(): boolean;

  setGlobalToneMappingEnabled(globalToneMappingEnabled: boolean): void;

  isWhiteBalanceModeSupported(whiteBalanceMode: interop.Enum<typeof AVCaptureWhiteBalanceMode>): boolean;

  readonly lockingWhiteBalanceWithCustomDeviceGainsSupported: boolean;

  whiteBalanceMode: interop.Enum<typeof AVCaptureWhiteBalanceMode>;

  readonly adjustingWhiteBalance: boolean;

  readonly deviceWhiteBalanceGains: AVCaptureWhiteBalanceGains;

  readonly grayWorldDeviceWhiteBalanceGains: AVCaptureWhiteBalanceGains;

  readonly maxWhiteBalanceGain: number;

  setWhiteBalanceModeLockedWithDeviceWhiteBalanceTemperatureAndTintValuesCompletionHandler(whiteBalanceTemperatureAndTintValues: AVCaptureWhiteBalanceTemperatureAndTintValues, handler: (p1: CMTime) => void | null): void;

  setWhiteBalanceModeLockedWithDeviceWhiteBalanceGainsCompletionHandler(whiteBalanceGains: AVCaptureWhiteBalanceGains, handler: (p1: CMTime) => void | null): void;

  chromaticityValuesForDeviceWhiteBalanceGains(whiteBalanceGains: AVCaptureWhiteBalanceGains): AVCaptureWhiteBalanceChromaticityValues;

  deviceWhiteBalanceGainsForChromaticityValues(chromaticityValues: AVCaptureWhiteBalanceChromaticityValues): AVCaptureWhiteBalanceGains;

  temperatureAndTintValuesForDeviceWhiteBalanceGains(whiteBalanceGains: AVCaptureWhiteBalanceGains): AVCaptureWhiteBalanceTemperatureAndTintValues;

  deviceWhiteBalanceGainsForTemperatureAndTintValues(tempAndTintValues: AVCaptureWhiteBalanceTemperatureAndTintValues): AVCaptureWhiteBalanceGains;

  isLockingWhiteBalanceWithCustomDeviceGainsSupported(): boolean;

  setWhiteBalanceMode(whiteBalanceMode: interop.Enum<typeof AVCaptureWhiteBalanceMode>): void;

  isAdjustingWhiteBalance(): boolean;

  subjectAreaChangeMonitoringEnabled: boolean;

  isSubjectAreaChangeMonitoringEnabled(): boolean;

  setSubjectAreaChangeMonitoringEnabled(subjectAreaChangeMonitoringEnabled: boolean): void;

  readonly lowLightBoostSupported: boolean;

  readonly lowLightBoostEnabled: boolean;

  automaticallyEnablesLowLightBoostWhenAvailable: boolean;

  isLowLightBoostSupported(): boolean;

  isLowLightBoostEnabled(): boolean;

  setAutomaticallyEnablesLowLightBoostWhenAvailable(automaticallyEnablesLowLightBoostWhenAvailable: boolean): void;

  videoZoomFactor: number;

  rampToVideoZoomFactorWithRate(factor: number, rate: number): void;

  readonly rampingVideoZoom: boolean;

  cancelVideoZoomRamp(): void;

  readonly dualCameraSwitchOverVideoZoomFactor: number;

  readonly displayVideoZoomFactorMultiplier: number;

  setVideoZoomFactor(videoZoomFactor: number): void;

  isRampingVideoZoom(): boolean;

  static authorizationStatusForMediaType(mediaType: string): interop.Enum<typeof AVAuthorizationStatus>;

  static requestAccessForMediaTypeCompletionHandler(mediaType: string, handler: (p1: boolean) => void): void;

  automaticallyAdjustsVideoHDREnabled: boolean;

  videoHDREnabled: boolean;

  setAutomaticallyAdjustsVideoHDREnabled(automaticallyAdjustsVideoHDREnabled: boolean): void;

  isVideoHDREnabled(): boolean;

  setVideoHDREnabled(videoHDREnabled: boolean): void;

  activeColorSpace: interop.Enum<typeof AVCaptureColorSpace>;

  setActiveColorSpace(activeColorSpace: interop.Enum<typeof AVCaptureColorSpace>): void;

  activeDepthDataFormat: AVCaptureDeviceFormat;

  activeDepthDataMinFrameDuration: CMTime;

  readonly minAvailableVideoZoomFactor: number;

  readonly maxAvailableVideoZoomFactor: number;

  setActiveDepthDataFormat(activeDepthDataFormat: AVCaptureDeviceFormat | null): void;

  setActiveDepthDataMinFrameDuration(activeDepthDataMinFrameDuration: CMTime): void;

  readonly geometricDistortionCorrectionSupported: boolean;

  geometricDistortionCorrectionEnabled: boolean;

  isGeometricDistortionCorrectionSupported(): boolean;

  isGeometricDistortionCorrectionEnabled(): boolean;

  setGeometricDistortionCorrectionEnabled(geometricDistortionCorrectionEnabled: boolean): void;

  static extrinsicMatrixFromDeviceToDevice(fromDevice: AVCaptureDevice, toDevice: AVCaptureDevice): NSData;

  static centerStageControlMode: interop.Enum<typeof AVCaptureCenterStageControlMode>;

  static centerStageEnabled: boolean;

  readonly centerStageActive: boolean;

  centerStageRectOfInterest: CGRect;

  static setCenterStageControlMode(centerStageControlMode: interop.Enum<typeof AVCaptureCenterStageControlMode>): void;

  static isCenterStageEnabled(): boolean;

  static setCenterStageEnabled(centerStageEnabled: boolean): void;

  isCenterStageActive(): boolean;

  setCenterStageRectOfInterest(centerStageRectOfInterest: CGRect): void;

  static readonly portraitEffectEnabled: boolean;

  readonly portraitEffectActive: boolean;

  static isPortraitEffectEnabled(): boolean;

  isPortraitEffectActive(): boolean;

  static readonly reactionEffectsEnabled: boolean;

  static readonly reactionEffectGesturesEnabled: boolean;

  readonly canPerformReactionEffects: boolean;

  readonly availableReactionTypes: NSSet;

  performEffectForReaction(reactionType: string): void;

  readonly reactionEffectsInProgress: NSArray;

  static readonly backgroundReplacementEnabled: boolean;

  readonly backgroundReplacementActive: boolean;

  static isBackgroundReplacementEnabled(): boolean;

  isBackgroundReplacementActive(): boolean;

  readonly continuityCamera: boolean;

  isContinuityCamera(): boolean;

  readonly companionDeskViewCamera: AVCaptureDevice;

  static readonly preferredMicrophoneMode: interop.Enum<typeof AVCaptureMicrophoneMode>;

  static readonly activeMicrophoneMode: interop.Enum<typeof AVCaptureMicrophoneMode>;

  static showSystemUserInterface(systemUserInterface: interop.Enum<typeof AVCaptureSystemUserInterface>): void;

  readonly spatialCaptureDiscomfortReasons: NSSet;

  readonly cinematicVideoCaptureSceneMonitoringStatuses: NSSet;

  readonly dynamicAspectRatio: string;

  readonly dynamicDimensions: CMVideoDimensions;

  setDynamicAspectRatioCompletionHandler(dynamicAspectRatio: string, handler: (p1: CMTime, p2: NSError) => void | null): void;

  readonly smartFramingMonitor: AVCaptureSmartFramingMonitor;

  readonly nominalFocalLengthIn35mmFilm: number;

  static readonly studioLightEnabled: boolean;

  readonly studioLightActive: boolean;

  static isStudioLightEnabled(): boolean;

  isStudioLightActive(): boolean;

  setCameraLensSmudgeDetectionEnabledDetectionInterval(cameraLensSmudgeDetectionEnabled: boolean, detectionInterval: CMTime): void;

  readonly cameraLensSmudgeDetectionEnabled: boolean;

  readonly cameraLensSmudgeDetectionInterval: CMTime;

  readonly cameraLensSmudgeDetectionStatus: interop.Enum<typeof AVCaptureCameraLensSmudgeDetectionStatus>;

  isCameraLensSmudgeDetectionEnabled(): boolean;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVFragmentedAsset extends AVURLAsset implements AVFragmentMinding {
  static fragmentedAssetWithURLOptions<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  readonly tracks: NSArray;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVFragmentedAssetTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVFragmentedAssetTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly associatedWithFragmentMinder: boolean;

  isAssociatedWithFragmentMinder(): boolean;
}

declare class AVAsynchronousVideoCompositionRequest extends NSObject implements NSCopying {
  readonly renderContext: AVVideoCompositionRenderContext;

  readonly compositionTime: CMTime;

  readonly sourceTrackIDs: NSArray;

  readonly sourceSampleDataTrackIDs: NSArray;

  readonly videoCompositionInstruction: AVVideoCompositionInstruction;

  sourceFrameByTrackID(trackID: number): interop.Object;

  sourceSampleBufferByTrackID(trackID: number): interop.Object;

  sourceTimedMetadataByTrackID(trackID: number): AVTimedMetadataGroup;

  finishWithComposedVideoFrame(composedVideoFrame: interop.Object): void;

  finishWithError(error: NSError): void;

  finishCancelledRequest(): void;

  sourceTaggedBufferGroupByTrackID(trackID: number): interop.Pointer;

  finishWithComposedTaggedBufferGroup(taggedBufferGroup: interop.PointerConvertible): void;

  attachSpatialVideoConfigurationToPixelBuffer(spatialVideoConfiguration: AVSpatialVideoConfiguration | null, pixelBuffer: interop.Object): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataItem extends NSObject implements AVAsynchronousKeyValueLoading, NSCopying, NSMutableCopying {
  readonly identifier: string;

  readonly extendedLanguageTag: string;

  readonly locale: NSLocale;

  readonly time: CMTime;

  readonly duration: CMTime;

  readonly dataType: string;

  readonly value: NSCopying;

  readonly extraAttributes: NSDictionary;

  readonly startDate: NSDate;

  readonly stringValue: string;

  readonly numberValue: NSNumber;

  readonly dateValue: NSDate;

  readonly dataValue: NSData;

  statusOfValueForKeyError(key: string, outError: interop.PointerConvertible): interop.Enum<typeof AVKeyValueStatus>;

  loadValuesAsynchronouslyForKeysCompletionHandler(keys: NSArray<interop.Object> | Array<interop.Object>, handler: () => void | null): void;

  static metadataItemsFromArrayFilteredAndSortedAccordingToPreferredLanguages(metadataItems: NSArray<interop.Object> | Array<interop.Object>, preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  static metadataItemsFromArrayFilteredByIdentifier(metadataItems: NSArray<interop.Object> | Array<interop.Object>, identifier: string): NSArray;

  static metadataItemsFromArrayFilteredByMetadataItemFilter(metadataItems: NSArray<interop.Object> | Array<interop.Object>, metadataItemFilter: AVMetadataItemFilter): NSArray;

  static identifierForKeyKeySpace(key: interop.Object, keySpace: string): string;

  static keySpaceForIdentifier(identifier: string): string;

  static keyForIdentifier(identifier: string): interop.Object;

  readonly key: NSCopying;

  readonly commonKey: string;

  readonly keySpace: string;

  static metadataItemWithPropertiesOfMetadataItemValueLoadingHandler(metadataItem: AVMetadataItem, handler: (p1: AVMetadataItemValueRequest) => void): AVMetadataItem;

  static metadataItemsFromArrayWithLocale(metadataItems: NSArray<interop.Object> | Array<interop.Object>, locale: NSLocale): NSArray;

  static metadataItemsFromArrayWithKeyKeySpace(metadataItems: NSArray<interop.Object> | Array<interop.Object>, key: interop.Object | null, keySpace: string | null): NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVSampleCursor extends NSObject implements NSCopying {
  stepInDecodeOrderByCount(stepCount: number): number;

  stepInPresentationOrderByCount(stepCount: number): number;

  stepByDecodeTimeWasPinned(deltaDecodeTime: CMTime, outWasPinned: interop.PointerConvertible): CMTime;

  stepByPresentationTimeWasPinned(deltaPresentationTime: CMTime, outWasPinned: interop.PointerConvertible): CMTime;

  readonly presentationTimeStamp: CMTime;

  readonly decodeTimeStamp: CMTime;

  comparePositionInDecodeOrderWithPositionOfCursor(cursor: AVSampleCursor): interop.Enum<typeof NSComparisonResult>;

  samplesWithEarlierDecodeTimeStampsMayHaveLaterPresentationTimeStampsThanCursor(cursor: AVSampleCursor): boolean;

  samplesWithLaterDecodeTimeStampsMayHaveEarlierPresentationTimeStampsThanCursor(cursor: AVSampleCursor): boolean;

  readonly currentSampleDuration: CMTime;

  copyCurrentSampleFormatDescription(): interop.Object;

  readonly currentSampleSyncInfo: AVSampleCursorSyncInfo;

  readonly currentSampleDependencyInfo: AVSampleCursorDependencyInfo;

  readonly currentSampleDependencyAttachments: NSDictionary;

  readonly currentSampleAudioDependencyInfo: AVSampleCursorAudioDependencyInfo;

  readonly samplesRequiredForDecoderRefresh: number;

  readonly currentChunkStorageURL: NSURL;

  readonly currentChunkStorageRange: AVSampleCursorStorageRange;

  readonly currentChunkInfo: AVSampleCursorChunkInfo;

  readonly currentSampleIndexInChunk: number;

  readonly currentSampleStorageRange: AVSampleCursorStorageRange;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMutableMediaSelection extends AVMediaSelection {
  selectMediaOptionInMediaSelectionGroup(mediaSelectionOption: AVMediaSelectionOption | null, mediaSelectionGroup: AVMediaSelectionGroup): void;
}

declare class AVCaptionRendererScene extends NSObject implements NSCopying {
  readonly timeRange: CMTimeRange;

  readonly hasActiveCaptions: boolean;

  readonly needsPeriodicRefresh: boolean;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetReaderOutputCaptionAdaptor extends NSObject {
  static assetReaderOutputCaptionAdaptorWithAssetReaderTrackOutput<This extends abstract new (...args: any) => any>(this: This, trackOutput: AVAssetReaderTrackOutput): InstanceType<This>;

  initWithAssetReaderTrackOutput(trackOutput: AVAssetReaderTrackOutput): this;

  readonly assetReaderTrackOutput: AVAssetReaderTrackOutput;

  nextCaptionGroup(): AVCaptionGroup;

  captionsNotPresentInPreviousGroupsInCaptionGroup(captionGroup: AVCaptionGroup): NSArray;

  validationDelegate: AVAssetReaderCaptionValidationHandling | null;

  setValidationDelegate(validationDelegate: AVAssetReaderCaptionValidationHandling | null): void;
}

declare class AVDelegatingPlaybackCoordinator extends AVPlaybackCoordinator {
  initWithPlaybackControlDelegate(playbackControlDelegate: AVPlaybackCoordinatorPlaybackControlDelegate): this;

  readonly playbackControlDelegate: AVPlaybackCoordinatorPlaybackControlDelegate | null;

  coordinateRateChangeToRateOptions(rate: number, options: interop.Enum<typeof AVDelegatingPlaybackCoordinatorRateChangeOptions>): void;

  coordinateSeekToTimeOptions(time: CMTime, options: interop.Enum<typeof AVDelegatingPlaybackCoordinatorSeekOptions>): void;

  transitionToItemWithIdentifierProposingInitialTimingBasedOnTimebase(itemIdentifier: string | null, snapshotTimebase: interop.Object | null): void;

  readonly currentItemIdentifier: string;

  reapplyCurrentItemStateToPlaybackControlDelegate(): void;
}

declare class AVAssetReader extends NSObject {
  static assetReaderWithAssetError<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset, outError: interop.PointerConvertible): InstanceType<This>;

  initWithAssetError(asset: AVAsset, outError: interop.PointerConvertible): this;

  readonly asset: AVAsset;

  readonly status: interop.Enum<typeof AVAssetReaderStatus>;

  readonly error: NSError;

  timeRange: CMTimeRange;

  readonly outputs: NSArray;

  canAddOutput(output: AVAssetReaderOutput): boolean;

  addOutput(output: AVAssetReaderOutput): void;

  startReading(): boolean;

  cancelReading(): void;

  setTimeRange(timeRange: CMTimeRange): void;
}

declare class AVRouteDetector extends NSObject {
  routeDetectionEnabled: boolean;

  readonly multipleRoutesDetected: boolean;

  detectsCustomRoutes: boolean;

  isRouteDetectionEnabled(): boolean;

  setRouteDetectionEnabled(routeDetectionEnabled: boolean): void;

  setDetectsCustomRoutes(detectsCustomRoutes: boolean): void;
}

declare class AVCaptureDepthDataOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  setDelegateCallbackQueue(delegate: AVCaptureDepthDataOutputDelegate | null, callbackQueue: NSObject | null): void;

  readonly delegate: AVCaptureDepthDataOutputDelegate;

  readonly delegateCallbackQueue: NSObject;

  alwaysDiscardsLateDepthData: boolean;

  filteringEnabled: boolean;

  setAlwaysDiscardsLateDepthData(alwaysDiscardsLateDepthData: boolean): void;

  isFilteringEnabled(): boolean;

  setFilteringEnabled(filteringEnabled: boolean): void;
}

declare class AVCoordinatedPlaybackParticipant extends NSObject {
  readonly suspensionReasons: NSArray;

  readonly readyToPlay: boolean;

  readonly identifier: NSUUID;

  isReadyToPlay(): boolean;
}

declare class AVCaptionConversionTimeRangeAdjustment extends AVCaptionConversionAdjustment {
  readonly startTimeOffset: CMTime;

  readonly durationOffset: CMTime;
}

declare class AVAssetReaderOutputMetadataAdaptor extends NSObject {
  static assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput<This extends abstract new (...args: any) => any>(this: This, trackOutput: AVAssetReaderTrackOutput): InstanceType<This>;

  initWithAssetReaderTrackOutput(trackOutput: AVAssetReaderTrackOutput): this;

  readonly assetReaderTrackOutput: AVAssetReaderTrackOutput;

  nextTimedMetadataGroup(): AVTimedMetadataGroup;
}

declare class AVCaptionGroup extends NSObject {
  initWithCaptionsTimeRange(captions: NSArray<interop.Object> | Array<interop.Object>, timeRange: CMTimeRange): this;

  initWithTimeRange(timeRange: CMTimeRange): this;

  readonly timeRange: CMTimeRange;

  readonly captions: NSArray;
}

declare class AVPlayerItemErrorLog extends NSObject implements NSCopying {
  extendedLogData(): NSData;

  readonly extendedLogDataStringEncoding: number;

  readonly events: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVFragmentedAssetTrack extends AVAssetTrack {
}

declare class AVContentKeySession extends NSObject {
  static contentKeySessionWithKeySystem<This extends abstract new (...args: any) => any>(this: This, keySystem: string): InstanceType<This>;

  static contentKeySessionWithKeySystemStorageDirectoryAtURL<This extends abstract new (...args: any) => any>(this: This, keySystem: string, storageURL: NSURL): InstanceType<This>;

  setDelegateQueue(delegate: AVContentKeySessionDelegate | null, delegateQueue: NSObject | null): void;

  readonly delegate: AVContentKeySessionDelegate;

  readonly delegateQueue: NSObject;

  readonly storageURL: NSURL;

  readonly keySystem: string;

  expire(): void;

  readonly contentProtectionSessionIdentifier: NSData;

  processContentKeyRequestWithIdentifierInitializationDataOptions(identifier: interop.Object | null, initializationData: NSData | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): void;

  renewExpiringResponseDataForContentKeyRequest(contentKeyRequest: AVContentKeyRequest): void;

  makeSecureTokenForExpirationDateOfPersistableContentKeyCompletionHandler(persistableContentKeyData: NSData, handler: (p1: NSData, p2: NSError) => void | null): void;

  invalidatePersistableContentKeyOptionsCompletionHandler(persistableContentKeyData: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, handler: (p1: NSData, p2: NSError) => void | null): void;

  invalidateAllPersistableContentKeysForAppOptionsCompletionHandler(appIdentifier: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, handler: (p1: NSData, p2: NSError) => void | null): void;

  addContentKeyRecipient(recipient: AVContentKeyRecipient): void;

  removeContentKeyRecipient(recipient: AVContentKeyRecipient): void;

  readonly contentKeyRecipients: NSArray;

  static pendingExpiredSessionReportsWithAppIdentifierStorageDirectoryAtURL(appIdentifier: NSData, storageURL: NSURL): NSArray;

  static removePendingExpiredSessionReportsWithAppIdentifierStorageDirectoryAtURL(expiredSessionReports: NSArray<interop.Object> | Array<interop.Object>, appIdentifier: NSData, storageURL: NSURL): void;
}

declare class AVMediaSelection extends NSObject implements NSCopying, NSMutableCopying {
  readonly asset: AVAsset | null;

  selectedMediaOptionInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): AVMediaSelectionOption;

  mediaSelectionCriteriaCanBeAppliedAutomaticallyToMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): boolean;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetricPlayerItemStallEvent extends AVMetricPlayerItemRateChangeEvent {
}

declare class AVCaptionRuby extends NSObject implements NSCopying, NSSecureCoding {
  initWithText(text: string): this;

  initWithTextPositionAlignment(text: string, position: interop.Enum<typeof AVCaptionRubyPosition>, alignment: interop.Enum<typeof AVCaptionRubyAlignment>): this;

  readonly text: string;

  readonly position: interop.Enum<typeof AVCaptionRubyPosition>;

  readonly alignment: interop.Enum<typeof AVCaptionRubyAlignment>;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVContentKeyResponse extends NSObject {
  static contentKeyResponseWithFairPlayStreamingKeyResponseData<This extends abstract new (...args: any) => any>(this: This, keyResponseData: NSData): InstanceType<This>;

  static contentKeyResponseWithClearKeyDataInitializationVector<This extends abstract new (...args: any) => any>(this: This, keyData: NSData, initializationVector: NSData | null): InstanceType<This>;

  static contentKeyResponseWithAuthorizationTokenData<This extends abstract new (...args: any) => any>(this: This, authorizationTokenData: NSData): InstanceType<This>;
}

declare class AVCaptionGrouper extends NSObject {
  addCaption(input: AVCaption): void;

  flushAddedCaptionsIntoGroupsUpToTime(upToTime: CMTime): NSArray;
}

declare class AVPlayerItemMediaDataCollector extends NSObject {
}

declare class AVPlayerItemRenderedLegibleOutput extends AVPlayerItemOutput {
  initWithVideoDisplaySize(videoDisplaySize: CGSize): this;

  setDelegateQueue(delegate: AVPlayerItemRenderedLegibleOutputPushDelegate | null, delegateQueue: NSObject | null): void;

  readonly delegate: AVPlayerItemRenderedLegibleOutputPushDelegate;

  readonly delegateQueue: NSObject;

  advanceIntervalForDelegateInvocation: number;

  videoDisplaySize: CGSize;

  setAdvanceIntervalForDelegateInvocation(advanceIntervalForDelegateInvocation: number): void;

  setVideoDisplaySize(videoDisplaySize: CGSize): void;
}

declare class AVAssetVariantVideoLayoutAttributes extends NSObject {
  readonly stereoViewComponents: interop.Enum<typeof CMStereoViewComponents>;

  readonly projectionType: interop.Enum<typeof CMProjectionType>;
}

declare class AVPlaybackCoordinationMedium extends NSObject {
  init(): this;

  readonly connectedPlaybackCoordinators: NSArray;
}

declare class AVDepthData extends NSObject {
  static depthDataFromDictionaryRepresentationError<This extends abstract new (...args: any) => any>(this: This, imageSourceAuxDataInfoDictionary: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, outError: interop.PointerConvertible): InstanceType<This>;

  depthDataByConvertingToDepthDataType(depthDataType: number): this;

  depthDataByApplyingExifOrientation(exifOrientation: interop.Enum<typeof CGImagePropertyOrientation>): this;

  depthDataByReplacingDepthDataMapWithPixelBufferError(pixelBuffer: interop.Object, outError: interop.PointerConvertible): this;

  readonly availableDepthDataTypes: NSArray;

  dictionaryRepresentationForAuxiliaryDataType(outAuxDataType: interop.PointerConvertible): NSDictionary;

  readonly depthDataType: number;

  readonly depthDataMap: interop.Object;

  readonly depthDataQuality: interop.Enum<typeof AVDepthDataQuality>;

  readonly depthDataFiltered: boolean;

  readonly depthDataAccuracy: interop.Enum<typeof AVDepthDataAccuracy>;

  readonly cameraCalibrationData: AVCameraCalibrationData;

  isDepthDataFiltered(): boolean;
}

declare class AVVideoPerformanceMetrics extends NSObject {
  readonly totalNumberOfFrames: number;

  readonly numberOfDroppedFrames: number;

  readonly numberOfCorruptedFrames: number;

  readonly numberOfFramesDisplayedUsingOptimizedCompositing: number;

  readonly totalAccumulatedFrameDelay: number;
}

declare class AVMetricPlayerItemVariantSwitchStartEvent extends AVMetricEvent {
  readonly fromVariant: AVAssetVariant;

  readonly toVariant: AVAssetVariant;

  readonly loadedTimeRanges: NSArray;

  readonly videoRendition: AVMetricMediaRendition;

  readonly audioRendition: AVMetricMediaRendition;

  readonly subtitleRendition: AVMetricMediaRendition;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableDateRangeMetadataGroup extends AVDateRangeMetadataGroup {
  // @ts-ignore MemberDecl.tsIgnore
  startDate: NSDate;

  // @ts-ignore MemberDecl.tsIgnore
  endDate: NSDate;

  // @ts-ignore MemberDecl.tsIgnore
  get items(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set items(value: NSArray<interop.Object> | Array<interop.Object>);

  setStartDate(startDate: NSDate): void;

  setEndDate(endDate: NSDate | null): void;

  setItems(items: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVMetadataMachineReadableCodeObject extends AVMetadataObject {
  readonly corners: NSArray;

  readonly stringValue: string;

  readonly descriptor: CIBarcodeDescriptor;
}

declare class AVPlayerItem extends NSObject implements NSCopying {
  static playerItemWithURL<This extends abstract new (...args: any) => any>(this: This, URL: NSURL): InstanceType<This>;

  static playerItemWithAsset<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset): InstanceType<This>;

  static playerItemWithAssetAutomaticallyLoadedAssetKeys<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset, automaticallyLoadedAssetKeys: NSArray<interop.Object> | Array<interop.Object> | null): InstanceType<This>;

  initWithURL(URL: NSURL): this;

  initWithAsset(asset: AVAsset): this;

  initWithAssetAutomaticallyLoadedAssetKeys(asset: AVAsset, automaticallyLoadedAssetKeys: NSArray<interop.Object> | Array<interop.Object> | null): this;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  copy(): interop.Object;

  readonly status: interop.Enum<typeof AVPlayerItemStatus>;

  readonly error: NSError;

  readonly asset: AVAsset;

  readonly tracks: NSArray;

  readonly duration: CMTime;

  readonly presentationSize: CGSize;

  readonly timedMetadata: NSArray;

  readonly automaticallyLoadedAssetKeys: NSArray;

  readonly canPlayFastForward: boolean;

  readonly canPlaySlowForward: boolean;

  readonly canPlayReverse: boolean;

  readonly canPlaySlowReverse: boolean;

  readonly canPlayFastReverse: boolean;

  readonly canStepForward: boolean;

  readonly canStepBackward: boolean;

  configuredTimeOffsetFromLive: CMTime;

  readonly recommendedTimeOffsetFromLive: CMTime;

  automaticallyPreservesTimeOffsetFromLive: boolean;

  setConfiguredTimeOffsetFromLive(configuredTimeOffsetFromLive: CMTime): void;

  setAutomaticallyPreservesTimeOffsetFromLive(automaticallyPreservesTimeOffsetFromLive: boolean): void;

  currentTime(): CMTime;

  forwardPlaybackEndTime: CMTime;

  reversePlaybackEndTime: CMTime;

  readonly seekableTimeRanges: NSArray;

  seekToTimeCompletionHandler(time: CMTime, completionHandler: (p1: boolean) => void | null): void;

  seekToTimeToleranceBeforeToleranceAfterCompletionHandler(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime, completionHandler: (p1: boolean) => void | null): void;

  cancelPendingSeeks(): void;

  currentDate(): NSDate;

  seekToDateCompletionHandler(date: NSDate, completionHandler: (p1: boolean) => void | null): boolean;

  stepByCount(stepCount: number): void;

  readonly timebase: interop.Object;

  setForwardPlaybackEndTime(forwardPlaybackEndTime: CMTime): void;

  setReversePlaybackEndTime(reversePlaybackEndTime: CMTime): void;

  videoComposition: AVVideoComposition;

  readonly customVideoCompositor: AVVideoCompositing;

  seekingWaitsForVideoCompositionRendering: boolean;

  get textStyleRules(): NSArray;
  set textStyleRules(value: NSArray<interop.Object> | Array<interop.Object>);

  videoApertureMode: string;

  appliesPerFrameHDRDisplayMetadata: boolean;

  setVideoComposition(videoComposition: AVVideoComposition): void;

  setSeekingWaitsForVideoCompositionRendering(seekingWaitsForVideoCompositionRendering: boolean): void;

  setTextStyleRules(textStyleRules: NSArray<interop.Object> | Array<interop.Object>): void;

  setVideoApertureMode(videoApertureMode: string): void;

  setAppliesPerFrameHDRDisplayMetadata(appliesPerFrameHDRDisplayMetadata: boolean): void;

  audioTimePitchAlgorithm: string;

  audioSpatializationAllowed: boolean;

  allowedAudioSpatializationFormats: interop.Enum<typeof AVAudioSpatializationFormats>;

  audioMix: AVAudioMix;

  setAudioTimePitchAlgorithm(audioTimePitchAlgorithm: string): void;

  isAudioSpatializationAllowed(): boolean;

  setAudioSpatializationAllowed(audioSpatializationAllowed: boolean): void;

  setAllowedAudioSpatializationFormats(allowedAudioSpatializationFormats: interop.Enum<typeof AVAudioSpatializationFormats>): void;

  setAudioMix(audioMix: AVAudioMix | null): void;

  readonly loadedTimeRanges: NSArray;

  readonly playbackLikelyToKeepUp: boolean;

  readonly playbackBufferFull: boolean;

  readonly playbackBufferEmpty: boolean;

  canUseNetworkResourcesForLiveStreamingWhilePaused: boolean;

  preferredForwardBufferDuration: number;

  isPlaybackLikelyToKeepUp(): boolean;

  isPlaybackBufferFull(): boolean;

  isPlaybackBufferEmpty(): boolean;

  setCanUseNetworkResourcesForLiveStreamingWhilePaused(canUseNetworkResourcesForLiveStreamingWhilePaused: boolean): void;

  setPreferredForwardBufferDuration(preferredForwardBufferDuration: number): void;

  preferredPeakBitRate: number;

  preferredPeakBitRateForExpensiveNetworks: number;

  preferredMaximumResolution: CGSize;

  preferredMaximumResolutionForExpensiveNetworks: CGSize;

  startsOnFirstEligibleVariant: boolean;

  variantPreferences: interop.Enum<typeof AVVariantPreferences>;

  setPreferredPeakBitRate(preferredPeakBitRate: number): void;

  setPreferredPeakBitRateForExpensiveNetworks(preferredPeakBitRateForExpensiveNetworks: number): void;

  setPreferredMaximumResolution(preferredMaximumResolution: CGSize): void;

  setPreferredMaximumResolutionForExpensiveNetworks(preferredMaximumResolutionForExpensiveNetworks: CGSize): void;

  setStartsOnFirstEligibleVariant(startsOnFirstEligibleVariant: boolean): void;

  setVariantPreferences(variantPreferences: interop.Enum<typeof AVVariantPreferences>): void;

  selectMediaOptionInMediaSelectionGroup(mediaSelectionOption: AVMediaSelectionOption | null, mediaSelectionGroup: AVMediaSelectionGroup): void;

  selectMediaOptionAutomaticallyInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): void;

  readonly currentMediaSelection: AVMediaSelection;

  get preferredCustomMediaSelectionSchemes(): NSArray;
  set preferredCustomMediaSelectionSchemes(value: NSArray<interop.Object> | Array<interop.Object>);

  selectMediaPresentationLanguageForMediaSelectionGroup(language: string, mediaSelectionGroup: AVMediaSelectionGroup): void;

  selectedMediaPresentationLanguageForMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): string;

  selectMediaPresentationSettingForMediaSelectionGroup(mediaPresentationSetting: AVMediaPresentationSetting, mediaSelectionGroup: AVMediaSelectionGroup): void;

  selectedMediaPresentationSettingsForMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): NSDictionary;

  effectiveMediaPresentationSettingsForMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): NSDictionary;

  setPreferredCustomMediaSelectionSchemes(preferredCustomMediaSelectionSchemes: NSArray<interop.Object> | Array<interop.Object>): void;

  accessLog(): AVPlayerItemAccessLog;

  errorLog(): AVPlayerItemErrorLog;

  addOutput(output: AVPlayerItemOutput): void;

  removeOutput(output: AVPlayerItemOutput): void;

  readonly outputs: NSArray;

  addMediaDataCollector(collector: AVPlayerItemMediaDataCollector): void;

  removeMediaDataCollector(collector: AVPlayerItemMediaDataCollector): void;

  readonly mediaDataCollectors: NSArray;

  seekToTime(time: CMTime): void;

  seekToTimeToleranceBeforeToleranceAfter(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime): void;

  seekToDate(date: NSDate): boolean;

  selectedMediaOptionInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): AVMediaSelectionOption;

  automaticallyHandlesInterstitialEvents: boolean;

  readonly templatePlayerItem: AVPlayerItem;

  setAutomaticallyHandlesInterstitialEvents(automaticallyHandlesInterstitialEvents: boolean): void;

  readonly integratedTimeline: AVPlayerItemIntegratedTimeline;

  get nowPlayingInfo(): NSDictionary;
  set nowPlayingInfo(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  setNowPlayingInfo(nowPlayingInfo: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): void;

  get externalMetadata(): NSArray;
  set externalMetadata(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly interstitialTimeRanges: NSArray;

  setExternalMetadata(externalMetadata: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVMetricDownloadSummaryEvent extends AVMetricEvent {
  readonly errorEvent: AVMetricErrorEvent;

  readonly recoverableErrorCount: number;

  readonly mediaResourceRequestCount: number;

  readonly bytesDownloadedCount: number;

  readonly downloadDuration: number;

  readonly variants: NSArray;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableMetadataItem extends AVMetadataItem {
  // @ts-ignore MemberDecl.tsIgnore
  identifier: string;

  // @ts-ignore MemberDecl.tsIgnore
  extendedLanguageTag: string;

  // @ts-ignore MemberDecl.tsIgnore
  locale: NSLocale;

  // @ts-ignore MemberDecl.tsIgnore
  time: CMTime;

  // @ts-ignore MemberDecl.tsIgnore
  duration: CMTime;

  // @ts-ignore MemberDecl.tsIgnore
  dataType: string;

  // @ts-ignore MemberDecl.tsIgnore
  value: NSCopying;

  // @ts-ignore MemberDecl.tsIgnore
  get extraAttributes(): NSDictionary;
  // @ts-ignore MemberDecl.tsIgnore
  set extraAttributes(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  static metadataItem(): AVMutableMetadataItem;

  setIdentifier(identifier: string | null): void;

  setExtendedLanguageTag(extendedLanguageTag: string | null): void;

  setLocale(locale: NSLocale | null): void;

  setTime(time: CMTime): void;

  setDuration(duration: CMTime): void;

  setDataType(dataType: string | null): void;

  setValue(value: NSCopying | null): void;

  setExtraAttributes(extraAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): void;

  // @ts-ignore MemberDecl.tsIgnore
  startDate: NSDate;

  setStartDate(startDate: NSDate | null): void;

  // @ts-ignore MemberDecl.tsIgnore
  keySpace: string;

  // @ts-ignore MemberDecl.tsIgnore
  key: NSCopying;

  setKeySpace(keySpace: string | null): void;

  setKey(key: NSCopying | null): void;
}

declare class AVPlayerMediaSelectionCriteria extends NSObject {
  readonly preferredLanguages: NSArray;

  readonly preferredMediaCharacteristics: NSArray;

  readonly principalMediaCharacteristics: NSArray;

  initWithPreferredLanguagesPreferredMediaCharacteristics(preferredLanguages: NSArray<interop.Object> | Array<interop.Object> | null, preferredMediaCharacteristics: NSArray<interop.Object> | Array<interop.Object> | null): this;

  initWithPrincipalMediaCharacteristicsPreferredLanguagesPreferredMediaCharacteristics(principalMediaCharacteristics: NSArray<interop.Object> | Array<interop.Object> | null, preferredLanguages: NSArray<interop.Object> | Array<interop.Object> | null, preferredMediaCharacteristics: NSArray<interop.Object> | Array<interop.Object> | null): this;
}

declare class AVMetadataDogBodyObject extends AVMetadataBodyObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetVariantAudioAttributes extends NSObject {
  readonly formatIDs: NSArray;

  renditionSpecificAttributesForMediaOption(mediaSelectionOption: AVMediaSelectionOption): AVAssetVariantAudioRenditionSpecificAttributes;
}

declare class AVCaptionConversionValidator extends NSObject {
  static captionConversionValidatorWithCaptionsTimeRangeConversionSettings<This extends abstract new (...args: any) => any>(this: This, captions: NSArray<interop.Object> | Array<interop.Object>, timeRange: CMTimeRange, conversionSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): InstanceType<This>;

  initWithCaptionsTimeRangeConversionSettings(captions: NSArray<interop.Object> | Array<interop.Object>, timeRange: CMTimeRange, conversionSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  readonly status: interop.Enum<typeof AVCaptionConversionValidatorStatus>;

  readonly captions: NSArray;

  readonly timeRange: CMTimeRange;

  validateCaptionConversionWithWarningHandler(handler: (p1: AVCaptionConversionWarning) => void | null): void;

  stopValidating(): void;

  readonly warnings: NSArray;
}

declare class AVAssetDownloadContentConfiguration extends NSObject implements NSCopying {
  get variantQualifiers(): NSArray;
  set variantQualifiers(value: NSArray<interop.Object> | Array<interop.Object>);

  get mediaSelections(): NSArray;
  set mediaSelections(value: NSArray<interop.Object> | Array<interop.Object>);

  setVariantQualifiers(variantQualifiers: NSArray<interop.Object> | Array<interop.Object>): void;

  setMediaSelections(mediaSelections: NSArray<interop.Object> | Array<interop.Object>): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCapturePhoto extends NSObject {
  readonly timestamp: CMTime;

  readonly rawPhoto: boolean;

  readonly pixelBuffer: interop.Object;

  readonly previewPixelBuffer: interop.Object;

  readonly embeddedThumbnailPhotoFormat: NSDictionary;

  readonly depthData: AVDepthData;

  readonly portraitEffectsMatte: AVPortraitEffectsMatte;

  semanticSegmentationMatteForType(semanticSegmentationMatteType: string): AVSemanticSegmentationMatte;

  readonly metadata: NSDictionary;

  readonly cameraCalibrationData: AVCameraCalibrationData;

  readonly resolvedSettings: AVCaptureResolvedPhotoSettings;

  readonly photoCount: number;

  readonly sourceDeviceType: string;

  readonly constantColorConfidenceMap: interop.Object;

  readonly constantColorCenterWeightedMeanConfidenceLevel: number;

  readonly constantColorFallbackPhoto: boolean;

  isRawPhoto(): boolean;

  isConstantColorFallbackPhoto(): boolean;

  fileDataRepresentation(): NSData;

  fileDataRepresentationWithCustomizer(customizer: AVCapturePhotoFileDataRepresentationCustomizer): NSData;

  fileDataRepresentationWithReplacementMetadataReplacementEmbeddedThumbnailPhotoFormatReplacementEmbeddedThumbnailPixelBufferReplacementDepthData(replacementMetadata: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, replacementEmbeddedThumbnailPhotoFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, replacementEmbeddedThumbnailPixelBuffer: interop.Object | null, replacementDepthData: AVDepthData | null): NSData;

  CGImageRepresentation(): interop.Object;

  previewCGImageRepresentation(): interop.Object;

  readonly bracketSettings: AVCaptureBracketedStillImageSettings;

  readonly sequenceCount: number;

  readonly lensStabilizationStatus: interop.Enum<typeof AVCaptureLensStabilizationStatus>;
}

declare class AVAssetResourceLoadingRequestor extends NSObject {
  readonly providesExpiredSessionReports: boolean;
}

declare class AVVideoCompositionLayerInstruction extends NSObject implements NSSecureCoding, NSCopying, NSMutableCopying {
  readonly trackID: number;

  getTransformRampForTimeStartTransformEndTransformTimeRange(time: CMTime, startTransform: interop.PointerConvertible, endTransform: interop.PointerConvertible, timeRange: interop.PointerConvertible): boolean;

  getOpacityRampForTimeStartOpacityEndOpacityTimeRange(time: CMTime, startOpacity: interop.PointerConvertible, endOpacity: interop.PointerConvertible, timeRange: interop.PointerConvertible): boolean;

  getCropRectangleRampForTimeStartCropRectangleEndCropRectangleTimeRange(time: CMTime, startCropRectangle: interop.PointerConvertible, endCropRectangle: interop.PointerConvertible, timeRange: interop.PointerConvertible): boolean;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptionRenderer extends NSObject {
  get captions(): NSArray;
  set captions(value: NSArray<interop.Object> | Array<interop.Object>);

  bounds: CGRect;

  captionSceneChangesInRange(consideredTimeRange: CMTimeRange): NSArray;

  renderInContextForTime(ctx: interop.Object, time: CMTime): void;

  setCaptions(captions: NSArray<interop.Object> | Array<interop.Object>): void;

  setBounds(bounds: CGRect): void;
}

declare class AVCaptureSynchronizedDepthData extends AVCaptureSynchronizedData {
  readonly depthData: AVDepthData;

  readonly depthDataWasDropped: boolean;

  readonly droppedReason: interop.Enum<typeof AVCaptureOutputDataDroppedReason>;
}

declare class AVPlayerVideoOutputConfiguration extends NSObject {
  readonly sourcePlayerItem: AVPlayerItem | null;

  readonly dataChannelDescriptions: NSArray;

  readonly preferredTransform: CGAffineTransform;

  readonly activationTime: CMTime;
}

declare class AVAssetSegmentTrackReport extends NSObject {
  readonly trackID: number;

  readonly mediaType: string;

  readonly earliestPresentationTimeStamp: CMTime;

  readonly duration: CMTime;

  readonly firstVideoSampleInformation: AVAssetSegmentReportSampleInformation;
}

declare class AVVideoCompositionRenderContext extends NSObject {
  readonly size: CGSize;

  readonly renderTransform: CGAffineTransform;

  readonly renderScale: number;

  readonly pixelAspectRatio: AVPixelAspectRatio;

  readonly edgeWidths: AVEdgeWidths;

  readonly highQualityRendering: boolean;

  readonly videoComposition: AVVideoComposition;

  newPixelBuffer(): interop.Object;
}

declare class AVExternalSyncDeviceDiscoverySession extends NSObject {
  static readonly sharedSession: AVExternalSyncDeviceDiscoverySession;

  static readonly supported: boolean;

  readonly devices: NSArray;

  static isSupported(): boolean;
}

declare class AVCaptureSynchronizedData extends NSObject {
  readonly timestamp: CMTime;
}

declare class AVCompositionTrackFormatDescriptionReplacement extends NSObject implements NSSecureCoding {
  readonly originalFormatDescription: interop.Object;

  readonly replacementFormatDescription: interop.Object;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVCaptureSession extends NSObject {
  canSetSessionPreset(preset: string): boolean;

  sessionPreset: string;

  readonly inputs: NSArray;

  canAddInput(input: AVCaptureInput): boolean;

  addInput(input: AVCaptureInput): void;

  removeInput(input: AVCaptureInput): void;

  readonly outputs: NSArray;

  canAddOutput(output: AVCaptureOutput): boolean;

  addOutput(output: AVCaptureOutput): void;

  removeOutput(output: AVCaptureOutput): void;

  addInputWithNoConnections(input: AVCaptureInput): void;

  addOutputWithNoConnections(output: AVCaptureOutput): void;

  readonly connections: NSArray;

  canAddConnection(connection: AVCaptureConnection): boolean;

  addConnection(connection: AVCaptureConnection): void;

  removeConnection(connection: AVCaptureConnection): void;

  readonly supportsControls: boolean;

  readonly maxControlsCount: number;

  setControlsDelegateQueue(controlsDelegate: AVCaptureSessionControlsDelegate | null, controlsDelegateCallbackQueue: NSObject | null): void;

  readonly controlsDelegate: AVCaptureSessionControlsDelegate;

  readonly controlsDelegateCallbackQueue: NSObject;

  readonly controls: NSArray;

  canAddControl(control: AVCaptureControl): boolean;

  addControl(control: AVCaptureControl): void;

  removeControl(control: AVCaptureControl): void;

  beginConfiguration(): void;

  commitConfiguration(): void;

  readonly running: boolean;

  readonly interrupted: boolean;

  readonly multitaskingCameraAccessSupported: boolean;

  multitaskingCameraAccessEnabled: boolean;

  usesApplicationAudioSession: boolean;

  automaticallyConfiguresApplicationAudioSession: boolean;

  configuresApplicationAudioSessionToMixWithOthers: boolean;

  configuresApplicationAudioSessionForBluetoothHighQualityRecording: boolean;

  automaticallyConfiguresCaptureDeviceForWideColor: boolean;

  startRunning(): void;

  stopRunning(): void;

  readonly synchronizationClock: interop.Object;

  readonly masterClock: interop.Object;

  readonly hardwareCost: number;

  readonly manualDeferredStartSupported: boolean;

  automaticallyRunsDeferredStart: boolean;

  runDeferredStartWhenNeeded(): void;

  readonly deferredStartDelegate: AVCaptureSessionDeferredStartDelegate;

  readonly deferredStartDelegateCallbackQueue: NSObject;

  setDeferredStartDelegateDeferredStartDelegateCallbackQueue(deferredStartDelegate: AVCaptureSessionDeferredStartDelegate | null, deferredStartDelegateCallbackQueue: NSObject | null): void;

  setSessionPreset(sessionPreset: string): void;

  isRunning(): boolean;

  isInterrupted(): boolean;

  isMultitaskingCameraAccessSupported(): boolean;

  isMultitaskingCameraAccessEnabled(): boolean;

  setMultitaskingCameraAccessEnabled(multitaskingCameraAccessEnabled: boolean): void;

  setUsesApplicationAudioSession(usesApplicationAudioSession: boolean): void;

  setAutomaticallyConfiguresApplicationAudioSession(automaticallyConfiguresApplicationAudioSession: boolean): void;

  setConfiguresApplicationAudioSessionToMixWithOthers(configuresApplicationAudioSessionToMixWithOthers: boolean): void;

  setConfiguresApplicationAudioSessionForBluetoothHighQualityRecording(configuresApplicationAudioSessionForBluetoothHighQualityRecording: boolean): void;

  setAutomaticallyConfiguresCaptureDeviceForWideColor(automaticallyConfiguresCaptureDeviceForWideColor: boolean): void;

  isManualDeferredStartSupported(): boolean;

  setAutomaticallyRunsDeferredStart(automaticallyRunsDeferredStart: boolean): void;
}

declare class AVAssetVariantVideoAttributes extends NSObject {
  readonly videoRange: string;

  readonly codecTypes: NSArray;

  readonly presentationSize: CGSize;

  readonly nominalFrameRate: number;

  readonly videoLayoutAttributes: NSArray;
}

declare class AVTimedMetadataGroup extends AVMetadataGroup implements NSCopying, NSMutableCopying {
  initWithItemsTimeRange(items: NSArray<interop.Object> | Array<interop.Object>, timeRange: CMTimeRange): this;

  initWithSampleBuffer(sampleBuffer: interop.Object): this;

  readonly timeRange: CMTimeRange;

  readonly items: NSArray;

  copyFormatDescription(): interop.Object;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetPlaybackAssistant extends NSObject {
  static assetPlaybackAssistantWithAsset<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset): InstanceType<This>;

  loadPlaybackConfigurationOptionsWithCompletionHandler(completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>) => void): void;
}

declare class AVAssetVariant extends NSObject {
  readonly peakBitRate: number;

  readonly averageBitRate: number;

  readonly videoAttributes: AVAssetVariantVideoAttributes;

  readonly audioAttributes: AVAssetVariantAudioAttributes;

  readonly URL: NSURL;
}

declare class AVContentKey extends NSObject {
  readonly contentKeySpecifier: AVContentKeySpecifier;

  readonly externalContentProtectionStatus: interop.Enum<typeof AVExternalContentProtectionStatus>;

  revoke(): void;
}

declare class AVCaptureSmartFramingMonitor extends NSObject {
  readonly supportedFramings: NSArray;

  get enabledFramings(): NSArray;
  set enabledFramings(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly recommendedFraming: AVCaptureFraming;

  startMonitoringWithError(outError: interop.PointerConvertible): boolean;

  stopMonitoring(): void;

  readonly monitoring: boolean;

  setEnabledFramings(enabledFramings: NSArray<interop.Object> | Array<interop.Object>): void;

  isMonitoring(): boolean;
}

declare class AVAssetWriter extends NSObject {
  static assetWriterWithURLFileTypeError<This extends abstract new (...args: any) => any>(this: This, outputURL: NSURL, outputFileType: string, outError: interop.PointerConvertible): InstanceType<This>;

  initWithURLFileTypeError(outputURL: NSURL, outputFileType: string, outError: interop.PointerConvertible): this;

  initWithContentType(outputContentType: UTType): this;

  readonly outputURL: NSURL;

  readonly outputFileType: string;

  readonly availableMediaTypes: NSArray;

  readonly status: interop.Enum<typeof AVAssetWriterStatus>;

  readonly error: NSError;

  get metadata(): NSArray;
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  shouldOptimizeForNetworkUse: boolean;

  directoryForTemporaryFiles: NSURL;

  readonly inputs: NSArray;

  canApplyOutputSettingsForMediaType(outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, mediaType: string): boolean;

  canAddInput(input: AVAssetWriterInput): boolean;

  addInput(input: AVAssetWriterInput): void;

  startWriting(): boolean;

  startSessionAtSourceTime(startTime: CMTime): void;

  endSessionAtSourceTime(endTime: CMTime): void;

  cancelWriting(): void;

  finishWriting(): boolean;

  finishWritingWithCompletionHandler(handler: () => void): void;

  setMetadata(metadata: NSArray<interop.Object> | Array<interop.Object>): void;

  setShouldOptimizeForNetworkUse(shouldOptimizeForNetworkUse: boolean): void;

  setDirectoryForTemporaryFiles(directoryForTemporaryFiles: NSURL): void;

  movieFragmentInterval: CMTime;

  initialMovieFragmentInterval: CMTime;

  initialMovieFragmentSequenceNumber: number;

  producesCombinableFragments: boolean;

  overallDurationHint: CMTime;

  movieTimeScale: number;

  setMovieFragmentInterval(movieFragmentInterval: CMTime): void;

  setInitialMovieFragmentInterval(initialMovieFragmentInterval: CMTime): void;

  setInitialMovieFragmentSequenceNumber(initialMovieFragmentSequenceNumber: number): void;

  setProducesCombinableFragments(producesCombinableFragments: boolean): void;

  setOverallDurationHint(overallDurationHint: CMTime): void;

  setMovieTimeScale(movieTimeScale: number): void;

  canAddInputGroup(inputGroup: AVAssetWriterInputGroup): boolean;

  addInputGroup(inputGroup: AVAssetWriterInputGroup): void;

  readonly inputGroups: NSArray;

  preferredOutputSegmentInterval: CMTime;

  initialSegmentStartTime: CMTime;

  outputFileTypeProfile: string;

  delegate: AVAssetWriterDelegate;

  flushSegment(): void;

  setPreferredOutputSegmentInterval(preferredOutputSegmentInterval: CMTime): void;

  setInitialSegmentStartTime(initialSegmentStartTime: CMTime): void;

  setOutputFileTypeProfile(outputFileTypeProfile: string): void;

  setDelegate(delegate: AVAssetWriterDelegate): void;
}

declare class AVZoomRange extends NSObject {
  readonly minZoomFactor: number;

  readonly maxZoomFactor: number;

  containsZoomFactor(zoomFactor: number): boolean;
}

declare class AVAssetWriterInputTaggedPixelBufferGroupAdaptor extends NSObject {
  static assetWriterInputTaggedPixelBufferGroupAdaptorWithAssetWriterInputSourcePixelBufferAttributes<This extends abstract new (...args: any) => any>(this: This, input: AVAssetWriterInput, sourcePixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithAssetWriterInputSourcePixelBufferAttributes(input: AVAssetWriterInput, sourcePixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly assetWriterInput: AVAssetWriterInput;

  readonly sourcePixelBufferAttributes: NSDictionary;

  readonly pixelBufferPool: interop.Object;

  appendTaggedPixelBufferGroupWithPresentationTime(taggedPixelBufferGroup: interop.PointerConvertible, presentationTime: CMTime): boolean;
}

declare class AVAssetResourceRenewalRequest extends AVAssetResourceLoadingRequest {
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableAudioMixInputParameters extends AVAudioMixInputParameters {
  static audioMixInputParametersWithTrack<This extends abstract new (...args: any) => any>(this: This, track: AVAssetTrack | null): InstanceType<This>;

  static audioMixInputParameters<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  // @ts-ignore MemberDecl.tsIgnore
  trackID: number;

  // @ts-ignore MemberDecl.tsIgnore
  audioTimePitchAlgorithm: string;

  // @ts-ignore MemberDecl.tsIgnore
  audioTapProcessor: interop.Object;

  setVolumeRampFromStartVolumeToEndVolumeTimeRange(startVolume: number, endVolume: number, timeRange: CMTimeRange): void;

  setVolumeAtTime(volume: number, time: CMTime): void;

  setTrackID(trackID: number): void;

  setAudioTimePitchAlgorithm(audioTimePitchAlgorithm: string | null): void;

  setAudioTapProcessor(audioTapProcessor: interop.Object): void;
}

declare class AVCaptureAudioChannel extends NSObject {
  readonly averagePowerLevel: number;

  readonly peakHoldLevel: number;
}

declare class AVMetricPlayerItemVariantSwitchEvent extends AVMetricEvent {
  readonly fromVariant: AVAssetVariant;

  readonly toVariant: AVAssetVariant;

  readonly loadedTimeRanges: NSArray;

  readonly videoRendition: AVMetricMediaRendition;

  readonly audioRendition: AVMetricMediaRendition;

  readonly subtitleRendition: AVMetricMediaRendition;

  readonly didSucceed: boolean;
}

declare class AVAssetReaderAudioMixOutput extends AVAssetReaderOutput {
  static assetReaderAudioMixOutputWithAudioTracksAudioSettings<This extends abstract new (...args: any) => any>(this: This, audioTracks: NSArray<interop.Object> | Array<interop.Object>, audioSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithAudioTracksAudioSettings(audioTracks: NSArray<interop.Object> | Array<interop.Object>, audioSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly audioTracks: NSArray;

  readonly audioSettings: NSDictionary;

  audioMix: AVAudioMix;

  audioTimePitchAlgorithm: string;

  setAudioMix(audioMix: AVAudioMix | null): void;

  setAudioTimePitchAlgorithm(audioTimePitchAlgorithm: string): void;
}

declare class AVCaptureSynchronizedMetadataObjectData extends AVCaptureSynchronizedData {
  readonly metadataObjects: NSArray;
}

declare class AVCaptureIndexPicker extends AVCaptureControl {
  initWithLocalizedTitleSymbolNameNumberOfIndexes(localizedTitle: string, symbolName: string, numberOfIndexes: number): this;

  initWithLocalizedTitleSymbolNameNumberOfIndexesLocalizedTitleTransform(localizedTitle: string, symbolName: string, numberOfIndexes: number, localizedTitleTransform: (p1: number) => string): this;

  initWithLocalizedTitleSymbolNameLocalizedIndexTitles(localizedTitle: string, symbolName: string, localizedIndexTitles: NSArray<interop.Object> | Array<interop.Object>): this;

  selectedIndex: number;

  readonly localizedTitle: string;

  readonly symbolName: string;

  readonly numberOfIndexes: number;

  readonly localizedIndexTitles: NSArray;

  accessibilityIdentifier: string;

  setActionQueueAction(actionQueue: NSObject, action: (p1: number) => void): void;

  setSelectedIndex(selectedIndex: number): void;

  setAccessibilityIdentifier(accessibilityIdentifier: string | null): void;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableMovieTrack extends AVMovieTrack {
  // @ts-ignore MemberDecl.tsIgnore
  mediaDataStorage: AVMediaDataStorage;

  sampleReferenceBaseURL: NSURL;

  // @ts-ignore MemberDecl.tsIgnore
  enabled: boolean;

  // @ts-ignore MemberDecl.tsIgnore
  alternateGroupID: number;

  modified: boolean;

  readonly hasProtectedContent: boolean;

  timescale: number;

  setMediaDataStorage(mediaDataStorage: AVMediaDataStorage | null): void;

  setSampleReferenceBaseURL(sampleReferenceBaseURL: NSURL | null): void;

  isEnabled(): boolean;

  setEnabled(enabled: boolean): void;

  setAlternateGroupID(alternateGroupID: number): void;

  isModified(): boolean;

  setModified(modified: boolean): void;

  setTimescale(timescale: number): void;

  // @ts-ignore MemberDecl.tsIgnore
  languageCode: string;

  // @ts-ignore MemberDecl.tsIgnore
  extendedLanguageTag: string;

  setLanguageCode(languageCode: string | null): void;

  setExtendedLanguageTag(extendedLanguageTag: string | null): void;

  // @ts-ignore MemberDecl.tsIgnore
  naturalSize: CGSize;

  // @ts-ignore MemberDecl.tsIgnore
  preferredTransform: CGAffineTransform;

  layer: number;

  cleanApertureDimensions: CGSize;

  productionApertureDimensions: CGSize;

  encodedPixelsDimensions: CGSize;

  setNaturalSize(naturalSize: CGSize): void;

  setPreferredTransform(preferredTransform: CGAffineTransform): void;

  setLayer(layer: number): void;

  setCleanApertureDimensions(cleanApertureDimensions: CGSize): void;

  setProductionApertureDimensions(productionApertureDimensions: CGSize): void;

  setEncodedPixelsDimensions(encodedPixelsDimensions: CGSize): void;

  // @ts-ignore MemberDecl.tsIgnore
  preferredVolume: number;

  setPreferredVolume(preferredVolume: number): void;

  preferredMediaChunkSize: number;

  preferredMediaChunkDuration: CMTime;

  preferredMediaChunkAlignment: number;

  setPreferredMediaChunkSize(preferredMediaChunkSize: number): void;

  setPreferredMediaChunkDuration(preferredMediaChunkDuration: CMTime): void;

  setPreferredMediaChunkAlignment(preferredMediaChunkAlignment: number): void;

  insertTimeRangeOfTrackAtTimeCopySampleDataError(timeRange: CMTimeRange, track: AVAssetTrack, startTime: CMTime, copySampleData: boolean, outError: interop.PointerConvertible): boolean;

  insertEmptyTimeRange(timeRange: CMTimeRange): void;

  removeTimeRange(timeRange: CMTimeRange): void;

  scaleTimeRangeToDuration(timeRange: CMTimeRange, duration: CMTime): void;

  // @ts-ignore MemberDecl.tsIgnore
  get metadata(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  setMetadata(metadata: NSArray<interop.Object> | Array<interop.Object>): void;

  addTrackAssociationToTrackType(movieTrack: AVMovieTrack, trackAssociationType: string): void;

  removeTrackAssociationToTrackType(movieTrack: AVMovieTrack, trackAssociationType: string): void;

  replaceFormatDescriptionWithFormatDescription(formatDescription: interop.Object, newFormatDescription: interop.Object): void;

  appendSampleBufferDecodeTimePresentationTimeError(sampleBuffer: interop.Object, outDecodeTime: interop.PointerConvertible, outPresentationTime: interop.PointerConvertible, outError: interop.PointerConvertible): boolean;

  insertMediaTimeRangeIntoTimeRange(mediaTimeRange: CMTimeRange, trackTimeRange: CMTimeRange): boolean;

  hasMediaCharacteristic(mediaCharacteristic: string): boolean;

  segmentForTrackTime(trackTime: CMTime): AVAssetTrackSegment;

  samplePresentationTimeForTrackTime(trackTime: CMTime): CMTime;

  metadataForFormat(format: string): NSArray;

  associatedTracksOfType(trackAssociationType: string): NSArray;
}

declare class AVFragmentedMovieMinder extends AVFragmentedAssetMinder {
  static fragmentedMovieMinderWithMovieMindingInterval<This extends abstract new (...args: any) => any>(this: This, movie: AVFragmentedMovie, mindingInterval: number): InstanceType<This>;

  initWithMovieMindingInterval(movie: AVFragmentedMovie, mindingInterval: number): this;

  mindingInterval: number;

  readonly movies: NSArray;

  addFragmentedMovie(movie: AVFragmentedMovie): void;

  removeFragmentedMovie(movie: AVFragmentedMovie): void;

  setMindingInterval(mindingInterval: number): void;
}

declare class AVCaptureExternalDisplayConfiguration extends NSObject {
  shouldMatchFrameRate: boolean;

  bypassColorSpaceConversion: boolean;

  preferredResolution: CMVideoDimensions;

  setShouldMatchFrameRate(shouldMatchFrameRate: boolean): void;

  setBypassColorSpaceConversion(bypassColorSpaceConversion: boolean): void;

  setPreferredResolution(preferredResolution: CMVideoDimensions): void;
}

declare class AVCaptureDeviceFormat extends NSObject {
  readonly mediaType: string;

  readonly formatDescription: interop.Object;

  readonly videoSupportedFrameRateRanges: NSArray;

  readonly videoFieldOfView: number;

  readonly videoBinned: boolean;

  isVideoStabilizationModeSupported(videoStabilizationMode: interop.Enum<typeof AVCaptureVideoStabilizationMode>): boolean;

  readonly videoStabilizationSupported: boolean;

  readonly videoMaxZoomFactor: number;

  readonly videoZoomFactorUpscaleThreshold: number;

  readonly systemRecommendedVideoZoomRange: AVZoomRange;

  readonly minExposureDuration: CMTime;

  readonly maxExposureDuration: CMTime;

  readonly systemRecommendedExposureBiasRange: AVExposureBiasRange;

  readonly minISO: number;

  readonly maxISO: number;

  readonly globalToneMappingSupported: boolean;

  readonly videoHDRSupported: boolean;

  readonly highResolutionStillImageDimensions: CMVideoDimensions;

  readonly highPhotoQualitySupported: boolean;

  readonly highestPhotoQualitySupported: boolean;

  readonly autoFocusSystem: interop.Enum<typeof AVCaptureAutoFocusSystem>;

  readonly supportedColorSpaces: NSArray;

  readonly videoMinZoomFactorForDepthDataDelivery: number;

  readonly videoMaxZoomFactorForDepthDataDelivery: number;

  readonly supportedVideoZoomFactorsForDepthDataDelivery: NSArray;

  readonly supportedVideoZoomRangesForDepthDataDelivery: NSArray;

  readonly zoomFactorsOutsideOfVideoZoomRangesForDepthDeliverySupported: boolean;

  readonly supportedDepthDataFormats: NSArray;

  readonly unsupportedCaptureOutputClasses: NSArray;

  readonly supportedMaxPhotoDimensions: NSArray;

  readonly secondaryNativeResolutionZoomFactors: NSArray;

  readonly autoVideoFrameRateSupported: boolean;

  isVideoBinned(): boolean;

  isVideoStabilizationSupported(): boolean;

  isGlobalToneMappingSupported(): boolean;

  isVideoHDRSupported(): boolean;

  isHighPhotoQualitySupported(): boolean;

  isHighestPhotoQualitySupported(): boolean;

  isAutoVideoFrameRateSupported(): boolean;

  readonly portraitEffectsMatteStillImageDeliverySupported: boolean;

  isPortraitEffectsMatteStillImageDeliverySupported(): boolean;

  readonly multiCamSupported: boolean;

  isMultiCamSupported(): boolean;

  readonly spatialVideoCaptureSupported: boolean;

  isSpatialVideoCaptureSupported(): boolean;

  readonly geometricDistortionCorrectedVideoFieldOfView: number;

  readonly centerStageSupported: boolean;

  readonly videoMinZoomFactorForCenterStage: number;

  readonly videoMaxZoomFactorForCenterStage: number;

  readonly videoFrameRateRangeForCenterStage: AVFrameRateRange;

  isCenterStageSupported(): boolean;

  readonly portraitEffectSupported: boolean;

  readonly videoFrameRateRangeForPortraitEffect: AVFrameRateRange;

  isPortraitEffectSupported(): boolean;

  readonly studioLightSupported: boolean;

  readonly videoFrameRateRangeForStudioLight: AVFrameRateRange;

  isStudioLightSupported(): boolean;

  readonly reactionEffectsSupported: boolean;

  readonly videoFrameRateRangeForReactionEffectsInProgress: AVFrameRateRange;

  readonly backgroundReplacementSupported: boolean;

  readonly videoFrameRateRangeForBackgroundReplacement: AVFrameRateRange;

  isBackgroundReplacementSupported(): boolean;

  readonly cinematicVideoCaptureSupported: boolean;

  readonly defaultSimulatedAperture: number;

  readonly minSimulatedAperture: number;

  readonly maxSimulatedAperture: number;

  readonly videoMinZoomFactorForCinematicVideo: number;

  readonly videoMaxZoomFactorForCinematicVideo: number;

  readonly videoFrameRateRangeForCinematicVideo: AVFrameRateRange;

  isCinematicVideoCaptureSupported(): boolean;

  readonly supportedDynamicAspectRatios: NSArray;

  videoFieldOfViewForAspectRatioGeometricDistortionCorrected(aspectRatio: string, geometricDistortionCorrected: boolean): number;

  readonly smartFramingSupported: boolean;

  isSmartFramingSupported(): boolean;

  readonly cameraLensSmudgeDetectionSupported: boolean;

  isCameraLensSmudgeDetectionSupported(): boolean;
}

declare class AVPlayerItemIntegratedTimelineSnapshot extends NSObject {
  readonly duration: CMTime;

  readonly currentSegment: AVPlayerItemSegment;

  readonly segments: NSArray;

  readonly currentTime: CMTime;

  readonly currentDate: NSDate;

  mapTimeToSegmentAtSegmentOffset(time: CMTime, timeSegmentOut: interop.PointerConvertible, segmentOffsetOut: interop.PointerConvertible): void;
}

declare class AVCaptureManualExposureBracketedStillImageSettings extends AVCaptureBracketedStillImageSettings {
  static manualExposureSettingsWithExposureDurationISO<This extends abstract new (...args: any) => any>(this: This, duration: CMTime, ISO: number): InstanceType<This>;

  readonly exposureDuration: CMTime;

  readonly ISO: number;
}

declare class AVCaptureSynchronizedDataCollection extends NSObject implements NSFastEnumeration {
  synchronizedDataForCaptureOutput(captureOutput: AVCaptureOutput): AVCaptureSynchronizedData;

  objectForKeyedSubscript(key: AVCaptureOutput): AVCaptureSynchronizedData;

  readonly count: number;

  countByEnumeratingWithStateObjectsCount(state: interop.PointerConvertible, buffer: interop.PointerConvertible, len: number): number;

  readonly [Symbol.iterator]: () => Iterator<any>;

}

declare class AVAssetResourceLoader extends NSObject {
  setDelegateQueue(delegate: AVAssetResourceLoaderDelegate | null, delegateQueue: NSObject | null): void;

  readonly delegate: AVAssetResourceLoaderDelegate;

  readonly delegateQueue: NSObject;

  preloadsEligibleContentKeys: boolean;

  setPreloadsEligibleContentKeys(preloadsEligibleContentKeys: boolean): void;

  sendsCommonMediaClientDataAsHTTPHeaders: boolean;

  setSendsCommonMediaClientDataAsHTTPHeaders(sendsCommonMediaClientDataAsHTTPHeaders: boolean): void;
}

declare class AVAsset extends NSObject implements NSCopying, AVAsynchronousKeyValueLoading {
  static assetWithURL<This extends abstract new (...args: any) => any>(this: This, URL: NSURL): InstanceType<This>;

  readonly duration: CMTime;

  readonly preferredRate: number;

  readonly preferredVolume: number;

  readonly preferredTransform: CGAffineTransform;

  readonly naturalSize: CGSize;

  readonly minimumTimeOffsetFromLive: CMTime;

  readonly providesPreciseDurationAndTiming: boolean;

  cancelLoading(): void;

  readonly referenceRestrictions: interop.Enum<typeof AVAssetReferenceRestrictions>;

  readonly tracks: NSArray;

  trackWithTrackID(trackID: number): AVAssetTrack;

  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVAssetTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly trackGroups: NSArray;

  readonly creationDate: AVMetadataItem;

  readonly lyrics: string;

  readonly commonMetadata: NSArray;

  readonly metadata: NSArray;

  readonly availableMetadataFormats: NSArray;

  metadataForFormat(format: string): NSArray;

  loadMetadataForFormatCompletionHandler(format: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly availableChapterLocales: NSArray;

  chapterMetadataGroupsWithTitleLocaleContainingItemsWithCommonKeys(locale: NSLocale, commonKeys: NSArray<interop.Object> | Array<interop.Object> | null): NSArray;

  loadChapterMetadataGroupsWithTitleLocaleContainingItemsWithCommonKeysCompletionHandler(locale: NSLocale, commonKeys: NSArray<interop.Object> | Array<interop.Object>, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  chapterMetadataGroupsBestMatchingPreferredLanguages(preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  loadChapterMetadataGroupsBestMatchingPreferredLanguagesCompletionHandler(preferredLanguages: NSArray<interop.Object> | Array<interop.Object>, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly availableMediaCharacteristicsWithMediaSelectionOptions: NSArray;

  mediaSelectionGroupForMediaCharacteristic(mediaCharacteristic: string): AVMediaSelectionGroup;

  loadMediaSelectionGroupForMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: AVMediaSelectionGroup, p2: NSError) => void | null): void;

  readonly preferredMediaSelection: AVMediaSelection;

  readonly allMediaSelections: NSArray;

  readonly hasProtectedContent: boolean;

  readonly canContainFragments: boolean;

  readonly containsFragments: boolean;

  readonly overallDurationHint: CMTime;

  readonly playable: boolean;

  readonly exportable: boolean;

  readonly readable: boolean;

  readonly composable: boolean;

  readonly compatibleWithSavedPhotosAlbum: boolean;

  readonly compatibleWithAirPlayVideo: boolean;

  isPlayable(): boolean;

  isExportable(): boolean;

  isReadable(): boolean;

  isComposable(): boolean;

  isCompatibleWithSavedPhotosAlbum(): boolean;

  isCompatibleWithAirPlayVideo(): boolean;

  unusedTrackID(): number;

  findUnusedTrackIDWithCompletionHandler(completionHandler: (p1: number, p2: NSError) => void | null): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  statusOfValueForKeyError(key: string, outError: interop.PointerConvertible): interop.Enum<typeof AVKeyValueStatus>;

  loadValuesAsynchronouslyForKeysCompletionHandler(keys: NSArray<interop.Object> | Array<interop.Object>, handler: () => void | null): void;
}

declare class AVPlayerItemAccessLog extends NSObject implements NSCopying {
  extendedLogData(): NSData;

  readonly extendedLogDataStringEncoding: number;

  readonly events: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableTimedMetadataGroup extends AVTimedMetadataGroup {
  // @ts-ignore MemberDecl.tsIgnore
  timeRange: CMTimeRange;

  // @ts-ignore MemberDecl.tsIgnore
  get items(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set items(value: NSArray<interop.Object> | Array<interop.Object>);

  setTimeRange(timeRange: CMTimeRange): void;

  setItems(items: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVSampleBufferRequest extends NSObject {
  initWithStartCursor(startCursor: AVSampleCursor): this;

  readonly startCursor: AVSampleCursor;

  direction: interop.Enum<typeof AVSampleBufferRequestDirection>;

  limitCursor: AVSampleCursor;

  preferredMinSampleCount: number;

  maxSampleCount: number;

  mode: interop.Enum<typeof AVSampleBufferRequestMode>;

  overrideTime: CMTime;

  setDirection(direction: interop.Enum<typeof AVSampleBufferRequestDirection>): void;

  setLimitCursor(limitCursor: AVSampleCursor | null): void;

  setPreferredMinSampleCount(preferredMinSampleCount: number): void;

  setMaxSampleCount(maxSampleCount: number): void;

  setMode(mode: interop.Enum<typeof AVSampleBufferRequestMode>): void;

  setOverrideTime(overrideTime: CMTime): void;
}

